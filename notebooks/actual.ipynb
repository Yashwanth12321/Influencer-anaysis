{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Performance                                          Video URL  HasFaces  \\\n",
      "0       1.1060  https://fgimagestorage.blob.core.windows.net/f...     False   \n",
      "1       2.2447  https://fgimagestorage.blob.core.windows.net/f...     False   \n",
      "2       2.0126  https://fgimagestorage.blob.core.windows.net/f...     False   \n",
      "3       1.7708  https://fgimagestorage.blob.core.windows.net/f...     False   \n",
      "4       0.6293  https://fgimagestorage.blob.core.windows.net/f...     False   \n",
      "\n",
      "  FaceID  Processed  \n",
      "0   None      False  \n",
      "1   None      False  \n",
      "2   None      False  \n",
      "3   None      False  \n",
      "4   None      False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Suppress OpenGL warnings\n",
    "os.environ[\"LIBGL_DEBUG\"] = \"quiet\"\n",
    "os.environ[\"MESA_LOADER_DRIVER_OVERRIDE\"] = \"swrast\"  # Force software rendering (optional)\n",
    "\n",
    "# Your imports and script logic here\n",
    "\n",
    "# Load the Excel file\n",
    "data_path = \"/home/harshit/Desktop/hi/influencer_analysis/src/Assignment Data.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "\n",
    "# Add columns to track processing status\n",
    "df[\"HasFaces\"] = False\n",
    "df[\"FaceID\"] = None\n",
    "df[\"Processed\"] = False\n",
    "print(df.head())\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Suppress OpenGL warnings\n",
    "sys.stderr = open(os.devnull, \"w\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_video(url, output_dir=\"./videos\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    filename = url.split(\"/\")[-1]  # Use the last part of the URL as the filename\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    print(\"filenama\",filename)\n",
    "    filename = filepath.split(\"/\")[-1]\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Video already exists: {filepath}\")\n",
    "        return filepath , filename\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f\"Downloaded video: {filepath}\")\n",
    "\n",
    "        return filepath,filename\n",
    "    else:\n",
    "        print(f\"Failed to download video from {url}\")\n",
    "        return None , None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_dir=\"./frames\", frame_rate=1):\n",
    "    # Use the video filename (without extension) to create a subfolder\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    video_frames_dir = os.path.join(output_dir, video_name)\n",
    "    \n",
    "    os.makedirs(video_frames_dir, exist_ok=True)  # Create a unique folder for the video's frames\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_interval = max(1, int(fps / frame_rate))  # Ensure the interval is at least 1\n",
    "    success, frame = cap.read()\n",
    "    count = 0\n",
    "\n",
    "    while success:\n",
    "        if count % frame_interval == 0:\n",
    "            frame_filename = os.path.join(video_frames_dir, f\"frame_{count}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "        success, frame = cap.read()\n",
    "        count += 1\n",
    "    cap.release()\n",
    "    print(f\"Frames extracted for {video_name} to: {video_frames_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "from collections import Counter\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "# Initialize Mediapipe face detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "def are_faces_similar(embedding1, embedding2, threshold=0.9):\n",
    "    \"\"\"Check if two face embeddings are similar based on a threshold.\"\"\"\n",
    "    distance = np.linalg.norm(embedding1 - embedding2)  # Euclidean distance\n",
    "    return distance < threshold\n",
    "\n",
    "def detect_faces(frame_path):\n",
    "    \"\"\"Detect faces in a single frame and return cropped faces with bounding boxes.\"\"\"\n",
    "    image = cv2.imread(frame_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Could not read image from {frame_path}\")\n",
    "        return [], image\n",
    "\n",
    "    cropped_faces = []\n",
    "    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.9) as face_detection:\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                h, w, _ = image.shape\n",
    "                x_min = int(bbox.xmin * w)\n",
    "                y_min = int(bbox.ymin * h)\n",
    "                box_width = int(bbox.width * w)\n",
    "                box_height = int(bbox.height * h)\n",
    "\n",
    "                # Ensure the bounding box is within image bounds\n",
    "                x_min = max(0, x_min)\n",
    "                y_min = max(0, y_min)\n",
    "                x_max = min(w, x_min + box_width)\n",
    "                y_max = min(h, y_min + box_height)\n",
    "\n",
    "                # Crop the detected face\n",
    "                cropped_face = image[y_min:y_max, x_min:x_max]\n",
    "                cropped_faces.append((cropped_face, (x_min, y_min, x_max, y_max)))\n",
    "\n",
    "    return cropped_faces, image\n",
    "\n",
    "def count_faces_in_video(frames_dir,fire_name):\n",
    "    \"\"\"Count faces across all frames in a directory, grouping similar faces.\"\"\"\n",
    "    frames_dir=frames_dir+\"/\"+fire_name\n",
    "    print(\"this is me\",frames_dir)\n",
    "    if not os.path.exists(frames_dir):\n",
    "        print(f\"Error: Directory {frames_dir} does not exist.\")\n",
    "        return Counter(), {}\n",
    "\n",
    "    face_counter = Counter()\n",
    "    face_to_frame_map = {}\n",
    "    known_embeddings = []  # Store unique face embeddings\n",
    "    known_face_ids = []    # Map embeddings to unique face IDs\n",
    "\n",
    "    for frame_file in os.listdir(frames_dir):\n",
    "        frame_path = os.path.join(frames_dir, frame_file)\n",
    "        if not frame_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue  # Skip non-image files\n",
    "\n",
    "        faces, image = detect_faces(frame_path)\n",
    "        if faces:\n",
    "            for cropped_face, bbox in faces:\n",
    "                try:\n",
    "                    # Step 1: Extract face embedding\n",
    "                    embedding = DeepFace.represent(img_path=cropped_face, model_name=\"VGG-Face\")[0][\"embedding\"]\n",
    "\n",
    "                    # Step 2: Check if this embedding matches any known embedding\n",
    "                    match_found = False\n",
    "                    for i, known_embedding in enumerate(known_embeddings):\n",
    "                        if are_faces_similar(embedding, known_embedding):\n",
    "                            face_id = known_face_ids[i]\n",
    "                            face_counter[face_id] += 1\n",
    "                            match_found = True\n",
    "                            break\n",
    "\n",
    "                    # Step 3: If no match found, assign a new ID\n",
    "                    if not match_found:\n",
    "                        face_id = len(known_embeddings) + 1  # Generate a new face ID\n",
    "                        known_embeddings.append(embedding)\n",
    "                        known_face_ids.append(face_id)\n",
    "                        face_counter[face_id] += 1\n",
    "                        # Store the first occurrence of this face for visualization\n",
    "                        if face_id not in face_to_frame_map:\n",
    "                            face_to_frame_map[face_id] = (image, (cropped_face, bbox))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing face: {e}\")\n",
    "\n",
    "    return face_counter, face_to_frame_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_face_embedding(face_id, face_embedding, vidname, embedding_dir=\"./embeddings\"):\n",
    "    \"\"\"\n",
    "    Save the face embedding or unique identifier to a file.\n",
    "    :param face_id: Unique ID of the face.\n",
    "    :param face_embedding: Data to save (e.g., an array or identifier).\n",
    "    :param vidname: Name of the video to organize embeddings.\n",
    "    :param embedding_dir: Directory to save the embeddings.\n",
    "    :return: Path to the saved embedding file.\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    folder_path = os.path.join(embedding_dir, vidname)\n",
    "    os.makedirs(folder_path, exist_ok=True)  # Ensure the subdirectory is created\n",
    "\n",
    "    # Save the embedding inside the subdirectory\n",
    "    embedding_path = os.path.join(folder_path, f\"face_{face_id}.npy\")\n",
    "    np.save(embedding_path, face_embedding)  # Save the face embedding as a .npy file\n",
    "    print(f\"Saved face embedding: {embedding_path}\")\n",
    "    return embedding_path\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def display_and_save_face(image, videoid, face, output_dir=\"./faces\"):\n",
    "    \"\"\"\n",
    "    Handle the structure of `face` dynamically.\n",
    "    Draw, display, and save a detected face.\n",
    "    \"\"\"\n",
    "    # Check the structure of `face`\n",
    "    if isinstance(face, tuple) and len(face) == 2:\n",
    "        cropped_face, bbox = face\n",
    "    elif isinstance(face, dict) and 'box' in face:\n",
    "        bbox = face['box']\n",
    "        cropped_face = image[bbox[1]:bbox[1] + bbox[3], bbox[0]:bbox[0] + bbox[2]]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected face structure: {face}\")\n",
    "\n",
    "    # Extract bounding box\n",
    "    x_min, y_min, x_max, y_max = bbox if len(bbox) == 4 else (bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3])\n",
    "\n",
    "    # Save the cropped face\n",
    "    face_dir = os.path.join(output_dir, str(videoid))\n",
    "    os.makedirs(face_dir, exist_ok=True)\n",
    "    face_path = os.path.join(face_dir, \"face.jpg\")\n",
    "    cv2.imwrite(face_path, cropped_face)\n",
    "    print(f\"Saved cropped face to: {face_path}\")\n",
    "\n",
    "#   # Optional: Display the face\n",
    "#     cv2.imshow(\"Cropped Face\", cropped_face)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()  \n",
    "\n",
    "    return face_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def process_video(row, video_dir=\"./videos\", frames_dir=\"./frames\", embedding_dir=\"./embeddings\"):\n",
    "    \"\"\"Process a single video: download, detect faces, and save results.\"\"\"\n",
    "    url = row[\"Video URL\"]\n",
    "    performance = row[\"Performance\"]\n",
    "\n",
    "    # Step 1: Download video\n",
    "    video_path,video_name = download_video(url, video_dir)\n",
    "\n",
    "    # Step 2: Extract frames\n",
    "    extract_frames(video_path, frames_dir)\n",
    "\n",
    "    # Step 3: Detect faces and count occurrences\n",
    "    face_counter, face_to_frame_map = count_faces_in_video(frames_dir,video_name)\n",
    "    if face_counter:\n",
    "        most_frequent_face_id = face_counter.most_common(1)[0][0]\n",
    "        print(f\"Most frequent face ID: {most_frequent_face_id} with {face_counter[most_frequent_face_id]} occurrences\")\n",
    "        # Display the most frequent face\n",
    "        image, face = face_to_frame_map[most_frequent_face_id]\n",
    "        display_and_save_face(image,video_name,face)\n",
    "    else:\n",
    "        print(\"No faces detected in the video.\")\n",
    "\n",
    "    if len(face_counter) == 0:\n",
    "        return None, False  # No faces detected\n",
    "\n",
    "    # Step 4: Identify most frequent face\n",
    "    most_frequent_face = face_counter.most_common(1)[0]\n",
    "    most_frequent_face_id = face_counter.most_common(1)[0][0]\n",
    "    image, (cropped_face, bbox) = face_to_frame_map[most_frequent_face_id]\n",
    "\n",
    "    try:\n",
    "        # Step 5: Extract face embedding with enforce_detection=False\n",
    "        embedding = DeepFace.represent(\n",
    "            img_path=cropped_face, \n",
    "            model_name=\"VGG-Face\", \n",
    "            enforce_detection=False\n",
    "        )[0][\"embedding\"]\n",
    "\n",
    "        # Step 6: Save face embedding\n",
    "        save_face_embedding(most_frequent_face_id, embedding, row[\"Video URL\"].split(\"/\")[-1], embedding_dir)\n",
    "\n",
    "        return most_frequent_face_id, True\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing face in video {row['Video URL']}: {e}\")\n",
    "        return None, False\n",
    "\n",
    "\n",
    "# Output directories\n",
    "videos_dir = \"./videos\"\n",
    "frames_dir = \"./frames\"\n",
    "embeddings_dir = \"./embeddings\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(videos_dir, exist_ok=True)\n",
    "os.makedirs(frames_dir, exist_ok=True)\n",
    "os.makedirs(embeddings_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 1/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-999607261342550\n",
      "filenama hd-999607261342550\n",
      "Video already exists: ./videos/hd-999607261342550\n",
      "Frames extracted for hd-999607261342550 to: ./frames/hd-999607261342550\n",
      "this is me ./frames/hd-999607261342550\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 2/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-997580728807604\n",
      "filenama hd-997580728807604\n",
      "Video already exists: ./videos/hd-997580728807604\n",
      "Frames extracted for hd-997580728807604 to: ./frames/hd-997580728807604\n",
      "this is me ./frames/hd-997580728807604\n",
      "No faces detected in the video.\n",
      "Processing row 3/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-992418235673669\n",
      "filenama hd-992418235673669\n",
      "Video already exists: ./videos/hd-992418235673669\n",
      "Frames extracted for hd-992418235673669 to: ./frames/hd-992418235673669\n",
      "this is me ./frames/hd-992418235673669\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 4/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-992064161877405\n",
      "filenama hd-992064161877405\n",
      "Video already exists: ./videos/hd-992064161877405\n",
      "Frames extracted for hd-992064161877405 to: ./frames/hd-992064161877405\n",
      "this is me ./frames/hd-992064161877405\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-992064161877405/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-992064161877405/face_1.npy\n",
      "Processing row 5/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-991636695150147\n",
      "filenama hd-991636695150147\n",
      "Video already exists: ./videos/hd-991636695150147\n",
      "Frames extracted for hd-991636695150147 to: ./frames/hd-991636695150147\n",
      "this is me ./frames/hd-991636695150147\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 6/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-989969399547901\n",
      "filenama hd-989969399547901\n",
      "Video already exists: ./videos/hd-989969399547901\n",
      "Frames extracted for hd-989969399547901 to: ./frames/hd-989969399547901\n",
      "this is me ./frames/hd-989969399547901\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 7/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-989930303148492\n",
      "filenama hd-989930303148492\n",
      "Video already exists: ./videos/hd-989930303148492\n",
      "Frames extracted for hd-989930303148492 to: ./frames/hd-989930303148492\n",
      "this is me ./frames/hd-989930303148492\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 8/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-989654009083459\n",
      "filenama hd-989654009083459\n",
      "Video already exists: ./videos/hd-989654009083459\n",
      "Frames extracted for hd-989654009083459 to: ./frames/hd-989654009083459\n",
      "this is me ./frames/hd-989654009083459\n",
      "No faces detected in the video.\n",
      "Processing row 9/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-989600295478567\n",
      "filenama hd-989600295478567\n",
      "Video already exists: ./videos/hd-989600295478567\n",
      "Frames extracted for hd-989600295478567 to: ./frames/hd-989600295478567\n",
      "this is me ./frames/hd-989600295478567\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 10/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-989284361966196\n",
      "filenama hd-989284361966196\n",
      "Video already exists: ./videos/hd-989284361966196\n",
      "Frames extracted for hd-989284361966196 to: ./frames/hd-989284361966196\n",
      "this is me ./frames/hd-989284361966196\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 11/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-988185795921355\n",
      "filenama hd-988185795921355\n",
      "Video already exists: ./videos/hd-988185795921355\n",
      "Frames extracted for hd-988185795921355 to: ./frames/hd-988185795921355\n",
      "this is me ./frames/hd-988185795921355\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 12/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-987643572956494\n",
      "filenama hd-987643572956494\n",
      "Video already exists: ./videos/hd-987643572956494\n",
      "Frames extracted for hd-987643572956494 to: ./frames/hd-987643572956494\n",
      "this is me ./frames/hd-987643572956494\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-987643572956494/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-987643572956494/face_1.npy\n",
      "Processing row 13/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-987287402378278\n",
      "filenama hd-987287402378278\n",
      "Video already exists: ./videos/hd-987287402378278\n",
      "Frames extracted for hd-987287402378278 to: ./frames/hd-987287402378278\n",
      "this is me ./frames/hd-987287402378278\n",
      "No faces detected in the video.\n",
      "Processing row 14/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-987232088920289\n",
      "filenama hd-987232088920289\n",
      "Video already exists: ./videos/hd-987232088920289\n",
      "Frames extracted for hd-987232088920289 to: ./frames/hd-987232088920289\n",
      "this is me ./frames/hd-987232088920289\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 15/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-986360206629277\n",
      "filenama hd-986360206629277\n",
      "Video already exists: ./videos/hd-986360206629277\n",
      "Frames extracted for hd-986360206629277 to: ./frames/hd-986360206629277\n",
      "this is me ./frames/hd-986360206629277\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 16/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-983335896508749\n",
      "filenama hd-983335896508749\n",
      "Video already exists: ./videos/hd-983335896508749\n",
      "Frames extracted for hd-983335896508749 to: ./frames/hd-983335896508749\n",
      "this is me ./frames/hd-983335896508749\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-983335896508749/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-983335896508749/face_1.npy\n",
      "Processing row 17/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-978448136455993\n",
      "filenama hd-978448136455993\n",
      "Video already exists: ./videos/hd-978448136455993\n",
      "Frames extracted for hd-978448136455993 to: ./frames/hd-978448136455993\n",
      "this is me ./frames/hd-978448136455993\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 18/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-977008307250628\n",
      "filenama hd-977008307250628\n",
      "Video already exists: ./videos/hd-977008307250628\n",
      "Frames extracted for hd-977008307250628 to: ./frames/hd-977008307250628\n",
      "this is me ./frames/hd-977008307250628\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 19/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-975523146942238\n",
      "filenama hd-975523146942238\n",
      "Video already exists: ./videos/hd-975523146942238\n",
      "Frames extracted for hd-975523146942238 to: ./frames/hd-975523146942238\n",
      "this is me ./frames/hd-975523146942238\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 20/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-967731231014052\n",
      "filenama hd-967731231014052\n",
      "Video already exists: ./videos/hd-967731231014052\n",
      "Frames extracted for hd-967731231014052 to: ./frames/hd-967731231014052\n",
      "this is me ./frames/hd-967731231014052\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 21/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-966715248087290\n",
      "filenama hd-966715248087290\n",
      "Video already exists: ./videos/hd-966715248087290\n",
      "Frames extracted for hd-966715248087290 to: ./frames/hd-966715248087290\n",
      "this is me ./frames/hd-966715248087290\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 22/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-966458824582483\n",
      "filenama hd-966458824582483\n",
      "Video already exists: ./videos/hd-966458824582483\n",
      "Frames extracted for hd-966458824582483 to: ./frames/hd-966458824582483\n",
      "this is me ./frames/hd-966458824582483\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 23/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-966019214364727\n",
      "filenama hd-966019214364727\n",
      "Video already exists: ./videos/hd-966019214364727\n",
      "Frames extracted for hd-966019214364727 to: ./frames/hd-966019214364727\n",
      "this is me ./frames/hd-966019214364727\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 24/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-965108935263649\n",
      "filenama hd-965108935263649\n",
      "Video already exists: ./videos/hd-965108935263649\n",
      "Frames extracted for hd-965108935263649 to: ./frames/hd-965108935263649\n",
      "this is me ./frames/hd-965108935263649\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-965108935263649/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-965108935263649/face_1.npy\n",
      "Processing row 25/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-964733417506862\n",
      "filenama hd-964733417506862\n",
      "Video already exists: ./videos/hd-964733417506862\n",
      "Frames extracted for hd-964733417506862 to: ./frames/hd-964733417506862\n",
      "this is me ./frames/hd-964733417506862\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 26/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-963303392509872\n",
      "filenama hd-963303392509872\n",
      "Video already exists: ./videos/hd-963303392509872\n",
      "Frames extracted for hd-963303392509872 to: ./frames/hd-963303392509872\n",
      "this is me ./frames/hd-963303392509872\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-963303392509872/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-963303392509872/face_1.npy\n",
      "Processing row 27/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-960884234555681\n",
      "filenama hd-960884234555681\n",
      "Video already exists: ./videos/hd-960884234555681\n",
      "Frames extracted for hd-960884234555681 to: ./frames/hd-960884234555681\n",
      "this is me ./frames/hd-960884234555681\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-960884234555681/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-960884234555681/face_1.npy\n",
      "Processing row 28/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-958774641659407\n",
      "filenama hd-958774641659407\n",
      "Video already exists: ./videos/hd-958774641659407\n",
      "Frames extracted for hd-958774641659407 to: ./frames/hd-958774641659407\n",
      "this is me ./frames/hd-958774641659407\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-958774641659407/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-958774641659407/face_1.npy\n",
      "Processing row 29/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-958675741960412\n",
      "filenama hd-958675741960412\n",
      "Video already exists: ./videos/hd-958675741960412\n",
      "Frames extracted for hd-958675741960412 to: ./frames/hd-958675741960412\n",
      "this is me ./frames/hd-958675741960412\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 30/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-958267042213267\n",
      "filenama hd-958267042213267\n",
      "Video already exists: ./videos/hd-958267042213267\n",
      "Frames extracted for hd-958267042213267 to: ./frames/hd-958267042213267\n",
      "this is me ./frames/hd-958267042213267\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 31/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-954832972830686\n",
      "filenama hd-954832972830686\n",
      "Video already exists: ./videos/hd-954832972830686\n",
      "Frames extracted for hd-954832972830686 to: ./frames/hd-954832972830686\n",
      "this is me ./frames/hd-954832972830686\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-954832972830686/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-954832972830686/face_1.npy\n",
      "Processing row 32/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-954440782897187\n",
      "filenama hd-954440782897187\n",
      "Video already exists: ./videos/hd-954440782897187\n",
      "Frames extracted for hd-954440782897187 to: ./frames/hd-954440782897187\n",
      "this is me ./frames/hd-954440782897187\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 33/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-951885082053340\n",
      "filenama hd-951885082053340\n",
      "Video already exists: ./videos/hd-951885082053340\n",
      "Frames extracted for hd-951885082053340 to: ./frames/hd-951885082053340\n",
      "this is me ./frames/hd-951885082053340\n",
      "No faces detected in the video.\n",
      "Processing row 34/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-951491629353387\n",
      "filenama hd-951491629353387\n",
      "Video already exists: ./videos/hd-951491629353387\n",
      "Frames extracted for hd-951491629353387 to: ./frames/hd-951491629353387\n",
      "this is me ./frames/hd-951491629353387\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 35/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-946181943065342\n",
      "filenama hd-946181943065342\n",
      "Video already exists: ./videos/hd-946181943065342\n",
      "Frames extracted for hd-946181943065342 to: ./frames/hd-946181943065342\n",
      "this is me ./frames/hd-946181943065342\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 36/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-944981830978756\n",
      "filenama hd-944981830978756\n",
      "Video already exists: ./videos/hd-944981830978756\n",
      "Frames extracted for hd-944981830978756 to: ./frames/hd-944981830978756\n",
      "this is me ./frames/hd-944981830978756\n",
      "No faces detected in the video.\n",
      "Processing row 37/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-944755280756437\n",
      "filenama hd-944755280756437\n",
      "Video already exists: ./videos/hd-944755280756437\n",
      "Frames extracted for hd-944755280756437 to: ./frames/hd-944755280756437\n",
      "this is me ./frames/hd-944755280756437\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 38/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-944160410298140\n",
      "filenama hd-944160410298140\n",
      "Video already exists: ./videos/hd-944160410298140\n",
      "Frames extracted for hd-944160410298140 to: ./frames/hd-944160410298140\n",
      "this is me ./frames/hd-944160410298140\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 39/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-942779243913664\n",
      "filenama hd-942779243913664\n",
      "Video already exists: ./videos/hd-942779243913664\n",
      "Frames extracted for hd-942779243913664 to: ./frames/hd-942779243913664\n",
      "this is me ./frames/hd-942779243913664\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-942779243913664/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-942779243913664/face_1.npy\n",
      "Processing row 40/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-942524046763053\n",
      "filenama hd-942524046763053\n",
      "Video already exists: ./videos/hd-942524046763053\n",
      "Frames extracted for hd-942524046763053 to: ./frames/hd-942524046763053\n",
      "this is me ./frames/hd-942524046763053\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 41/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-940634710428411\n",
      "filenama hd-940634710428411\n",
      "Video already exists: ./videos/hd-940634710428411\n",
      "Frames extracted for hd-940634710428411 to: ./frames/hd-940634710428411\n",
      "this is me ./frames/hd-940634710428411\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 42/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-939795907980426\n",
      "filenama hd-939795907980426\n",
      "Video already exists: ./videos/hd-939795907980426\n",
      "Frames extracted for hd-939795907980426 to: ./frames/hd-939795907980426\n",
      "this is me ./frames/hd-939795907980426\n",
      "No faces detected in the video.\n",
      "Processing row 43/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-938232524809973\n",
      "filenama hd-938232524809973\n",
      "Video already exists: ./videos/hd-938232524809973\n",
      "Frames extracted for hd-938232524809973 to: ./frames/hd-938232524809973\n",
      "this is me ./frames/hd-938232524809973\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 44/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-937508703912579\n",
      "filenama hd-937508703912579\n",
      "Video already exists: ./videos/hd-937508703912579\n",
      "Frames extracted for hd-937508703912579 to: ./frames/hd-937508703912579\n",
      "this is me ./frames/hd-937508703912579\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 45/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-937410954343974\n",
      "filenama hd-937410954343974\n",
      "Video already exists: ./videos/hd-937410954343974\n",
      "Frames extracted for hd-937410954343974 to: ./frames/hd-937410954343974\n",
      "this is me ./frames/hd-937410954343974\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-937410954343974/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-937410954343974/face_1.npy\n",
      "Processing row 46/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-935558767885747\n",
      "filenama hd-935558767885747\n",
      "Video already exists: ./videos/hd-935558767885747\n",
      "Frames extracted for hd-935558767885747 to: ./frames/hd-935558767885747\n",
      "this is me ./frames/hd-935558767885747\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 47/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-935530867630269\n",
      "filenama hd-935530867630269\n",
      "Video already exists: ./videos/hd-935530867630269\n",
      "Frames extracted for hd-935530867630269 to: ./frames/hd-935530867630269\n",
      "this is me ./frames/hd-935530867630269\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 48/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-935168780798574\n",
      "filenama hd-935168780798574\n",
      "Video already exists: ./videos/hd-935168780798574\n",
      "Frames extracted for hd-935168780798574 to: ./frames/hd-935168780798574\n",
      "this is me ./frames/hd-935168780798574\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 49/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-933913194646448\n",
      "filenama hd-933913194646448\n",
      "Video already exists: ./videos/hd-933913194646448\n",
      "Frames extracted for hd-933913194646448 to: ./frames/hd-933913194646448\n",
      "this is me ./frames/hd-933913194646448\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-933913194646448/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-933913194646448/face_1.npy\n",
      "Processing row 50/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-933773150951550\n",
      "filenama hd-933773150951550\n",
      "Video already exists: ./videos/hd-933773150951550\n",
      "Frames extracted for hd-933773150951550 to: ./frames/hd-933773150951550\n",
      "this is me ./frames/hd-933773150951550\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-933773150951550/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-933773150951550/face_1.npy\n",
      "Processing row 51/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-932703258597949\n",
      "filenama hd-932703258597949\n",
      "Video already exists: ./videos/hd-932703258597949\n",
      "Frames extracted for hd-932703258597949 to: ./frames/hd-932703258597949\n",
      "this is me ./frames/hd-932703258597949\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-932703258597949/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-932703258597949/face_1.npy\n",
      "Processing row 52/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-932296771464171\n",
      "filenama hd-932296771464171\n",
      "Video already exists: ./videos/hd-932296771464171\n",
      "Frames extracted for hd-932296771464171 to: ./frames/hd-932296771464171\n",
      "this is me ./frames/hd-932296771464171\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 53/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-932085787962122\n",
      "filenama hd-932085787962122\n",
      "Video already exists: ./videos/hd-932085787962122\n",
      "Frames extracted for hd-932085787962122 to: ./frames/hd-932085787962122\n",
      "this is me ./frames/hd-932085787962122\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 54/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-932038864470963\n",
      "filenama hd-932038864470963\n",
      "Video already exists: ./videos/hd-932038864470963\n",
      "Frames extracted for hd-932038864470963 to: ./frames/hd-932038864470963\n",
      "this is me ./frames/hd-932038864470963\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 55/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-930116227971248\n",
      "filenama hd-930116227971248\n",
      "Video already exists: ./videos/hd-930116227971248\n",
      "Frames extracted for hd-930116227971248 to: ./frames/hd-930116227971248\n",
      "this is me ./frames/hd-930116227971248\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-930116227971248/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-930116227971248/face_1.npy\n",
      "Processing row 56/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-929830031529018\n",
      "filenama hd-929830031529018\n",
      "Video already exists: ./videos/hd-929830031529018\n",
      "Frames extracted for hd-929830031529018 to: ./frames/hd-929830031529018\n",
      "this is me ./frames/hd-929830031529018\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 57/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-929511878466995\n",
      "filenama hd-929511878466995\n",
      "Video already exists: ./videos/hd-929511878466995\n",
      "Frames extracted for hd-929511878466995 to: ./frames/hd-929511878466995\n",
      "this is me ./frames/hd-929511878466995\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 58/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-929300948587514\n",
      "filenama hd-929300948587514\n",
      "Video already exists: ./videos/hd-929300948587514\n",
      "Frames extracted for hd-929300948587514 to: ./frames/hd-929300948587514\n",
      "this is me ./frames/hd-929300948587514\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 59/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-925596815118953\n",
      "filenama hd-925596815118953\n",
      "Video already exists: ./videos/hd-925596815118953\n",
      "Frames extracted for hd-925596815118953 to: ./frames/hd-925596815118953\n",
      "this is me ./frames/hd-925596815118953\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 60/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-925260332281638\n",
      "filenama hd-925260332281638\n",
      "Video already exists: ./videos/hd-925260332281638\n",
      "Frames extracted for hd-925260332281638 to: ./frames/hd-925260332281638\n",
      "this is me ./frames/hd-925260332281638\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-925260332281638/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-925260332281638/face_1.npy\n",
      "Processing row 61/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-924865635226814\n",
      "filenama hd-924865635226814\n",
      "Video already exists: ./videos/hd-924865635226814\n",
      "Frames extracted for hd-924865635226814 to: ./frames/hd-924865635226814\n",
      "this is me ./frames/hd-924865635226814\n",
      "No faces detected in the video.\n",
      "Processing row 62/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-924585008982148\n",
      "filenama hd-924585008982148\n",
      "Video already exists: ./videos/hd-924585008982148\n",
      "Frames extracted for hd-924585008982148 to: ./frames/hd-924585008982148\n",
      "this is me ./frames/hd-924585008982148\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 63/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-621652523105267\n",
      "filenama hd-621652523105267\n",
      "Video already exists: ./videos/hd-621652523105267\n",
      "Frames extracted for hd-621652523105267 to: ./frames/hd-621652523105267\n",
      "this is me ./frames/hd-621652523105267\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 64/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-621266003076530\n",
      "filenama hd-621266003076530\n",
      "Video already exists: ./videos/hd-621266003076530\n",
      "Frames extracted for hd-621266003076530 to: ./frames/hd-621266003076530\n",
      "this is me ./frames/hd-621266003076530\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-621266003076530/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-621266003076530/face_1.npy\n",
      "Processing row 65/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-620702145697389\n",
      "filenama hd-620702145697389\n",
      "Video already exists: ./videos/hd-620702145697389\n",
      "Frames extracted for hd-620702145697389 to: ./frames/hd-620702145697389\n",
      "this is me ./frames/hd-620702145697389\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 66/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-620154813059921\n",
      "filenama hd-620154813059921\n",
      "Video already exists: ./videos/hd-620154813059921\n",
      "Frames extracted for hd-620154813059921 to: ./frames/hd-620154813059921\n",
      "this is me ./frames/hd-620154813059921\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-620154813059921/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-620154813059921/face_1.npy\n",
      "Processing row 67/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-618555366744628\n",
      "filenama hd-618555366744628\n",
      "Video already exists: ./videos/hd-618555366744628\n",
      "Frames extracted for hd-618555366744628 to: ./frames/hd-618555366744628\n",
      "this is me ./frames/hd-618555366744628\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-618555366744628/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-618555366744628/face_1.npy\n",
      "Processing row 68/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6174004652651971\n",
      "filenama hd-6174004652651971\n",
      "Video already exists: ./videos/hd-6174004652651971\n",
      "Frames extracted for hd-6174004652651971 to: ./frames/hd-6174004652651971\n",
      "this is me ./frames/hd-6174004652651971\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 69/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-617288786873081\n",
      "filenama hd-617288786873081\n",
      "Video already exists: ./videos/hd-617288786873081\n",
      "Frames extracted for hd-617288786873081 to: ./frames/hd-617288786873081\n",
      "this is me ./frames/hd-617288786873081\n",
      "No faces detected in the video.\n",
      "Processing row 70/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6172742522782221\n",
      "filenama hd-6172742522782221\n",
      "Video already exists: ./videos/hd-6172742522782221\n",
      "Frames extracted for hd-6172742522782221 to: ./frames/hd-6172742522782221\n",
      "this is me ./frames/hd-6172742522782221\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-6172742522782221/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-6172742522782221/face_1.npy\n",
      "Processing row 71/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-613417017284998\n",
      "filenama hd-613417017284998\n",
      "Video already exists: ./videos/hd-613417017284998\n",
      "Frames extracted for hd-613417017284998 to: ./frames/hd-613417017284998\n",
      "this is me ./frames/hd-613417017284998\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 72/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-613197413789434\n",
      "filenama hd-613197413789434\n",
      "Video already exists: ./videos/hd-613197413789434\n",
      "Frames extracted for hd-613197413789434 to: ./frames/hd-613197413789434\n",
      "this is me ./frames/hd-613197413789434\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 73/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-613152173490344\n",
      "filenama hd-613152173490344\n",
      "Video already exists: ./videos/hd-613152173490344\n",
      "Frames extracted for hd-613152173490344 to: ./frames/hd-613152173490344\n",
      "this is me ./frames/hd-613152173490344\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-613152173490344/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-613152173490344/face_1.npy\n",
      "Processing row 74/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-612555930635832\n",
      "filenama hd-612555930635832\n",
      "Video already exists: ./videos/hd-612555930635832\n",
      "Frames extracted for hd-612555930635832 to: ./frames/hd-612555930635832\n",
      "this is me ./frames/hd-612555930635832\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 75/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-612426467555072\n",
      "filenama hd-612426467555072\n",
      "Video already exists: ./videos/hd-612426467555072\n",
      "Frames extracted for hd-612426467555072 to: ./frames/hd-612426467555072\n",
      "this is me ./frames/hd-612426467555072\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-612426467555072/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-612426467555072/face_1.npy\n",
      "Processing row 76/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-611188517518682\n",
      "filenama hd-611188517518682\n",
      "Video already exists: ./videos/hd-611188517518682\n",
      "Frames extracted for hd-611188517518682 to: ./frames/hd-611188517518682\n",
      "this is me ./frames/hd-611188517518682\n",
      "No faces detected in the video.\n",
      "Processing row 77/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6107397609317402\n",
      "filenama hd-6107397609317402\n",
      "Video already exists: ./videos/hd-6107397609317402\n",
      "Frames extracted for hd-6107397609317402 to: ./frames/hd-6107397609317402\n",
      "this is me ./frames/hd-6107397609317402\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 78/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6096104653784047\n",
      "filenama hd-6096104653784047\n",
      "Video already exists: ./videos/hd-6096104653784047\n",
      "Frames extracted for hd-6096104653784047 to: ./frames/hd-6096104653784047\n",
      "this is me ./frames/hd-6096104653784047\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-6096104653784047/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-6096104653784047/face_1.npy\n",
      "Processing row 79/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-606237444463640\n",
      "filenama hd-606237444463640\n",
      "Video already exists: ./videos/hd-606237444463640\n",
      "Frames extracted for hd-606237444463640 to: ./frames/hd-606237444463640\n",
      "this is me ./frames/hd-606237444463640\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-606237444463640/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-606237444463640/face_1.npy\n",
      "Processing row 80/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-605272664726548\n",
      "filenama hd-605272664726548\n",
      "Video already exists: ./videos/hd-605272664726548\n",
      "Frames extracted for hd-605272664726548 to: ./frames/hd-605272664726548\n",
      "this is me ./frames/hd-605272664726548\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-605272664726548/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-605272664726548/face_1.npy\n",
      "Processing row 81/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6046690562050296\n",
      "filenama hd-6046690562050296\n",
      "Video already exists: ./videos/hd-6046690562050296\n",
      "Frames extracted for hd-6046690562050296 to: ./frames/hd-6046690562050296\n",
      "this is me ./frames/hd-6046690562050296\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-6046690562050296/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-6046690562050296/face_1.npy\n",
      "Processing row 82/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-604285914607200\n",
      "filenama hd-604285914607200\n",
      "Video already exists: ./videos/hd-604285914607200\n",
      "Frames extracted for hd-604285914607200 to: ./frames/hd-604285914607200\n",
      "this is me ./frames/hd-604285914607200\n",
      "No faces detected in the video.\n",
      "Processing row 83/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-604041931565137\n",
      "filenama hd-604041931565137\n",
      "Video already exists: ./videos/hd-604041931565137\n",
      "Frames extracted for hd-604041931565137 to: ./frames/hd-604041931565137\n",
      "this is me ./frames/hd-604041931565137\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-604041931565137/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-604041931565137/face_1.npy\n",
      "Processing row 84/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-603099807587246\n",
      "filenama hd-603099807587246\n",
      "Video already exists: ./videos/hd-603099807587246\n",
      "Frames extracted for hd-603099807587246 to: ./frames/hd-603099807587246\n",
      "this is me ./frames/hd-603099807587246\n",
      "No faces detected in the video.\n",
      "Processing row 85/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-911926190614858\n",
      "filenama hd-911926190614858\n",
      "Video already exists: ./videos/hd-911926190614858\n",
      "Frames extracted for hd-911926190614858 to: ./frames/hd-911926190614858\n",
      "this is me ./frames/hd-911926190614858\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-911926190614858/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-911926190614858/face_1.npy\n",
      "Processing row 86/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-911482386703699\n",
      "filenama hd-911482386703699\n",
      "Video already exists: ./videos/hd-911482386703699\n",
      "Frames extracted for hd-911482386703699 to: ./frames/hd-911482386703699\n",
      "this is me ./frames/hd-911482386703699\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 87/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-911172609864769\n",
      "filenama hd-911172609864769\n",
      "Video already exists: ./videos/hd-911172609864769\n",
      "Frames extracted for hd-911172609864769 to: ./frames/hd-911172609864769\n",
      "this is me ./frames/hd-911172609864769\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-911172609864769/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-911172609864769/face_1.npy\n",
      "Processing row 88/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-910958533691058\n",
      "filenama hd-910958533691058\n",
      "Video already exists: ./videos/hd-910958533691058\n",
      "Frames extracted for hd-910958533691058 to: ./frames/hd-910958533691058\n",
      "this is me ./frames/hd-910958533691058\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-910958533691058/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-910958533691058/face_1.npy\n",
      "Processing row 89/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-909937876815529\n",
      "filenama hd-909937876815529\n",
      "Video already exists: ./videos/hd-909937876815529\n",
      "Frames extracted for hd-909937876815529 to: ./frames/hd-909937876815529\n",
      "this is me ./frames/hd-909937876815529\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 90/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-909110383822260\n",
      "filenama hd-909110383822260\n",
      "Video already exists: ./videos/hd-909110383822260\n",
      "Frames extracted for hd-909110383822260 to: ./frames/hd-909110383822260\n",
      "this is me ./frames/hd-909110383822260\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-909110383822260/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-909110383822260/face_1.npy\n",
      "Processing row 91/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-909067460285978\n",
      "filenama hd-909067460285978\n",
      "Video already exists: ./videos/hd-909067460285978\n",
      "Frames extracted for hd-909067460285978 to: ./frames/hd-909067460285978\n",
      "this is me ./frames/hd-909067460285978\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 92/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-907416560296782\n",
      "filenama hd-907416560296782\n",
      "Video already exists: ./videos/hd-907416560296782\n",
      "Frames extracted for hd-907416560296782 to: ./frames/hd-907416560296782\n",
      "this is me ./frames/hd-907416560296782\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-907416560296782/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-907416560296782/face_1.npy\n",
      "Processing row 93/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-906909830682725\n",
      "filenama hd-906909830682725\n",
      "Video already exists: ./videos/hd-906909830682725\n",
      "Frames extracted for hd-906909830682725 to: ./frames/hd-906909830682725\n",
      "this is me ./frames/hd-906909830682725\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 94/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-906506897404894\n",
      "filenama hd-906506897404894\n",
      "Video already exists: ./videos/hd-906506897404894\n",
      "Frames extracted for hd-906506897404894 to: ./frames/hd-906506897404894\n",
      "this is me ./frames/hd-906506897404894\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 95/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-905844110841635\n",
      "filenama hd-905844110841635\n",
      "Video already exists: ./videos/hd-905844110841635\n",
      "Frames extracted for hd-905844110841635 to: ./frames/hd-905844110841635\n",
      "this is me ./frames/hd-905844110841635\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 96/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-905739711170399\n",
      "filenama hd-905739711170399\n",
      "Video already exists: ./videos/hd-905739711170399\n",
      "Frames extracted for hd-905739711170399 to: ./frames/hd-905739711170399\n",
      "this is me ./frames/hd-905739711170399\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-905739711170399/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-905739711170399/face_1.npy\n",
      "Processing row 97/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-905545323817883\n",
      "filenama hd-905545323817883\n",
      "Video already exists: ./videos/hd-905545323817883\n",
      "Frames extracted for hd-905545323817883 to: ./frames/hd-905545323817883\n",
      "this is me ./frames/hd-905545323817883\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 98/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-904815481005158\n",
      "filenama hd-904815481005158\n",
      "Video already exists: ./videos/hd-904815481005158\n",
      "Frames extracted for hd-904815481005158 to: ./frames/hd-904815481005158\n",
      "this is me ./frames/hd-904815481005158\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 99/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-904480964010630\n",
      "filenama hd-904480964010630\n",
      "Video already exists: ./videos/hd-904480964010630\n",
      "Frames extracted for hd-904480964010630 to: ./frames/hd-904480964010630\n",
      "this is me ./frames/hd-904480964010630\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 100/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-904174908300812\n",
      "filenama hd-904174908300812\n",
      "Video already exists: ./videos/hd-904174908300812\n",
      "Frames extracted for hd-904174908300812 to: ./frames/hd-904174908300812\n",
      "this is me ./frames/hd-904174908300812\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-904174908300812/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-904174908300812/face_1.npy\n",
      "Processing row 101/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-903960640750545\n",
      "filenama hd-903960640750545\n",
      "Video already exists: ./videos/hd-903960640750545\n",
      "Frames extracted for hd-903960640750545 to: ./frames/hd-903960640750545\n",
      "this is me ./frames/hd-903960640750545\n",
      "No faces detected in the video.\n",
      "Processing row 102/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-903913985069116\n",
      "filenama hd-903913985069116\n",
      "Video already exists: ./videos/hd-903913985069116\n",
      "Frames extracted for hd-903913985069116 to: ./frames/hd-903913985069116\n",
      "this is me ./frames/hd-903913985069116\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-903913985069116/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-903913985069116/face_1.npy\n",
      "Processing row 103/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-903060767715541\n",
      "filenama hd-903060767715541\n",
      "Video already exists: ./videos/hd-903060767715541\n",
      "Frames extracted for hd-903060767715541 to: ./frames/hd-903060767715541\n",
      "this is me ./frames/hd-903060767715541\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-903060767715541/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-903060767715541/face_1.npy\n",
      "Processing row 104/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-902843234362370\n",
      "filenama hd-902843234362370\n",
      "Video already exists: ./videos/hd-902843234362370\n",
      "Frames extracted for hd-902843234362370 to: ./frames/hd-902843234362370\n",
      "this is me ./frames/hd-902843234362370\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 105/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-902456848100089\n",
      "filenama hd-902456848100089\n",
      "Video already exists: ./videos/hd-902456848100089\n",
      "Frames extracted for hd-902456848100089 to: ./frames/hd-902456848100089\n",
      "this is me ./frames/hd-902456848100089\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-902456848100089/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-902456848100089/face_1.npy\n",
      "Processing row 106/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-902309670925392\n",
      "filenama hd-902309670925392\n",
      "Video already exists: ./videos/hd-902309670925392\n",
      "Frames extracted for hd-902309670925392 to: ./frames/hd-902309670925392\n",
      "this is me ./frames/hd-902309670925392\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 107/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-9020567984620018\n",
      "filenama hd-9020567984620018\n",
      "Video already exists: ./videos/hd-9020567984620018\n",
      "Frames extracted for hd-9020567984620018 to: ./frames/hd-9020567984620018\n",
      "this is me ./frames/hd-9020567984620018\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 108/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-901695498551491\n",
      "filenama hd-901695498551491\n",
      "Video already exists: ./videos/hd-901695498551491\n",
      "Frames extracted for hd-901695498551491 to: ./frames/hd-901695498551491\n",
      "this is me ./frames/hd-901695498551491\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 109/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-901272811190482\n",
      "filenama hd-901272811190482\n",
      "Video already exists: ./videos/hd-901272811190482\n",
      "Frames extracted for hd-901272811190482 to: ./frames/hd-901272811190482\n",
      "this is me ./frames/hd-901272811190482\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 110/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-899987727789409\n",
      "filenama hd-899987727789409\n",
      "Video already exists: ./videos/hd-899987727789409\n",
      "Frames extracted for hd-899987727789409 to: ./frames/hd-899987727789409\n",
      "this is me ./frames/hd-899987727789409\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-899987727789409/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-899987727789409/face_1.npy\n",
      "Processing row 111/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8995485367146316\n",
      "filenama hd-8995485367146316\n",
      "Video already exists: ./videos/hd-8995485367146316\n",
      "Frames extracted for hd-8995485367146316 to: ./frames/hd-8995485367146316\n",
      "this is me ./frames/hd-8995485367146316\n",
      "No faces detected in the video.\n",
      "Processing row 112/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-899155277883965\n",
      "filenama hd-899155277883965\n",
      "Video already exists: ./videos/hd-899155277883965\n",
      "Frames extracted for hd-899155277883965 to: ./frames/hd-899155277883965\n",
      "this is me ./frames/hd-899155277883965\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-899155277883965/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-899155277883965/face_1.npy\n",
      "Processing row 113/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-898967424867870\n",
      "filenama hd-898967424867870\n",
      "Video already exists: ./videos/hd-898967424867870\n",
      "Frames extracted for hd-898967424867870 to: ./frames/hd-898967424867870\n",
      "this is me ./frames/hd-898967424867870\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 114/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-898402801287469\n",
      "filenama hd-898402801287469\n",
      "Video already exists: ./videos/hd-898402801287469\n",
      "Frames extracted for hd-898402801287469 to: ./frames/hd-898402801287469\n",
      "this is me ./frames/hd-898402801287469\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-898402801287469/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-898402801287469/face_1.npy\n",
      "Processing row 115/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-898103501380741\n",
      "filenama hd-898103501380741\n",
      "Video already exists: ./videos/hd-898103501380741\n",
      "Frames extracted for hd-898103501380741 to: ./frames/hd-898103501380741\n",
      "this is me ./frames/hd-898103501380741\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 116/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-897680994566577\n",
      "filenama hd-897680994566577\n",
      "Video already exists: ./videos/hd-897680994566577\n",
      "Frames extracted for hd-897680994566577 to: ./frames/hd-897680994566577\n",
      "this is me ./frames/hd-897680994566577\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-897680994566577/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-897680994566577/face_1.npy\n",
      "Processing row 117/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-897088088160051\n",
      "filenama hd-897088088160051\n",
      "Video already exists: ./videos/hd-897088088160051\n",
      "Frames extracted for hd-897088088160051 to: ./frames/hd-897088088160051\n",
      "this is me ./frames/hd-897088088160051\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 118/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-896843165102015\n",
      "filenama hd-896843165102015\n",
      "Video already exists: ./videos/hd-896843165102015\n",
      "Frames extracted for hd-896843165102015 to: ./frames/hd-896843165102015\n",
      "this is me ./frames/hd-896843165102015\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-896843165102015/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-896843165102015/face_1.npy\n",
      "Processing row 119/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-896598988012982\n",
      "filenama hd-896598988012982\n",
      "Video already exists: ./videos/hd-896598988012982\n",
      "Frames extracted for hd-896598988012982 to: ./frames/hd-896598988012982\n",
      "this is me ./frames/hd-896598988012982\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-896598988012982/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-896598988012982/face_1.npy\n",
      "Processing row 120/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-896589688256009\n",
      "filenama hd-896589688256009\n",
      "Video already exists: ./videos/hd-896589688256009\n",
      "Frames extracted for hd-896589688256009 to: ./frames/hd-896589688256009\n",
      "this is me ./frames/hd-896589688256009\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 121/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-895042408159688\n",
      "filenama hd-895042408159688\n",
      "Video already exists: ./videos/hd-895042408159688\n",
      "Frames extracted for hd-895042408159688 to: ./frames/hd-895042408159688\n",
      "this is me ./frames/hd-895042408159688\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 122/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-894559812351386\n",
      "filenama hd-894559812351386\n",
      "Video already exists: ./videos/hd-894559812351386\n",
      "Frames extracted for hd-894559812351386 to: ./frames/hd-894559812351386\n",
      "this is me ./frames/hd-894559812351386\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 123/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-894559522288371\n",
      "filenama hd-894559522288371\n",
      "Video already exists: ./videos/hd-894559522288371\n",
      "Frames extracted for hd-894559522288371 to: ./frames/hd-894559522288371\n",
      "this is me ./frames/hd-894559522288371\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-894559522288371/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-894559522288371/face_1.npy\n",
      "Processing row 124/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-894457734962164\n",
      "filenama hd-894457734962164\n",
      "Video already exists: ./videos/hd-894457734962164\n",
      "Frames extracted for hd-894457734962164 to: ./frames/hd-894457734962164\n",
      "this is me ./frames/hd-894457734962164\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 125/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-894066258497958\n",
      "filenama hd-894066258497958\n",
      "Video already exists: ./videos/hd-894066258497958\n",
      "Frames extracted for hd-894066258497958 to: ./frames/hd-894066258497958\n",
      "this is me ./frames/hd-894066258497958\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 126/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-893539262677484\n",
      "filenama hd-893539262677484\n",
      "Video already exists: ./videos/hd-893539262677484\n",
      "Frames extracted for hd-893539262677484 to: ./frames/hd-893539262677484\n",
      "this is me ./frames/hd-893539262677484\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 127/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-893173505441981\n",
      "filenama hd-893173505441981\n",
      "Video already exists: ./videos/hd-893173505441981\n",
      "Frames extracted for hd-893173505441981 to: ./frames/hd-893173505441981\n",
      "this is me ./frames/hd-893173505441981\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 128/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-892383375224287\n",
      "filenama hd-892383375224287\n",
      "Video already exists: ./videos/hd-892383375224287\n",
      "Frames extracted for hd-892383375224287 to: ./frames/hd-892383375224287\n",
      "this is me ./frames/hd-892383375224287\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 129/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-891684945300160\n",
      "filenama hd-891684945300160\n",
      "Video already exists: ./videos/hd-891684945300160\n",
      "Frames extracted for hd-891684945300160 to: ./frames/hd-891684945300160\n",
      "this is me ./frames/hd-891684945300160\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-891684945300160/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-891684945300160/face_1.npy\n",
      "Processing row 130/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-891661008828094\n",
      "filenama hd-891661008828094\n",
      "Video already exists: ./videos/hd-891661008828094\n",
      "Frames extracted for hd-891661008828094 to: ./frames/hd-891661008828094\n",
      "this is me ./frames/hd-891661008828094\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 131/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-891391212618023\n",
      "filenama hd-891391212618023\n",
      "Video already exists: ./videos/hd-891391212618023\n",
      "Frames extracted for hd-891391212618023 to: ./frames/hd-891391212618023\n",
      "this is me ./frames/hd-891391212618023\n",
      "No faces detected in the video.\n",
      "Processing row 132/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-890166872024685\n",
      "filenama hd-890166872024685\n",
      "Video already exists: ./videos/hd-890166872024685\n",
      "Frames extracted for hd-890166872024685 to: ./frames/hd-890166872024685\n",
      "this is me ./frames/hd-890166872024685\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 133/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-890005255637433\n",
      "filenama hd-890005255637433\n",
      "Video already exists: ./videos/hd-890005255637433\n",
      "Frames extracted for hd-890005255637433 to: ./frames/hd-890005255637433\n",
      "this is me ./frames/hd-890005255637433\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-890005255637433/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-890005255637433/face_1.npy\n",
      "Processing row 134/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-889728479746704\n",
      "filenama hd-889728479746704\n",
      "Video already exists: ./videos/hd-889728479746704\n",
      "Frames extracted for hd-889728479746704 to: ./frames/hd-889728479746704\n",
      "this is me ./frames/hd-889728479746704\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 135/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-889604775414234\n",
      "filenama hd-889604775414234\n",
      "Video already exists: ./videos/hd-889604775414234\n",
      "Frames extracted for hd-889604775414234 to: ./frames/hd-889604775414234\n",
      "this is me ./frames/hd-889604775414234\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-889604775414234/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-889604775414234/face_1.npy\n",
      "Processing row 136/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-889375178765113\n",
      "filenama hd-889375178765113\n",
      "Video already exists: ./videos/hd-889375178765113\n",
      "Frames extracted for hd-889375178765113 to: ./frames/hd-889375178765113\n",
      "this is me ./frames/hd-889375178765113\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-889375178765113/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-889375178765113/face_1.npy\n",
      "Processing row 137/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-888593019388197\n",
      "filenama hd-888593019388197\n",
      "Video already exists: ./videos/hd-888593019388197\n",
      "Frames extracted for hd-888593019388197 to: ./frames/hd-888593019388197\n",
      "this is me ./frames/hd-888593019388197\n",
      "No faces detected in the video.\n",
      "Processing row 138/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-888183703182855\n",
      "filenama hd-888183703182855\n",
      "Video already exists: ./videos/hd-888183703182855\n",
      "Frames extracted for hd-888183703182855 to: ./frames/hd-888183703182855\n",
      "this is me ./frames/hd-888183703182855\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-888183703182855/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-888183703182855/face_1.npy\n",
      "Processing row 139/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-888062106715252\n",
      "filenama hd-888062106715252\n",
      "Video already exists: ./videos/hd-888062106715252\n",
      "Frames extracted for hd-888062106715252 to: ./frames/hd-888062106715252\n",
      "this is me ./frames/hd-888062106715252\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-888062106715252/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-888062106715252/face_1.npy\n",
      "Processing row 140/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-888056015719840\n",
      "filenama hd-888056015719840\n",
      "Video already exists: ./videos/hd-888056015719840\n",
      "Frames extracted for hd-888056015719840 to: ./frames/hd-888056015719840\n",
      "this is me ./frames/hd-888056015719840\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-888056015719840/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-888056015719840/face_1.npy\n",
      "Processing row 141/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-887363366529815\n",
      "filenama hd-887363366529815\n",
      "Video already exists: ./videos/hd-887363366529815\n",
      "Frames extracted for hd-887363366529815 to: ./frames/hd-887363366529815\n",
      "this is me ./frames/hd-887363366529815\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-887363366529815/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-887363366529815/face_1.npy\n",
      "Processing row 142/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-886609482926268\n",
      "filenama hd-886609482926268\n",
      "Video already exists: ./videos/hd-886609482926268\n",
      "Frames extracted for hd-886609482926268 to: ./frames/hd-886609482926268\n",
      "this is me ./frames/hd-886609482926268\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-886609482926268/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-886609482926268/face_1.npy\n",
      "Processing row 143/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-886049645973007\n",
      "filenama hd-886049645973007\n",
      "Video already exists: ./videos/hd-886049645973007\n",
      "Frames extracted for hd-886049645973007 to: ./frames/hd-886049645973007\n",
      "this is me ./frames/hd-886049645973007\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-886049645973007/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-886049645973007/face_1.npy\n",
      "Processing row 144/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-885689066019680\n",
      "filenama hd-885689066019680\n",
      "Video already exists: ./videos/hd-885689066019680\n",
      "Frames extracted for hd-885689066019680 to: ./frames/hd-885689066019680\n",
      "this is me ./frames/hd-885689066019680\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 145/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-885670366433640\n",
      "filenama hd-885670366433640\n",
      "Video already exists: ./videos/hd-885670366433640\n",
      "Frames extracted for hd-885670366433640 to: ./frames/hd-885670366433640\n",
      "this is me ./frames/hd-885670366433640\n",
      "No faces detected in the video.\n",
      "Processing row 146/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-885209946993560\n",
      "filenama hd-885209946993560\n",
      "Video already exists: ./videos/hd-885209946993560\n",
      "Frames extracted for hd-885209946993560 to: ./frames/hd-885209946993560\n",
      "this is me ./frames/hd-885209946993560\n",
      "No faces detected in the video.\n",
      "Processing row 147/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-883738210384679\n",
      "filenama hd-883738210384679\n",
      "Video already exists: ./videos/hd-883738210384679\n",
      "Frames extracted for hd-883738210384679 to: ./frames/hd-883738210384679\n",
      "this is me ./frames/hd-883738210384679\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-883738210384679/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-883738210384679/face_1.npy\n",
      "Processing row 148/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-883246492824014\n",
      "filenama hd-883246492824014\n",
      "Video already exists: ./videos/hd-883246492824014\n",
      "Frames extracted for hd-883246492824014 to: ./frames/hd-883246492824014\n",
      "this is me ./frames/hd-883246492824014\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-883246492824014/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-883246492824014/face_1.npy\n",
      "Processing row 149/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-882993126248062\n",
      "filenama hd-882993126248062\n",
      "Video already exists: ./videos/hd-882993126248062\n",
      "Frames extracted for hd-882993126248062 to: ./frames/hd-882993126248062\n",
      "this is me ./frames/hd-882993126248062\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 150/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8828692983838031\n",
      "filenama hd-8828692983838031\n",
      "Video already exists: ./videos/hd-8828692983838031\n",
      "Frames extracted for hd-8828692983838031 to: ./frames/hd-8828692983838031\n",
      "this is me ./frames/hd-8828692983838031\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-8828692983838031/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-8828692983838031/face_1.npy\n",
      "Processing row 151/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-882867522830120\n",
      "filenama hd-882867522830120\n",
      "Video already exists: ./videos/hd-882867522830120\n",
      "Frames extracted for hd-882867522830120 to: ./frames/hd-882867522830120\n",
      "this is me ./frames/hd-882867522830120\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 152/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-882019143545185\n",
      "filenama hd-882019143545185\n",
      "Video already exists: ./videos/hd-882019143545185\n",
      "Frames extracted for hd-882019143545185 to: ./frames/hd-882019143545185\n",
      "this is me ./frames/hd-882019143545185\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 153/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-881925359723909\n",
      "filenama hd-881925359723909\n",
      "Video already exists: ./videos/hd-881925359723909\n",
      "Frames extracted for hd-881925359723909 to: ./frames/hd-881925359723909\n",
      "this is me ./frames/hd-881925359723909\n",
      "No faces detected in the video.\n",
      "Processing row 154/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8816515918390519\n",
      "filenama hd-8816515918390519\n",
      "Video already exists: ./videos/hd-8816515918390519\n",
      "Frames extracted for hd-8816515918390519 to: ./frames/hd-8816515918390519\n",
      "this is me ./frames/hd-8816515918390519\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-8816515918390519/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-8816515918390519/face_1.npy\n",
      "Processing row 155/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-881342303358042\n",
      "filenama hd-881342303358042\n",
      "Video already exists: ./videos/hd-881342303358042\n",
      "Frames extracted for hd-881342303358042 to: ./frames/hd-881342303358042\n",
      "this is me ./frames/hd-881342303358042\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 156/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-881270063889884\n",
      "filenama hd-881270063889884\n",
      "Video already exists: ./videos/hd-881270063889884\n",
      "Frames extracted for hd-881270063889884 to: ./frames/hd-881270063889884\n",
      "this is me ./frames/hd-881270063889884\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-881270063889884/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-881270063889884/face_1.npy\n",
      "Processing row 157/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8806609246079208\n",
      "filenama hd-8806609246079208\n",
      "Video already exists: ./videos/hd-8806609246079208\n",
      "Frames extracted for hd-8806609246079208 to: ./frames/hd-8806609246079208\n",
      "this is me ./frames/hd-8806609246079208\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 158/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-880568190186256\n",
      "filenama hd-880568190186256\n",
      "Video already exists: ./videos/hd-880568190186256\n",
      "Frames extracted for hd-880568190186256 to: ./frames/hd-880568190186256\n",
      "this is me ./frames/hd-880568190186256\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 159/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-880340126836307\n",
      "filenama hd-880340126836307\n",
      "Video already exists: ./videos/hd-880340126836307\n",
      "Frames extracted for hd-880340126836307 to: ./frames/hd-880340126836307\n",
      "this is me ./frames/hd-880340126836307\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 160/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8796411607036992\n",
      "filenama hd-8796411607036992\n",
      "Video already exists: ./videos/hd-8796411607036992\n",
      "Frames extracted for hd-8796411607036992 to: ./frames/hd-8796411607036992\n",
      "this is me ./frames/hd-8796411607036992\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 161/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-879631723735807\n",
      "filenama hd-879631723735807\n",
      "Video already exists: ./videos/hd-879631723735807\n",
      "Frames extracted for hd-879631723735807 to: ./frames/hd-879631723735807\n",
      "this is me ./frames/hd-879631723735807\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 162/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-879049300656635\n",
      "filenama hd-879049300656635\n",
      "Video already exists: ./videos/hd-879049300656635\n",
      "Frames extracted for hd-879049300656635 to: ./frames/hd-879049300656635\n",
      "this is me ./frames/hd-879049300656635\n",
      "No faces detected in the video.\n",
      "Processing row 163/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-877975993416760\n",
      "filenama hd-877975993416760\n",
      "Video already exists: ./videos/hd-877975993416760\n",
      "Frames extracted for hd-877975993416760 to: ./frames/hd-877975993416760\n",
      "this is me ./frames/hd-877975993416760\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 164/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-877662697022279\n",
      "filenama hd-877662697022279\n",
      "Video already exists: ./videos/hd-877662697022279\n",
      "Frames extracted for hd-877662697022279 to: ./frames/hd-877662697022279\n",
      "this is me ./frames/hd-877662697022279\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 165/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-877511836784655\n",
      "filenama hd-877511836784655\n",
      "Video already exists: ./videos/hd-877511836784655\n",
      "Frames extracted for hd-877511836784655 to: ./frames/hd-877511836784655\n",
      "this is me ./frames/hd-877511836784655\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 166/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-877210454387561\n",
      "filenama hd-877210454387561\n",
      "Video already exists: ./videos/hd-877210454387561\n",
      "Frames extracted for hd-877210454387561 to: ./frames/hd-877210454387561\n",
      "this is me ./frames/hd-877210454387561\n",
      "No faces detected in the video.\n",
      "Processing row 167/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-877129693575192\n",
      "filenama hd-877129693575192\n",
      "Video already exists: ./videos/hd-877129693575192\n",
      "Frames extracted for hd-877129693575192 to: ./frames/hd-877129693575192\n",
      "this is me ./frames/hd-877129693575192\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 168/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-876239523982490\n",
      "filenama hd-876239523982490\n",
      "Video already exists: ./videos/hd-876239523982490\n",
      "Frames extracted for hd-876239523982490 to: ./frames/hd-876239523982490\n",
      "this is me ./frames/hd-876239523982490\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-876239523982490/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-876239523982490/face_1.npy\n",
      "Processing row 169/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-876121221160846\n",
      "filenama hd-876121221160846\n",
      "Video already exists: ./videos/hd-876121221160846\n",
      "Frames extracted for hd-876121221160846 to: ./frames/hd-876121221160846\n",
      "this is me ./frames/hd-876121221160846\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-876121221160846/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-876121221160846/face_1.npy\n",
      "Processing row 170/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-875485623676104\n",
      "filenama hd-875485623676104\n",
      "Video already exists: ./videos/hd-875485623676104\n",
      "Frames extracted for hd-875485623676104 to: ./frames/hd-875485623676104\n",
      "this is me ./frames/hd-875485623676104\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 171/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-874864704574925\n",
      "filenama hd-874864704574925\n",
      "Video already exists: ./videos/hd-874864704574925\n",
      "Frames extracted for hd-874864704574925 to: ./frames/hd-874864704574925\n",
      "this is me ./frames/hd-874864704574925\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-874864704574925/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-874864704574925/face_1.npy\n",
      "Processing row 172/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-874747697073121\n",
      "filenama hd-874747697073121\n",
      "Video already exists: ./videos/hd-874747697073121\n",
      "Frames extracted for hd-874747697073121 to: ./frames/hd-874747697073121\n",
      "this is me ./frames/hd-874747697073121\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 173/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-874543520932484\n",
      "filenama hd-874543520932484\n",
      "Video already exists: ./videos/hd-874543520932484\n",
      "Frames extracted for hd-874543520932484 to: ./frames/hd-874543520932484\n",
      "this is me ./frames/hd-874543520932484\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 174/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-874190910572544\n",
      "filenama hd-874190910572544\n",
      "Video already exists: ./videos/hd-874190910572544\n",
      "Frames extracted for hd-874190910572544 to: ./frames/hd-874190910572544\n",
      "this is me ./frames/hd-874190910572544\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 175/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-874084244131796\n",
      "filenama hd-874084244131796\n",
      "Video already exists: ./videos/hd-874084244131796\n",
      "Frames extracted for hd-874084244131796 to: ./frames/hd-874084244131796\n",
      "this is me ./frames/hd-874084244131796\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 176/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-873560550525047\n",
      "filenama hd-873560550525047\n",
      "Video already exists: ./videos/hd-873560550525047\n",
      "Frames extracted for hd-873560550525047 to: ./frames/hd-873560550525047\n",
      "this is me ./frames/hd-873560550525047\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 177/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-873317140849832\n",
      "filenama hd-873317140849832\n",
      "Video already exists: ./videos/hd-873317140849832\n",
      "Frames extracted for hd-873317140849832 to: ./frames/hd-873317140849832\n",
      "this is me ./frames/hd-873317140849832\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-873317140849832/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-873317140849832/face_1.npy\n",
      "Processing row 178/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-873043573965895\n",
      "filenama hd-873043573965895\n",
      "Video already exists: ./videos/hd-873043573965895\n",
      "Frames extracted for hd-873043573965895 to: ./frames/hd-873043573965895\n",
      "this is me ./frames/hd-873043573965895\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 179/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-872760463806517\n",
      "filenama hd-872760463806517\n",
      "Video already exists: ./videos/hd-872760463806517\n",
      "Frames extracted for hd-872760463806517 to: ./frames/hd-872760463806517\n",
      "this is me ./frames/hd-872760463806517\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 180/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-872400620956045\n",
      "filenama hd-872400620956045\n",
      "Video already exists: ./videos/hd-872400620956045\n",
      "Frames extracted for hd-872400620956045 to: ./frames/hd-872400620956045\n",
      "this is me ./frames/hd-872400620956045\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 181/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-872222594086011\n",
      "filenama hd-872222594086011\n",
      "Video already exists: ./videos/hd-872222594086011\n",
      "Frames extracted for hd-872222594086011 to: ./frames/hd-872222594086011\n",
      "this is me ./frames/hd-872222594086011\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 182/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-872188860590219\n",
      "filenama hd-872188860590219\n",
      "Video already exists: ./videos/hd-872188860590219\n",
      "Frames extracted for hd-872188860590219 to: ./frames/hd-872188860590219\n",
      "this is me ./frames/hd-872188860590219\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-872188860590219/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-872188860590219/face_1.npy\n",
      "Processing row 183/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-871981848375866\n",
      "filenama hd-871981848375866\n",
      "Video already exists: ./videos/hd-871981848375866\n",
      "Frames extracted for hd-871981848375866 to: ./frames/hd-871981848375866\n",
      "this is me ./frames/hd-871981848375866\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-871981848375866/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-871981848375866/face_1.npy\n",
      "Processing row 184/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8715627171842855\n",
      "filenama hd-8715627171842855\n",
      "Video already exists: ./videos/hd-8715627171842855\n",
      "Frames extracted for hd-8715627171842855 to: ./frames/hd-8715627171842855\n",
      "this is me ./frames/hd-8715627171842855\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 185/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-871286287458461\n",
      "filenama hd-871286287458461\n",
      "Video already exists: ./videos/hd-871286287458461\n",
      "Frames extracted for hd-871286287458461 to: ./frames/hd-871286287458461\n",
      "this is me ./frames/hd-871286287458461\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 186/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-871185627435460\n",
      "filenama hd-871185627435460\n",
      "Video already exists: ./videos/hd-871185627435460\n",
      "Frames extracted for hd-871185627435460 to: ./frames/hd-871185627435460\n",
      "this is me ./frames/hd-871185627435460\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 187/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-871075730546911\n",
      "filenama hd-871075730546911\n",
      "Video already exists: ./videos/hd-871075730546911\n",
      "Frames extracted for hd-871075730546911 to: ./frames/hd-871075730546911\n",
      "this is me ./frames/hd-871075730546911\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-871075730546911/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-871075730546911/face_1.npy\n",
      "Processing row 188/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-871037203883530\n",
      "filenama hd-871037203883530\n",
      "Video already exists: ./videos/hd-871037203883530\n",
      "Frames extracted for hd-871037203883530 to: ./frames/hd-871037203883530\n",
      "this is me ./frames/hd-871037203883530\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-871037203883530/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-871037203883530/face_1.npy\n",
      "Processing row 189/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-819765763526762\n",
      "filenama hd-819765763526762\n",
      "Video already exists: ./videos/hd-819765763526762\n",
      "Frames extracted for hd-819765763526762 to: ./frames/hd-819765763526762\n",
      "this is me ./frames/hd-819765763526762\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-819765763526762/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-819765763526762/face_1.npy\n",
      "Processing row 190/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-818776323774715\n",
      "filenama hd-818776323774715\n",
      "Video already exists: ./videos/hd-818776323774715\n",
      "Frames extracted for hd-818776323774715 to: ./frames/hd-818776323774715\n",
      "this is me ./frames/hd-818776323774715\n",
      "No faces detected in the video.\n",
      "Processing row 191/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-818462803696191\n",
      "filenama hd-818462803696191\n",
      "Video already exists: ./videos/hd-818462803696191\n",
      "Frames extracted for hd-818462803696191 to: ./frames/hd-818462803696191\n",
      "this is me ./frames/hd-818462803696191\n",
      "No faces detected in the video.\n",
      "Processing row 192/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-817768845898837\n",
      "filenama hd-817768845898837\n",
      "Video already exists: ./videos/hd-817768845898837\n",
      "Frames extracted for hd-817768845898837 to: ./frames/hd-817768845898837\n",
      "this is me ./frames/hd-817768845898837\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-817768845898837/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-817768845898837/face_1.npy\n",
      "Processing row 193/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-817763467176157\n",
      "filenama hd-817763467176157\n",
      "Video already exists: ./videos/hd-817763467176157\n",
      "Frames extracted for hd-817763467176157 to: ./frames/hd-817763467176157\n",
      "this is me ./frames/hd-817763467176157\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 194/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-817477363934899\n",
      "filenama hd-817477363934899\n",
      "Video already exists: ./videos/hd-817477363934899\n",
      "Frames extracted for hd-817477363934899 to: ./frames/hd-817477363934899\n",
      "this is me ./frames/hd-817477363934899\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-817477363934899/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-817477363934899/face_1.npy\n",
      "Processing row 195/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-817475239730695\n",
      "filenama hd-817475239730695\n",
      "Video already exists: ./videos/hd-817475239730695\n",
      "Frames extracted for hd-817475239730695 to: ./frames/hd-817475239730695\n",
      "this is me ./frames/hd-817475239730695\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 196/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-817135236672734\n",
      "filenama hd-817135236672734\n",
      "Video already exists: ./videos/hd-817135236672734\n",
      "Frames extracted for hd-817135236672734 to: ./frames/hd-817135236672734\n",
      "this is me ./frames/hd-817135236672734\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 197/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-816335920524988\n",
      "filenama hd-816335920524988\n",
      "Video already exists: ./videos/hd-816335920524988\n",
      "Frames extracted for hd-816335920524988 to: ./frames/hd-816335920524988\n",
      "this is me ./frames/hd-816335920524988\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 198/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-815391233916449\n",
      "filenama hd-815391233916449\n",
      "Video already exists: ./videos/hd-815391233916449\n",
      "Frames extracted for hd-815391233916449 to: ./frames/hd-815391233916449\n",
      "this is me ./frames/hd-815391233916449\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-815391233916449/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-815391233916449/face_1.npy\n",
      "Processing row 199/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-814072014151046\n",
      "filenama hd-814072014151046\n",
      "Video already exists: ./videos/hd-814072014151046\n",
      "Frames extracted for hd-814072014151046 to: ./frames/hd-814072014151046\n",
      "this is me ./frames/hd-814072014151046\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 200/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-813828049840959\n",
      "filenama hd-813828049840959\n",
      "Video already exists: ./videos/hd-813828049840959\n",
      "Frames extracted for hd-813828049840959 to: ./frames/hd-813828049840959\n",
      "this is me ./frames/hd-813828049840959\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-813828049840959/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-813828049840959/face_1.npy\n",
      "Processing row 201/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-811606650922029\n",
      "filenama hd-811606650922029\n",
      "Video already exists: ./videos/hd-811606650922029\n",
      "Frames extracted for hd-811606650922029 to: ./frames/hd-811606650922029\n",
      "this is me ./frames/hd-811606650922029\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 202/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8111507755613955\n",
      "filenama hd-8111507755613955\n",
      "Video already exists: ./videos/hd-8111507755613955\n",
      "Frames extracted for hd-8111507755613955 to: ./frames/hd-8111507755613955\n",
      "this is me ./frames/hd-8111507755613955\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 203/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8100667816697710\n",
      "filenama hd-8100667816697710\n",
      "Video already exists: ./videos/hd-8100667816697710\n",
      "Frames extracted for hd-8100667816697710 to: ./frames/hd-8100667816697710\n",
      "this is me ./frames/hd-8100667816697710\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 204/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-809480737932683\n",
      "filenama hd-809480737932683\n",
      "Video already exists: ./videos/hd-809480737932683\n",
      "Frames extracted for hd-809480737932683 to: ./frames/hd-809480737932683\n",
      "this is me ./frames/hd-809480737932683\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 205/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-808321904744283\n",
      "filenama hd-808321904744283\n",
      "Video already exists: ./videos/hd-808321904744283\n",
      "Frames extracted for hd-808321904744283 to: ./frames/hd-808321904744283\n",
      "this is me ./frames/hd-808321904744283\n",
      "No faces detected in the video.\n",
      "Processing row 206/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-808097524590260\n",
      "filenama hd-808097524590260\n",
      "Video already exists: ./videos/hd-808097524590260\n",
      "Frames extracted for hd-808097524590260 to: ./frames/hd-808097524590260\n",
      "this is me ./frames/hd-808097524590260\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-808097524590260/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-808097524590260/face_1.npy\n",
      "Processing row 207/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-807800198130528\n",
      "filenama hd-807800198130528\n",
      "Video already exists: ./videos/hd-807800198130528\n",
      "Frames extracted for hd-807800198130528 to: ./frames/hd-807800198130528\n",
      "this is me ./frames/hd-807800198130528\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 208/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-806751788307038\n",
      "filenama hd-806751788307038\n",
      "Video already exists: ./videos/hd-806751788307038\n",
      "Frames extracted for hd-806751788307038 to: ./frames/hd-806751788307038\n",
      "this is me ./frames/hd-806751788307038\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-806751788307038/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-806751788307038/face_1.npy\n",
      "Processing row 209/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8057957437624799\n",
      "filenama hd-8057957437624799\n",
      "Video already exists: ./videos/hd-8057957437624799\n",
      "Frames extracted for hd-8057957437624799 to: ./frames/hd-8057957437624799\n",
      "this is me ./frames/hd-8057957437624799\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 210/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-803990118540094\n",
      "filenama hd-803990118540094\n",
      "Video already exists: ./videos/hd-803990118540094\n",
      "Frames extracted for hd-803990118540094 to: ./frames/hd-803990118540094\n",
      "this is me ./frames/hd-803990118540094\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-803990118540094/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-803990118540094/face_1.npy\n",
      "Processing row 211/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-803897110603133\n",
      "filenama hd-803897110603133\n",
      "Video already exists: ./videos/hd-803897110603133\n",
      "Frames extracted for hd-803897110603133 to: ./frames/hd-803897110603133\n",
      "this is me ./frames/hd-803897110603133\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 212/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-802443478544141\n",
      "filenama hd-802443478544141\n",
      "Video already exists: ./videos/hd-802443478544141\n",
      "Frames extracted for hd-802443478544141 to: ./frames/hd-802443478544141\n",
      "this is me ./frames/hd-802443478544141\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 213/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8008073409211713\n",
      "filenama hd-8008073409211713\n",
      "Video already exists: ./videos/hd-8008073409211713\n",
      "Frames extracted for hd-8008073409211713 to: ./frames/hd-8008073409211713\n",
      "this is me ./frames/hd-8008073409211713\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-8008073409211713/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-8008073409211713/face_1.npy\n",
      "Processing row 214/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-7995631707140182\n",
      "filenama hd-7995631707140182\n",
      "Video already exists: ./videos/hd-7995631707140182\n",
      "Frames extracted for hd-7995631707140182 to: ./frames/hd-7995631707140182\n",
      "this is me ./frames/hd-7995631707140182\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 215/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-797179088937277\n",
      "filenama hd-797179088937277\n",
      "Video already exists: ./videos/hd-797179088937277\n",
      "Frames extracted for hd-797179088937277 to: ./frames/hd-797179088937277\n",
      "this is me ./frames/hd-797179088937277\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 216/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-797024995612413\n",
      "filenama hd-797024995612413\n",
      "Video already exists: ./videos/hd-797024995612413\n",
      "Frames extracted for hd-797024995612413 to: ./frames/hd-797024995612413\n",
      "this is me ./frames/hd-797024995612413\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-797024995612413/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-797024995612413/face_1.npy\n",
      "Processing row 217/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-796944101940903\n",
      "filenama hd-796944101940903\n",
      "Video already exists: ./videos/hd-796944101940903\n",
      "Frames extracted for hd-796944101940903 to: ./frames/hd-796944101940903\n",
      "this is me ./frames/hd-796944101940903\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-796944101940903/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-796944101940903/face_1.npy\n",
      "Processing row 218/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-793257836073148\n",
      "filenama hd-793257836073148\n",
      "Video already exists: ./videos/hd-793257836073148\n",
      "Frames extracted for hd-793257836073148 to: ./frames/hd-793257836073148\n",
      "this is me ./frames/hd-793257836073148\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-793257836073148/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-793257836073148/face_1.npy\n",
      "Processing row 219/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-791572172961239\n",
      "filenama hd-791572172961239\n",
      "Video already exists: ./videos/hd-791572172961239\n",
      "Frames extracted for hd-791572172961239 to: ./frames/hd-791572172961239\n",
      "this is me ./frames/hd-791572172961239\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-791572172961239/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-791572172961239/face_1.npy\n",
      "Processing row 220/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-790055392972248\n",
      "filenama hd-790055392972248\n",
      "Video already exists: ./videos/hd-790055392972248\n",
      "Frames extracted for hd-790055392972248 to: ./frames/hd-790055392972248\n",
      "this is me ./frames/hd-790055392972248\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-790055392972248/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-790055392972248/face_1.npy\n",
      "Processing row 221/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-789793989900194\n",
      "filenama hd-789793989900194\n",
      "Video already exists: ./videos/hd-789793989900194\n",
      "Frames extracted for hd-789793989900194 to: ./frames/hd-789793989900194\n",
      "this is me ./frames/hd-789793989900194\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 222/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-789715035654710\n",
      "filenama hd-789715035654710\n",
      "Video already exists: ./videos/hd-789715035654710\n",
      "Frames extracted for hd-789715035654710 to: ./frames/hd-789715035654710\n",
      "this is me ./frames/hd-789715035654710\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-789715035654710/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-789715035654710/face_1.npy\n",
      "Processing row 223/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-786610583313461\n",
      "filenama hd-786610583313461\n",
      "Video already exists: ./videos/hd-786610583313461\n",
      "Frames extracted for hd-786610583313461 to: ./frames/hd-786610583313461\n",
      "this is me ./frames/hd-786610583313461\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 224/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-696006115320413\n",
      "filenama hd-696006115320413\n",
      "Video already exists: ./videos/hd-696006115320413\n",
      "Frames extracted for hd-696006115320413 to: ./frames/hd-696006115320413\n",
      "this is me ./frames/hd-696006115320413\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-696006115320413/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-696006115320413/face_1.npy\n",
      "Processing row 225/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-695130362192250\n",
      "filenama hd-695130362192250\n",
      "Video already exists: ./videos/hd-695130362192250\n",
      "Frames extracted for hd-695130362192250 to: ./frames/hd-695130362192250\n",
      "this is me ./frames/hd-695130362192250\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-695130362192250/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-695130362192250/face_1.npy\n",
      "Processing row 226/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-694675672308301\n",
      "filenama hd-694675672308301\n",
      "Video already exists: ./videos/hd-694675672308301\n",
      "Frames extracted for hd-694675672308301 to: ./frames/hd-694675672308301\n",
      "this is me ./frames/hd-694675672308301\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 227/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-693988272279384\n",
      "filenama hd-693988272279384\n",
      "Video already exists: ./videos/hd-693988272279384\n",
      "Frames extracted for hd-693988272279384 to: ./frames/hd-693988272279384\n",
      "this is me ./frames/hd-693988272279384\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-693988272279384/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-693988272279384/face_1.npy\n",
      "Processing row 228/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-691857912087615\n",
      "filenama hd-691857912087615\n",
      "Video already exists: ./videos/hd-691857912087615\n",
      "Frames extracted for hd-691857912087615 to: ./frames/hd-691857912087615\n",
      "this is me ./frames/hd-691857912087615\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-691857912087615/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-691857912087615/face_1.npy\n",
      "Processing row 229/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-691581235967071\n",
      "filenama hd-691581235967071\n",
      "Video already exists: ./videos/hd-691581235967071\n",
      "Frames extracted for hd-691581235967071 to: ./frames/hd-691581235967071\n",
      "this is me ./frames/hd-691581235967071\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 230/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-691252805779835\n",
      "filenama hd-691252805779835\n",
      "Video already exists: ./videos/hd-691252805779835\n",
      "Frames extracted for hd-691252805779835 to: ./frames/hd-691252805779835\n",
      "this is me ./frames/hd-691252805779835\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-691252805779835/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-691252805779835/face_1.npy\n",
      "Processing row 231/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-690670309134450\n",
      "filenama hd-690670309134450\n",
      "Video already exists: ./videos/hd-690670309134450\n",
      "Frames extracted for hd-690670309134450 to: ./frames/hd-690670309134450\n",
      "this is me ./frames/hd-690670309134450\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-690670309134450/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-690670309134450/face_1.npy\n",
      "Processing row 232/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-690541956158254\n",
      "filenama hd-690541956158254\n",
      "Video already exists: ./videos/hd-690541956158254\n",
      "Frames extracted for hd-690541956158254 to: ./frames/hd-690541956158254\n",
      "this is me ./frames/hd-690541956158254\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 233/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-689771035910864\n",
      "filenama hd-689771035910864\n",
      "Video already exists: ./videos/hd-689771035910864\n",
      "Frames extracted for hd-689771035910864 to: ./frames/hd-689771035910864\n",
      "this is me ./frames/hd-689771035910864\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-689771035910864/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-689771035910864/face_1.npy\n",
      "Processing row 234/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-689599909618915\n",
      "filenama hd-689599909618915\n",
      "Video already exists: ./videos/hd-689599909618915\n",
      "Frames extracted for hd-689599909618915 to: ./frames/hd-689599909618915\n",
      "this is me ./frames/hd-689599909618915\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 235/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-689363059404444\n",
      "filenama hd-689363059404444\n",
      "Video already exists: ./videos/hd-689363059404444\n",
      "Frames extracted for hd-689363059404444 to: ./frames/hd-689363059404444\n",
      "this is me ./frames/hd-689363059404444\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 236/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-688887926060399\n",
      "filenama hd-688887926060399\n",
      "Video already exists: ./videos/hd-688887926060399\n",
      "Frames extracted for hd-688887926060399 to: ./frames/hd-688887926060399\n",
      "this is me ./frames/hd-688887926060399\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-688887926060399/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-688887926060399/face_1.npy\n",
      "Processing row 237/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-687665956347322\n",
      "filenama hd-687665956347322\n",
      "Video already exists: ./videos/hd-687665956347322\n",
      "Frames extracted for hd-687665956347322 to: ./frames/hd-687665956347322\n",
      "this is me ./frames/hd-687665956347322\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 238/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-687024156350870\n",
      "filenama hd-687024156350870\n",
      "Video already exists: ./videos/hd-687024156350870\n",
      "Frames extracted for hd-687024156350870 to: ./frames/hd-687024156350870\n",
      "this is me ./frames/hd-687024156350870\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 239/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-686488653080244\n",
      "filenama hd-686488653080244\n",
      "Video already exists: ./videos/hd-686488653080244\n",
      "Frames extracted for hd-686488653080244 to: ./frames/hd-686488653080244\n",
      "this is me ./frames/hd-686488653080244\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-686488653080244/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-686488653080244/face_1.npy\n",
      "Processing row 240/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-686083626588321\n",
      "filenama hd-686083626588321\n",
      "Video already exists: ./videos/hd-686083626588321\n",
      "Frames extracted for hd-686083626588321 to: ./frames/hd-686083626588321\n",
      "this is me ./frames/hd-686083626588321\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-686083626588321/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-686083626588321/face_1.npy\n",
      "Processing row 241/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-684364333171304\n",
      "filenama hd-684364333171304\n",
      "Video already exists: ./videos/hd-684364333171304\n",
      "Frames extracted for hd-684364333171304 to: ./frames/hd-684364333171304\n",
      "this is me ./frames/hd-684364333171304\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 242/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-684264882912286\n",
      "filenama hd-684264882912286\n",
      "Video already exists: ./videos/hd-684264882912286\n",
      "Frames extracted for hd-684264882912286 to: ./frames/hd-684264882912286\n",
      "this is me ./frames/hd-684264882912286\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-684264882912286/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-684264882912286/face_1.npy\n",
      "Processing row 243/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6837957766319053\n",
      "filenama hd-6837957766319053\n",
      "Video already exists: ./videos/hd-6837957766319053\n",
      "Frames extracted for hd-6837957766319053 to: ./frames/hd-6837957766319053\n",
      "this is me ./frames/hd-6837957766319053\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 244/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-682791943270614\n",
      "filenama hd-682791943270614\n",
      "Video already exists: ./videos/hd-682791943270614\n",
      "Frames extracted for hd-682791943270614 to: ./frames/hd-682791943270614\n",
      "this is me ./frames/hd-682791943270614\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 245/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-682596103528135\n",
      "filenama hd-682596103528135\n",
      "Video already exists: ./videos/hd-682596103528135\n",
      "Frames extracted for hd-682596103528135 to: ./frames/hd-682596103528135\n",
      "this is me ./frames/hd-682596103528135\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-682596103528135/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-682596103528135/face_1.npy\n",
      "Processing row 246/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-680549530054789\n",
      "filenama hd-680549530054789\n",
      "Video already exists: ./videos/hd-680549530054789\n",
      "Frames extracted for hd-680549530054789 to: ./frames/hd-680549530054789\n",
      "this is me ./frames/hd-680549530054789\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-680549530054789/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-680549530054789/face_1.npy\n",
      "Processing row 247/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-680540137074841\n",
      "filenama hd-680540137074841\n",
      "Video already exists: ./videos/hd-680540137074841\n",
      "Frames extracted for hd-680540137074841 to: ./frames/hd-680540137074841\n",
      "this is me ./frames/hd-680540137074841\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 248/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-680162593779089\n",
      "filenama hd-680162593779089\n",
      "Video already exists: ./videos/hd-680162593779089\n",
      "Frames extracted for hd-680162593779089 to: ./frames/hd-680162593779089\n",
      "this is me ./frames/hd-680162593779089\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 249/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-679261516829908\n",
      "filenama hd-679261516829908\n",
      "Video already exists: ./videos/hd-679261516829908\n",
      "Frames extracted for hd-679261516829908 to: ./frames/hd-679261516829908\n",
      "this is me ./frames/hd-679261516829908\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-679261516829908/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-679261516829908/face_1.npy\n",
      "Processing row 250/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-678133704039459\n",
      "filenama hd-678133704039459\n",
      "Video already exists: ./videos/hd-678133704039459\n",
      "Frames extracted for hd-678133704039459 to: ./frames/hd-678133704039459\n",
      "this is me ./frames/hd-678133704039459\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 251/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-676770877464110\n",
      "filenama hd-676770877464110\n",
      "Video already exists: ./videos/hd-676770877464110\n",
      "Frames extracted for hd-676770877464110 to: ./frames/hd-676770877464110\n",
      "this is me ./frames/hd-676770877464110\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 252/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6764280623620361\n",
      "filenama hd-6764280623620361\n",
      "Video already exists: ./videos/hd-6764280623620361\n",
      "Frames extracted for hd-6764280623620361 to: ./frames/hd-6764280623620361\n",
      "this is me ./frames/hd-6764280623620361\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-6764280623620361/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-6764280623620361/face_1.npy\n",
      "Processing row 253/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-673961584214053\n",
      "filenama hd-673961584214053\n",
      "Video already exists: ./videos/hd-673961584214053\n",
      "Frames extracted for hd-673961584214053 to: ./frames/hd-673961584214053\n",
      "this is me ./frames/hd-673961584214053\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 254/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6720438181324436\n",
      "filenama hd-6720438181324436\n",
      "Video already exists: ./videos/hd-6720438181324436\n",
      "Frames extracted for hd-6720438181324436 to: ./frames/hd-6720438181324436\n",
      "this is me ./frames/hd-6720438181324436\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-6720438181324436/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-6720438181324436/face_1.npy\n",
      "Processing row 255/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-671839840899900\n",
      "filenama hd-671839840899900\n",
      "Video already exists: ./videos/hd-671839840899900\n",
      "Frames extracted for hd-671839840899900 to: ./frames/hd-671839840899900\n",
      "this is me ./frames/hd-671839840899900\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 256/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-429145826826558\n",
      "filenama hd-429145826826558\n",
      "Video already exists: ./videos/hd-429145826826558\n",
      "Frames extracted for hd-429145826826558 to: ./frames/hd-429145826826558\n",
      "this is me ./frames/hd-429145826826558\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-429145826826558/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-429145826826558/face_1.npy\n",
      "Processing row 257/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-427878012859864\n",
      "filenama hd-427878012859864\n",
      "Video already exists: ./videos/hd-427878012859864\n",
      "Frames extracted for hd-427878012859864 to: ./frames/hd-427878012859864\n",
      "this is me ./frames/hd-427878012859864\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-427878012859864/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-427878012859864/face_1.npy\n",
      "Processing row 258/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-426644026275739\n",
      "filenama hd-426644026275739\n",
      "Video already exists: ./videos/hd-426644026275739\n",
      "Frames extracted for hd-426644026275739 to: ./frames/hd-426644026275739\n",
      "this is me ./frames/hd-426644026275739\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-426644026275739/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-426644026275739/face_1.npy\n",
      "Processing row 259/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-425151876539382\n",
      "filenama hd-425151876539382\n",
      "Video already exists: ./videos/hd-425151876539382\n",
      "Frames extracted for hd-425151876539382 to: ./frames/hd-425151876539382\n",
      "this is me ./frames/hd-425151876539382\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 260/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-424802420355057\n",
      "filenama hd-424802420355057\n",
      "Video already exists: ./videos/hd-424802420355057\n",
      "Frames extracted for hd-424802420355057 to: ./frames/hd-424802420355057\n",
      "this is me ./frames/hd-424802420355057\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-424802420355057/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-424802420355057/face_1.npy\n",
      "Processing row 261/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-424394867097391\n",
      "filenama hd-424394867097391\n",
      "Video already exists: ./videos/hd-424394867097391\n",
      "Frames extracted for hd-424394867097391 to: ./frames/hd-424394867097391\n",
      "this is me ./frames/hd-424394867097391\n",
      "No faces detected in the video.\n",
      "Processing row 262/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-1698824364241828\n",
      "filenama hd-1698824364241828\n",
      "Video already exists: ./videos/hd-1698824364241828\n",
      "Frames extracted for hd-1698824364241828 to: ./frames/hd-1698824364241828\n",
      "this is me ./frames/hd-1698824364241828\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-1698824364241828/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-1698824364241828/face_1.npy\n",
      "Processing row 263/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-1693566687752051\n",
      "filenama hd-1693566687752051\n",
      "Video already exists: ./videos/hd-1693566687752051\n",
      "Frames extracted for hd-1693566687752051 to: ./frames/hd-1693566687752051\n",
      "this is me ./frames/hd-1693566687752051\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 264/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-1689212771862832\n",
      "filenama hd-1689212771862832\n",
      "Video already exists: ./videos/hd-1689212771862832\n",
      "Frames extracted for hd-1689212771862832 to: ./frames/hd-1689212771862832\n",
      "this is me ./frames/hd-1689212771862832\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 265/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-1685108828975354\n",
      "filenama hd-1685108828975354\n",
      "Video already exists: ./videos/hd-1685108828975354\n",
      "Frames extracted for hd-1685108828975354 to: ./frames/hd-1685108828975354\n",
      "this is me ./frames/hd-1685108828975354\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No faces detected in the video.\n",
      "Processing row 266/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-1119706949586170\n",
      "filenama hd-1119706949586170\n",
      "Video already exists: ./videos/hd-1119706949586170\n",
      "Frames extracted for hd-1119706949586170 to: ./frames/hd-1119706949586170\n",
      "this is me ./frames/hd-1119706949586170\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-1119706949586170/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-1119706949586170/face_1.npy\n",
      "Processing row 267/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-1119272995406354\n",
      "filenama hd-1119272995406354\n",
      "Video already exists: ./videos/hd-1119272995406354\n",
      "Frames extracted for hd-1119272995406354 to: ./frames/hd-1119272995406354\n",
      "this is me ./frames/hd-1119272995406354\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Error processing face: unsupported operand type(s) for -: 'list' and 'list'\n",
      "Most frequent face ID: 1 with 1 occurrences\n",
      "Saved cropped face to: ./faces/hd-1119272995406354/face.jpg\n",
      "Saved face embedding: ./embeddings/hd-1119272995406354/face_1.npy\n",
      "Processing row 268/268: https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-1118763132933218\n",
      "filenama hd-1118763132933218\n",
      "Video already exists: ./videos/hd-1118763132933218\n",
      "Frames extracted for hd-1118763132933218 to: ./frames/hd-1118763132933218\n",
      "this is me ./frames/hd-1118763132933218\n",
      "No faces detected in the video.\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# DataFrame to store videos without faces\n",
    "no_faces_df = pd.DataFrame(columns=[\"Performance\", \"Video URL\"])\n",
    "faces_df=pd.DataFrame(columns=[\"Performance\", \"Video URL\"])\n",
    "\n",
    "# Iterate through the dataset\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Processing row {index + 1}/{len(df)}: {row['Video URL']}\")\n",
    "\n",
    "    # Process the video\n",
    "    face_id, has_faces = process_video(row, videos_dir, frames_dir, embeddings_dir)\n",
    "\n",
    "    if has_faces:\n",
    "        df.at[index, \"HasFaces\"] = True\n",
    "        df.at[index, \"FaceID\"] = face_id\n",
    "    else:\n",
    "        no_faces_df = pd.concat([no_faces_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    # Mark as processed\n",
    "    df.at[index, \"Processed\"] = True\n",
    "\n",
    "# Create the complement DataFrame: rows in df but not in no_faces_df\n",
    "faces_df = df[~df.index.isin(no_faces_df.index)].copy()\n",
    "\n",
    "# Save results\n",
    "df.to_excel(\"processed_with_faces_or_not.xlsx\", index=False)\n",
    "no_faces_df.to_excel(\"videos_without_faces.xlsx\", index=False)\n",
    "faces_df.to_excel(\"videos_with_faces.xlsx\", index=False)\n",
    "\n",
    "print(\"Processing complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face-video mapping saved to 'face_video_mapping.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "def load_embeddings(embedding_dir):\n",
    "    \"\"\"Load all embeddings and their metadata from the directory.\"\"\"\n",
    "    embeddings = []\n",
    "    metadata = []  # To track video IDs and face paths\n",
    "\n",
    "    for video_id in os.listdir(embedding_dir):\n",
    "        video_path = os.path.join(embedding_dir, video_id)\n",
    "        if os.path.isdir(video_path):\n",
    "            for file in os.listdir(video_path):\n",
    "                if file.endswith(\".npy\"):\n",
    "                    embedding_path = os.path.join(video_path, file)\n",
    "                    embeddings.append(np.load(embedding_path))\n",
    "                    metadata.append({\n",
    "                        \"video_id\": video_id,\n",
    "                        \"face_file\": embedding_path,\n",
    "                        \"face_id\": f\"{video_id}_Face_1\"  # Unique face ID combining video_id and face name\n",
    "                    })\n",
    "\n",
    "    return np.array(embeddings), metadata\n",
    "\n",
    "def group_similar_faces(embeddings, metadata, threshold=0.9):\n",
    "    \"\"\"Group similar faces based on cosine similarity.\"\"\"\n",
    "    groups = []\n",
    "    used = set()\n",
    "\n",
    "    for i, emb1 in enumerate(embeddings):\n",
    "        if i in used:\n",
    "            continue  # Skip already grouped embeddings\n",
    "        group = [metadata[i]]\n",
    "        used.add(i)\n",
    "        for j, emb2 in enumerate(embeddings):\n",
    "            if j != i and j not in used:\n",
    "                similarity = cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0]\n",
    "                if similarity >= threshold:\n",
    "                    group.append(metadata[j])\n",
    "                    used.add(j)\n",
    "        groups.append(group)\n",
    "\n",
    "    return groups\n",
    "\n",
    "def create_face_table(groups, faces_dir):\n",
    "    \"\"\"Create a DataFrame showing unique faces and their associated videos.\"\"\"\n",
    "    rows = []\n",
    "    for group_id, group in enumerate(groups):\n",
    "        video_urls = [f\"videos/{item['video_id']}\" for item in group]  # Assume videos are in the 'videos' folder\n",
    "        face_file = os.path.join(faces_dir, group[0]['video_id'], f\"{group[0]['face_id']}.jpg\")  # First face as representative\n",
    "        rows.append({\n",
    "            \"Group ID\": group_id,\n",
    "            \"Face Image Path\": face_file,\n",
    "            \"Video URLs\": \", \".join(video_urls)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def display_faces_from_table(df):\n",
    "    \"\"\"Display unique faces from the table.\"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        face_image_path = row[\"Face Image Path\"]\n",
    "        if os.path.exists(face_image_path):\n",
    "            face_image = cv2.imread(face_image_path)\n",
    "            cv2.imshow(f\"Group {row['Group ID']} - Videos: {row['Video URLs']}\", face_image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Paths\n",
    "embedding_dir = \"./embeddings\"\n",
    "faces_dir = \"./faces\"\n",
    "\n",
    "# Load embeddings\n",
    "embeddings, metadata = load_embeddings(embedding_dir)\n",
    "\n",
    "# Group similar faces\n",
    "groups = group_similar_faces(embeddings, metadata, threshold=0.9)\n",
    "\n",
    "# Create the face table\n",
    "face_table = create_face_table(groups, faces_dir)\n",
    "\n",
    "# Save and display results\n",
    "face_table.to_excel(\"face_video_mapping.xlsx\", index=False)\n",
    "print(\"Face-video mapping saved to 'face_video_mapping.xlsx'.\")\n",
    "\n",
    "# Optional: Display faces\n",
    "display_faces_from_table(face_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face-video mapping with points saved to 'face_video_mapping_with_points.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "def load_embeddings(embedding_dir, performance_points):\n",
    "    \"\"\"Load all embeddings and their metadata from the directory.\"\"\"\n",
    "    embeddings = []\n",
    "    metadata = []  # To track video IDs and face paths\n",
    "\n",
    "    for video_id in os.listdir(embedding_dir):\n",
    "        video_path = os.path.join(embedding_dir, video_id)\n",
    "        if os.path.isdir(video_path):\n",
    "            for file in os.listdir(video_path):\n",
    "                if file.endswith(\".npy\"):\n",
    "                    embedding_path = os.path.join(video_path, file)\n",
    "                    embeddings.append(np.load(embedding_path))\n",
    "                    metadata.append({\n",
    "                        \"video_id\": video_id,\n",
    "                        \"face_file\": embedding_path,\n",
    "                        \"face_id\": f\"{video_id}_Face_1\",  # Unique face ID combining video_id and face name\n",
    "                        \"performance_points\": performance_points.get(video_id, 0)  # Fetch points or default to 0\n",
    "                    })\n",
    "\n",
    "    return np.array(embeddings), metadata\n",
    "\n",
    "def group_similar_faces(embeddings, metadata, threshold=0.9):\n",
    "    \"\"\"Group similar faces based on cosine similarity.\"\"\"\n",
    "    groups = []\n",
    "    used = set()\n",
    "\n",
    "    for i, emb1 in enumerate(embeddings):\n",
    "        if i in used:\n",
    "            continue  # Skip already grouped embeddings\n",
    "        group = [metadata[i]]\n",
    "        used.add(i)\n",
    "        for j, emb2 in enumerate(embeddings):\n",
    "            if j != i and j not in used:\n",
    "                similarity = cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0]\n",
    "                if similarity >= threshold:\n",
    "                    group.append(metadata[j])\n",
    "                    used.add(j)\n",
    "        groups.append(group)\n",
    "\n",
    "    return groups\n",
    "\n",
    "def create_face_table(groups, faces_dir):\n",
    "    \"\"\"Create a DataFrame showing unique faces and their associated videos and points.\"\"\"\n",
    "    rows = []\n",
    "    for group_id, group in enumerate(groups):\n",
    "        video_urls = [f\"videos/{item['video_id']}\" for item in group]  # Assume videos are in the 'videos' folder\n",
    "        performance_points = sum(item[\"performance_points\"] for item in group)/ len(group)  # Sum points for the group\n",
    "        face_file = os.path.join(faces_dir, group[0]['video_id'], f\"{group[0]['face_id']}.jpg\")  # First face as representative\n",
    "        rows.append({\n",
    "            \"Group ID\": group_id,\n",
    "            \"Face Image Path\": face_file,\n",
    "            \"Video URLs\": \", \".join(video_urls),\n",
    "            \"Performance Points\": performance_points\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"/home/harshit/Desktop/hi/influencer_analysis/src/Assignment Data.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "# Create a mapping of performance points\n",
    "performance_points = {}\n",
    "for _, row in df.iterrows():\n",
    "    video_id = row[\"Video URL\"].split(\"/\")[-1]  # Extract the video ID from the URL\n",
    "    performance_points[video_id] = row[\"Performance\"]\n",
    "\n",
    "# Paths\n",
    "embedding_dir = \"./embeddings\"\n",
    "faces_dir = \"./faces\"\n",
    "\n",
    "# Load embeddings\n",
    "embeddings, metadata = load_embeddings(embedding_dir, performance_points)\n",
    "\n",
    "# Group similar faces\n",
    "groups = group_similar_faces(embeddings, metadata, threshold=0.9)\n",
    "\n",
    "# Create the face table\n",
    "face_table = create_face_table(groups, faces_dir)\n",
    "\n",
    "# Save and display results\n",
    "face_table.to_excel(\"face_video_mapping_with_points.xlsx\", index=False)\n",
    "print(\"Face-video mapping with points saved to 'face_video_mapping_with_points.xlsx'.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face-video mapping saved to 'face_video_mapping_sorted.xlsx'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <table border=\"1\">\n",
       "        <tr>\n",
       "            <th>Index</th>\n",
       "            <th>Face Image</th>\n",
       "            <th>Video URLs</th>\n",
       "            <th>Average Performance Points</th>\n",
       "        </tr>\n",
       "    \n",
       "        <tr>\n",
       "            <td>1</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-983335896508749/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-983335896508749</td>\n",
       "            <td>2.26</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>2</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-604041931565137/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-604041931565137</td>\n",
       "            <td>1.53</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>3</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-791572172961239/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-791572172961239, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-803990118540094, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8008073409211713, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-424802420355057</td>\n",
       "            <td>1.31</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>4</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-883738210384679/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-883738210384679, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-1698824364241828</td>\n",
       "            <td>1.23</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>5</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-793257836073148/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-793257836073148</td>\n",
       "            <td>1.20</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>6</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-954832972830686/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-954832972830686, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-797024995612413, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-942779243913664</td>\n",
       "            <td>1.15</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>7</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-925260332281638/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-925260332281638, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-909110383822260, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-902456848100089</td>\n",
       "            <td>1.12</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>8</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-808097524590260/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-808097524590260, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-987643572956494</td>\n",
       "            <td>1.08</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>9</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-888183703182855/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-888183703182855, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-881270063889884</td>\n",
       "            <td>0.94</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>10</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-680549530054789/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-680549530054789, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-890005255637433, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-899155277883965, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-891684945300160, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-896598988012982, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-621266003076530, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-817768845898837, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-426644026275739, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-620154813059921, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-684264882912286, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-427878012859864, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-690670309134450, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-871075730546911, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-1119272995406354, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-789715035654710, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-872188860590219, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-911172609864769, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-899987727789409, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-897680994566577, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-686488653080244, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-889604775414234, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-910958533691058, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-612426467555072, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-898402801287469, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-796944101940903, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8828692983838031, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-958774641659407, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-886049645973007, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-691857912087615, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-883246492824014, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-896843165102015, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-606237444463640, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6172742522782221, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-871037203883530, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-679261516829908, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-688887926060399, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-691252805779835, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6096104653784047, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-903060767715541, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-695130362192250, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-696006115320413, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-813828049840959, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-686083626588321, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-618555366744628, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-889375178765113, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-682596103528135, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-937410954343974, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-933913194646448, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-888056015719840, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-689771035910864, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-613152173490344, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-605272664726548, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-930116227971248, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-992064161877405, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-693988272279384, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6046690562050296, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-907416560296782, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-8816515918390519, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-933773150951550</td>\n",
       "            <td>0.93</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>11</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-871981848375866/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-871981848375866</td>\n",
       "            <td>0.90</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>12</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-6720438181324436/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6720438181324436</td>\n",
       "            <td>0.88</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>13</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-429145826826558/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-429145826826558, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-806751788307038</td>\n",
       "            <td>0.85</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>14</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-903913985069116/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-903913985069116</td>\n",
       "            <td>0.83</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>15</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-876121221160846/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-876121221160846, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-873317140849832, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-932703258597949</td>\n",
       "            <td>0.76</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>16</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-817477363934899/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-817477363934899, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-887363366529815</td>\n",
       "            <td>0.74</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>17</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-874864704574925/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-874864704574925</td>\n",
       "            <td>0.62</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>18</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-965108935263649/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-965108935263649, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-888062106715252</td>\n",
       "            <td>0.60</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>19</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-886609482926268/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-886609482926268, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-790055392972248, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-911926190614858, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-819765763526762, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-815391233916449</td>\n",
       "            <td>0.51</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>20</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-6764280623620361/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-6764280623620361</td>\n",
       "            <td>0.35</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>21</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-904174908300812/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-904174908300812, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-963303392509872</td>\n",
       "            <td>0.31</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>22</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-960884234555681/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-960884234555681</td>\n",
       "            <td>0.31</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>23</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-1119706949586170/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-1119706949586170</td>\n",
       "            <td>0.22</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>24</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-905739711170399/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-905739711170399, https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-894559522288371</td>\n",
       "            <td>0.18</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr>\n",
       "            <td>25</td>  <!-- Ensure sequential index -->\n",
       "            <td><img src=\"./faces/hd-876239523982490/face.jpg\" width=\"100\"></td>\n",
       "            <td>https://fgimagestorage.blob.core.windows.net/facebook-assets/hd-876239523982490</td>\n",
       "            <td>0.05</td>\n",
       "        </tr>\n",
       "        </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Function to load embeddings and metadata\n",
    "def load_embeddings(embedding_dir, performance_data):\n",
    "    \"\"\"\n",
    "    Load all embeddings and their metadata from the directory, including performance points.\n",
    "    :param embedding_dir: Path to the directory containing embeddings.\n",
    "    :param performance_data: Dictionary mapping video IDs to performance points.\n",
    "    :return: Tuple of embeddings and metadata.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    metadata = []\n",
    "\n",
    "    for video_id in os.listdir(embedding_dir):\n",
    "        video_path = os.path.join(embedding_dir, video_id)\n",
    "        if os.path.isdir(video_path):\n",
    "            for file in os.listdir(video_path):\n",
    "                if file.endswith(\".npy\"):\n",
    "                    embedding_path = os.path.join(video_path, file)\n",
    "                    embeddings.append(np.load(embedding_path))\n",
    "                    metadata.append({\n",
    "                        \"video_id\": video_id,\n",
    "                        \"face_file\": embedding_path,\n",
    "                        \"face_id\": f\"{video_id}_Face_1\",\n",
    "                        \"performance_points\": performance_data.get(video_id, 0)  # Default to 0 if not found\n",
    "                    })\n",
    "\n",
    "    return np.array(embeddings), metadata\n",
    "\n",
    "# Function to group similar faces based on embeddings\n",
    "def group_similar_faces(embeddings, metadata, threshold=0.9):\n",
    "    \"\"\"Group similar faces based on cosine similarity.\"\"\"\n",
    "    groups = []\n",
    "    used = set()\n",
    "\n",
    "    for i, emb1 in enumerate(embeddings):\n",
    "        if i in used:\n",
    "            continue\n",
    "        group = [metadata[i]]\n",
    "        used.add(i)\n",
    "        for j, emb2 in enumerate(embeddings):\n",
    "            if j != i and j not in used:\n",
    "                similarity = cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0]\n",
    "                if similarity >= threshold:\n",
    "                    group.append(metadata[j])\n",
    "                    used.add(j)\n",
    "        groups.append(group)\n",
    "\n",
    "    return groups\n",
    "\n",
    "# Function to create a face table with images\n",
    "def create_face_table_with_images(groups, faces_dir):\n",
    "    \"\"\"Create a DataFrame with face images, video URLs, and average performance points.\"\"\"\n",
    "    rows = []\n",
    "    for group_id, group in enumerate(groups):\n",
    "        video_urls = [f\"https://fgimagestorage.blob.core.windows.net/facebook-assets/{item['video_id']}\" for item in group]\n",
    "        performance_points = sum(item[\"performance_points\"] for item in group) / len(group)\n",
    "\n",
    "        # Get face image path\n",
    "        face_file_path = os.path.join(faces_dir, group[0]['video_id'], f\"face.jpg\")  # Assuming saved as 'face.jpg'\n",
    "        if os.path.exists(face_file_path):\n",
    "            face_image_path = face_file_path\n",
    "        else:\n",
    "            face_image_path = None  # Handle cases where the image doesn't exist\n",
    "\n",
    "        rows.append({\n",
    "            \"Face Image Path\": face_image_path,\n",
    "            \"Video URLs\": \", \".join(video_urls),\n",
    "            \"Average Performance Points\": performance_points\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Function to display the face table inline in Jupyter Notebook\n",
    "def display_face_table_with_images(df):\n",
    "    \"\"\"Display a table in Jupyter Notebook with face images and other information.\"\"\"\n",
    "    html = \"\"\"\n",
    "    <table border=\"1\">\n",
    "        <tr>\n",
    "            <th>Index</th>\n",
    "            <th>Face Image</th>\n",
    "            <th>Video URLs</th>\n",
    "            <th>Average Performance Points</th>\n",
    "        </tr>\n",
    "    \"\"\"\n",
    "    for idx, row in df.iterrows():\n",
    "        face_image_html = (\n",
    "            f'<img src=\"{row[\"Face Image Path\"]}\" width=\"100\">' if row[\"Face Image Path\"] else \"Image Not Found\"\n",
    "        )\n",
    "        html += f\"\"\"\n",
    "        <tr>\n",
    "            <td>{idx + 1}</td>  <!-- Ensure sequential index -->\n",
    "            <td>{face_image_html}</td>\n",
    "            <td>{row[\"Video URLs\"]}</td>\n",
    "            <td>{row[\"Average Performance Points\"]:.2f}</td>\n",
    "        </tr>\n",
    "        \"\"\"\n",
    "    html += \"</table>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "# Main Execution\n",
    "\n",
    "# Paths to data and directories\n",
    "data_path = \"/home/harshit/Desktop/hi/influencer_analysis/src/Assignment Data.xlsx\"\n",
    "embedding_dir = \"./embeddings\"\n",
    "faces_dir = \"./faces\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "# Load performance data\n",
    "performance_data = {}\n",
    "for _, row in df.iterrows():\n",
    "    video_id = row[\"Video URL\"].split(\"/\")[-1]  # Extract the video ID from the URL\n",
    "    performance_data[video_id] = row[\"Performance\"]\n",
    "\n",
    "# Load embeddings with metadata\n",
    "embeddings, metadata = load_embeddings(embedding_dir, performance_data)\n",
    "\n",
    "# Group similar faces\n",
    "groups = group_similar_faces(embeddings, metadata, threshold=0.9)\n",
    "\n",
    "# Create the face table\n",
    "face_table = create_face_table_with_images(groups, faces_dir)\n",
    "\n",
    "# Sort the face table by \"Average Performance Points\" in descending order\n",
    "face_table = face_table.sort_values(by=\"Average Performance Points\", ascending=False).reset_index(drop=True)  # Reset index\n",
    "\n",
    "# Save the table to Excel\n",
    "face_table.to_excel(\"face_video_mapping_sorted.xlsx\", index=False)\n",
    "print(\"Face-video mapping saved to 'face_video_mapping_sorted.xlsx'.\")\n",
    "\n",
    "# Optional: Display the table inline\n",
    "display_face_table_with_images(face_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def extract_visual_features(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = max(1, int(fps))  # Sample 1 frame per second\n",
    "    \n",
    "    colors = []\n",
    "    transitions = 0\n",
    "    prev_frame = None\n",
    "\n",
    "    for i in range(0, frame_count, frame_interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Resize for faster processing\n",
    "        resized = cv2.resize(frame, (100, 100))\n",
    "        dominant_color = cv2.mean(resized)[:3]  # Extract RGB average\n",
    "        colors.append(dominant_color)\n",
    "\n",
    "        # Detect transitions by comparing frames\n",
    "        if prev_frame is not None:\n",
    "            diff = cv2.absdiff(prev_frame, resized)\n",
    "            transitions += np.sum(diff > 50) > 10000  # Adjust threshold\n",
    "        prev_frame = resized\n",
    "\n",
    "    cap.release()\n",
    "    return {\n",
    "        \"dominant_colors\": Counter(map(tuple, colors)).most_common(5),\n",
    "        \"transitions\": transitions,\n",
    "        \"duration\": frame_count / fps\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_audio_features(video_path):\n",
    "    audio, sr = librosa.load(video_path, sr=None, mono=True)  # Load audio from video\n",
    "    mfccs = librosa.feature.mfcc(audio, sr=sr, n_mfcc=13)  # Extract MFCCs\n",
    "    \n",
    "    tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)  # Detect tempo (BPM)\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr))\n",
    "    \n",
    "    return {\n",
    "        \"mfcc_mean\": np.mean(mfccs, axis=1).tolist(),\n",
    "        \"tempo\": tempo,\n",
    "        \"spectral_centroid\": spectral_centroid\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text_from_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_interval = 30  # Extract every 30th frame\n",
    "\n",
    "    texts = []\n",
    "    for i in range(0, frame_count, frame_interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Convert to grayscale for OCR\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        text = pytesseract.image_to_string(Image.fromarray(gray))\n",
    "        texts.append(text.strip())\n",
    "    cap.release()\n",
    "    return \" \".join(filter(None, texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos\n",
      "True\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-999607261342550\n",
      "Processing: hd-999607261342550\n",
      "this is result {'video': 'hd-999607261342550', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-997580728807604\n",
      "Processing: hd-997580728807604\n",
      "this is result {'video': 'hd-997580728807604', 'visual_features': {'dominant_colors': [((129.7374, 146.79170000000002, 152.42520000000002), 1), ((129.9078, 147.0496, 152.5256), 1), ((133.0109, 144.3932, 154.3015), 1), ((128.6303, 139.1468, 146.088), 1), ((126.42790000000001, 136.3923, 141.96630000000002), 1)], 'transitions': 1, 'duration': 11.7}, 'text_data': 'HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY fa\\n\\nHUSTLEZY HUSTLEZY\\n\\nSHOP NOW\\n\\nfe\\naS\\nAttractive range Easy\\n\\nFast delivery\\nof products Y customisation'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-992418235673669\n",
      "Processing: hd-992418235673669\n",
      "this is result {'video': 'hd-992418235673669', 'visual_features': {'dominant_colors': [((172.5106, 163.9001, 169.6592), 1), ((171.1917, 162.52460000000002, 169.48950000000002), 1), ((174.4289, 166.0076, 170.6759), 1), ((175.1237, 165.2859, 165.3479), 1), ((178.48160000000001, 164.7567, 164.2929), 1)], 'transitions': 1, 'duration': 20.766666666666666}, 'text_data': 'He got me the cutest camera roll\\nkeychain with pictures of us 44 He got me the cutest camera roll\\nkeychain with pictures of us #4 He got me the cutest camera roll\\nkeychain with pictures of us #4 He got me the cutest camera roll\\nkeychain with pictures of us #4 He got me the cutest camera roll\\nkeychain with pictures of us #4\\n\\n= He got me the cutest camera roll\\nkeychain with pictures of us #4 He got me the cutest camera roll\\nkeychain with pictures of us #4 He got me the cutest camera roll\\nkeychain with pictures of us #4\\n\\naa8\\npasty yy. oe\\n\\n4\\n\\ny He got me the cutest camera roll\\nkeychain with pictures of us #4 He got me the cutest camera roll\\nkeychain with pictures of us #4 He got me the cutest camera roll\\nkeychain with pictures of us 44 He got me the cutest camera roll\\nkeychain with pictures of us 44 He got me the cutest camera roll\\nkeychain with pictures of us 44 He got me the cutest camera roll\\nkeychain with pictures of us 44 He got me the cutest camera roll\\nkeychain with pictures of us 44 He got me the cutest camera roll\\nkeychain with pictures of us 44 He got me the cutest camera roll\\nkeychain with pictures of us #4 He got me the cutest camera roll\\nkeychain with pictures of us #4 He got me the cutest camera roll\\n\\n\\n\\nkeychain with pictures of us 44 He got me the cutest camera roll\\n\\n\\n\\nkeychain with pictures of us 44\\n\\nPh\\n\\nHUSTLEZY \\n\\nfy He got me the cutest camera roll\\n\\nkeychain with pictures of us 44'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-991636695150147\n",
      "Processing: hd-991636695150147\n",
      "this is result {'video': 'hd-991636695150147', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989969399547901\n",
      "Processing: hd-989969399547901\n",
      "this is result {'video': 'hd-989969399547901', 'visual_features': {'dominant_colors': [((192.83620000000002, 195.47160000000002, 197.53560000000002), 1), ((174.8416, 181.8984, 197.41250000000002), 1), ((174.0739, 176.9369, 188.4302), 1), ((169.1318, 171.1987, 180.2901), 1), ((154.2815, 155.4358, 167.12470000000002), 1)], 'transitions': 7, 'duration': 18.566666666666666}, 'text_data': 'HUSTLEZY\\n\\nMy boyfriend was so excited\\nto show me what he got & { i)\\nHUSTLEZY\\n\\nMy boyfriend was so excited\\nto show me what he got &@ HUSTLEZY\\n\\nN\\n\\nMy boyfriend was so excited\\nto show me what he got @ HUSTLEZY HUSTLEZY |\\n\\nUST KERR.\\n\\nja YOU FOR YEU coe =. HUSTLEZY h\\niisdii\\nHUSTLEZY | HUSTLEZY h =\\nHUSTLE: h \\\\\\nHUSTLEZY HUSTLEZY HUSTLEZY fi\\n\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n@'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989930303148492\n",
      "Processing: hd-989930303148492\n",
      "this is result {'video': 'hd-989930303148492', 'visual_features': {'dominant_colors': [((136.5566, 118.4003, 59.1584), 1), ((20.9134, 29.807000000000002, 33.3522), 1), ((24.3199, 30.0441, 31.1522), 1), ((25.9284, 31.7575, 31.7119), 1), ((23.9681, 30.652700000000003, 32.607800000000005), 1)], 'transitions': 6, 'duration': 19.998664529914528}, 'text_data': '7t0e tay\\n\\n(ip iy) amin!\\n\\nraw\\ne SG i\\n\\n:\\n\\nS|\\n\\n=\\nv\\nie)\\naR\\n2\\n>\\nN\\n9\\nis) a LMP mie\\n= MEER ER ERT EE TRERETILL nenertsy peat\\nTUT T ee\\na fi\\n\\nHUSTLEZY fl\\n\\nHUSTLEZY\\n\\na> a\\n\\nAttractive range A s\\nFast deliver\\nof products Y customisation\\n\\noe'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989654009083459\n",
      "Processing: hd-989654009083459\n",
      "this is result {'video': 'hd-989654009083459', 'visual_features': {'dominant_colors': [((93.73010000000001, 110.17500000000001, 135.85500000000002), 1), ((84.9991, 101.8035, 128.3133), 1), ((92.7204, 108.4247, 138.6584), 1), ((90.1379, 106.9411, 135.8553), 1), ((120.5408, 132.7279, 160.19140000000002), 1)], 'transitions': 5, 'duration': 10.4}, 'text_data': 'WS ican t go anywhere J 4  Without what? |\\nad HUSTLEZY HUSTLEZY\\n\\na HUSTLEZY HUSTLEZY ~~ a .  .\\n~ ~\\nwo _\\nHUSTLEZY\\n\\n\\n\\nF\\n\\nmy soulmate, always\\n& forever Y - HUSTLEZY'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989600295478567\n",
      "Processing: hd-989600295478567\n",
      "this is result {'video': 'hd-989600295478567', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989284361966196\n",
      "Processing: hd-989284361966196\n",
      "this is result {'video': 'hd-989284361966196', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-988185795921355\n",
      "Processing: hd-988185795921355\n",
      "this is result {'video': 'hd-988185795921355', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-987287402378278\n",
      "Processing: hd-987287402378278\n",
      "this is result {'video': 'hd-987287402378278', 'visual_features': {'dominant_colors': [((40.1036, 49.063300000000005, 60.1227), 1), ((54.093, 63.001900000000006, 75.28190000000001), 1), ((57.5636, 67.7836, 83.1187), 1), ((104.9689, 122.56, 157.12640000000002), 1), ((120.02340000000001, 138.0585, 176.0252), 1)], 'transitions': 2, 'duration': 14.133333333333333}, 'text_data': 'LOVE LAMP\\nPERSONALIZED LOVE LAMP\\nPERSONALIZED PLACE YOUR\\n\\n\"NAMES\\n~~ | PLACE YOUR\\n_ NAMES\\n= ZZ | _ :\\nPLACE*-YOUR\\nNAMES ,\\nAND A VERY\\nSPECIAL DATE \\nAND A VERY\\nSPECIAL DATE <A\\nTAND A VERY\\n\\nSPECIAL DATE ) ANDA\\' VERY\\nSPECIAL DATE'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-987232088920289\n",
      "Processing: hd-987232088920289\n",
      "this is result {'video': 'hd-987232088920289', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-986360206629277\n",
      "Processing: hd-986360206629277\n",
      "this is result {'video': 'hd-986360206629277', 'visual_features': {'dominant_colors': [((123.1255, 142.66140000000001, 149.9293), 1), ((123.09440000000001, 142.6823, 149.93030000000002), 1), ((126.9397, 141.2715, 154.5523), 1), ((119.2351, 131.94140000000002, 141.6231), 1), ((116.7629, 129.0337, 137.21030000000002), 1)], 'transitions': 1, 'duration': 12.0}, 'text_data': 'ad\\nUa\\n\\n\\\\ Sr)\\n\\napn J NY\\n\\nene / HUSTLEZY h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nvy,\\nwey\\n4S\\nAttractive range Easy\\n\\nFast delivery\\n\\nof products customisation'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-978448136455993\n",
      "Processing: hd-978448136455993\n",
      "this is result {'video': 'hd-978448136455993', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-977008307250628\n",
      "Processing: hd-977008307250628\n",
      "this is result {'video': 'hd-977008307250628', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-975523146942238\n",
      "Processing: hd-975523146942238\n",
      "this is result {'video': 'hd-975523146942238', 'visual_features': {'dominant_colors': [((127.71560000000001, 143.9805, 170.0011), 1), ((101.5818, 124.0476, 158.8992), 1), ((84.64840000000001, 106.3116, 142.5867), 1), ((98.62530000000001, 120.8168, 148.7554), 1), ((95.2089, 115.8246, 145.945), 1)], 'transitions': 5, 'duration': 16.666666666666668}, 'text_data': 'y mulhivense\\nof jusenomenenn!\\n\\ntina\\n\\nHi! SS\\n\\nES \\\\\\\\k\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy HUSTLEZY\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy  HUSTLEZY\\n\\nFor Your Most\\nMemorable Moments HUSTLEZY HUSTLEZY\\n\\nKesariya\\nRanbir & Alia\\nSN\\na\\nco =\\n\\nS sell ndaf-\\n\\n=, deik aah = HUSTLEZY h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery Easy\\nof products customisation\\n\\ni, fi\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n= @\\n\\nAttractive range\\nFast delive\\nepee tl\\n\\nEas\\nusto! and ition'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-967731231014052\n",
      "Processing: hd-967731231014052\n",
      "this is result {'video': 'hd-967731231014052', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-966715248087290\n",
      "Processing: hd-966715248087290\n",
      "this is result {'video': 'hd-966715248087290', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-966458824582483\n",
      "Processing: hd-966458824582483\n",
      "this is result {'video': 'hd-966458824582483', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-966019214364727\n",
      "Processing: hd-966019214364727\n",
      "this is result {'video': 'hd-966019214364727', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-964733417506862\n",
      "Processing: hd-964733417506862\n",
      "this is result {'video': 'hd-964733417506862', 'visual_features': {'dominant_colors': [((42.6301, 55.438100000000006, 83.6888), 1), ((60.351400000000005, 73.0166, 97.9407), 1), ((36.515, 42.703, 48.6541), 1), ((40.877300000000005, 47.5283, 54.9495), 1), ((50.3708, 64.94420000000001, 78.9766), 1)], 'transitions': 5, 'duration': 13.833333333333334}, 'text_data': 'Cherised memories\\nwith a picture with my\\ndogs! I loved it! Personalized Acrylic\\nLED Table Lamp\\nFor Your Loved Ones Personalized Acrylic\\nLED Table Lamp\\nFor Your Loved Ones Personalized Acrylic\\nLED Table Lamp\\nFor Your Loved Ones A beautiful customised\\nitem to gift your loved\\n\\nPefsonalized herylic\\nLEDTablelLamp\\nFor Your Loved Ones A beautiful customised\\nitem to gift your loved\\n\\nPrSonalized Acrylic\\nLED. Table Lamp\\n\\nFor Your Loved Ones It was a gift to my\\nfriend and they loved it! sb) It was a gift to my\\nfriend and they loved it!\\n\\ny | It was amazing, my\\nboyfriend loved it!\\n\\n99 loved bb) It was a gift to my\\nfriend and they loved it!\\n\\nA beautiful customised\\nitem to gift your loved Starting From i]\\n@Just 1,499.00 a\\n\\ny\\n\\nBS Xi\\n\\nStarting From i]\\n@Just 1,499.00\\n\\nz 999.00\\n_ Shop Now -\\n\\n|'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-958675741960412\n",
      "Processing: hd-958675741960412\n",
      "this is result {'video': 'hd-958675741960412', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-958267042213267\n",
      "Processing: hd-958267042213267\n",
      "this is result {'video': 'hd-958267042213267', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-954440782897187\n",
      "Processing: hd-954440782897187\n",
      "this is result {'video': 'hd-954440782897187', 'visual_features': {'dominant_colors': [((40.4917, 75.4499, 95.4351), 1), ((38.5296, 130.6686, 158.87730000000002), 1), ((28.925700000000003, 94.33040000000001, 110.3272), 1), ((23.434, 87.411, 112.08080000000001), 1), ((34.121300000000005, 86.0443, 112.8259), 1)], 'transitions': 5, 'duration': 22.566666666666666}, 'text_data': 'Don\\'t you t your ~\\n\\nlove story deserves 76\\n\\n -\\nSTRANGE TRAILS\\n\\nlamp to y6ur love STRANGE TRAILS\\n\\nWOW NS <q :\\noh\\n<>\\n\\n\"4\\n\\nThe Non Met\\n\\nAdd to playlist\\n\\nSHUFFLED WITH\\nBon Iver Beach Baby + Harry Styles\\nStephen Sanchez Until | Four + Cults\\nCurrent Joys F eg\\nmes\\n\\nAppears on fi\\n\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n@, h\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n@ www.hustlezy.com'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-951885082053340\n",
      "Processing: hd-951885082053340\n",
      "this is result {'video': 'hd-951885082053340', 'visual_features': {'dominant_colors': [((100.37920000000001, 138.8873, 177.5849), 1), ((97.6238, 134.8052, 171.97560000000001), 1), ((97.74090000000001, 134.6879, 172.00660000000002), 1), ((79.0672, 92.66000000000001, 120.483), 1), ((74.1416, 103.7684, 131.0342), 1)], 'transitions': 5, 'duration': 11.966666666666667}, 'text_data': 'ey Masry fou -\\naa  pt rat\\n\\n(=) ul [ he |! i 3 CUSTOMISED GIFT\\nFOR YOUR LOVED ONES CUSTOMISED GIFT\\nFOR YOUR LOVED ONES USE CODE \"NEWI0\"\\nFOR 10% OFF SHOP NOW AT HUSTLEZY.COM\\nSTARTS AT 219 INR ONLY'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-951491629353387\n",
      "Processing: hd-951491629353387\n",
      "this is result {'video': 'hd-951491629353387', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-946181943065342\n",
      "Processing: hd-946181943065342\n",
      "this is result {'video': 'hd-946181943065342', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-944981830978756\n",
      "Processing: hd-944981830978756\n",
      "this is result {'video': 'hd-944981830978756', 'visual_features': {'dominant_colors': [((116.5477, 113.9997, 130.44920000000002), 1), ((126.06930000000001, 123.32910000000001, 129.3469), 1), ((114.70660000000001, 115.4741, 138.2045), 1), ((114.91760000000001, 115.08000000000001, 139.02870000000001), 1), ((116.48400000000001, 118.45920000000001, 140.5941), 1)], 'transitions': 4, 'duration': 12.7}, 'text_data': '* HUSTLEZY\\n\\nThis is your sign to get\\n\\nthis for your man just\\nbecause HUSTLEZY\\n\\nthis fonyougman just\\nibecalise\\n-_ This isyoursign to get\\nthis for your manjjust\\nbecause Itisfa}keychain\\\\ filled) with\\ncustom|pics of your,\\n\\nchoice inside +\\neeeeeecacae Itisfa} keychain} filled with\\ncustom) pics|of your,\\n\\nchoice inside + \"\\na \\n\\nIsla) keychain filled! with\\ncustom pics of your\\nchoice inside + NMireasurevall|the/ special\\n\\nmemoriesifrom the ie\\n\\nHUSTLEZY HUSTLEZY\\n\\nP NOW\\n\\nH\\n\\nww\\naS\\nAttractive range Easy\\n\\nFast delivery\\n\\nof products customisation'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-944755280756437\n",
      "Processing: hd-944755280756437\n",
      "this is result {'video': 'hd-944755280756437', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-944160410298140\n",
      "Processing: hd-944160410298140\n",
      "this is result {'video': 'hd-944160410298140', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-942524046763053\n",
      "Processing: hd-942524046763053\n",
      "this is result {'video': 'hd-942524046763053', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-940634710428411\n",
      "Processing: hd-940634710428411\n",
      "this is result {'video': 'hd-940634710428411', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-939795907980426\n",
      "Processing: hd-939795907980426\n",
      "this is result {'video': 'hd-939795907980426', 'visual_features': {'dominant_colors': [((103.82780000000001, 140.37640000000002, 126.62750000000001), 1), ((118.19210000000001, 135.20600000000002, 128.2518), 1), ((128.1297, 134.66670000000002, 140.2105), 1), ((125.06160000000001, 128.6156, 136.0923), 1), ((134.8805, 140.989, 148.82760000000002), 1)], 'transitions': 4, 'duration': 17.066666666666666}, 'text_data': '3\\nof What gets you through\\nB the hardest times? sts\\n\\n| What gets you through\\n\\n== the hardest times? (ie\\n\\n1!\\niii Her  Her  Her  Her Y Her  h\\nHUSTLEZY\\n\\n& | = | \\n\\nAttractive range! fast dati Y\\nof products cat delivery\" customisdtion\\n\\nfe (i\\n\\nHUSTLEZY\\n\\n& | 4 | \\n\\nwey\\nfos)\\nFast deli\\nof products ast delivery\" customisation\\n\\nAttractive range'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-938232524809973\n",
      "Processing: hd-938232524809973\n",
      "this is result {'video': 'hd-938232524809973', 'visual_features': {'dominant_colors': [((163.6963, 173.0428, 196.34560000000002), 1), ((165.636, 173.9658, 194.56660000000002), 1), ((175.75740000000002, 183.0145, 197.31730000000002), 1), ((179.64880000000002, 186.312, 197.7332), 1), ((180.3889, 187.38660000000002, 198.2499), 1)], 'transitions': 1, 'duration': 15.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this Keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this Keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this Keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this Keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! 2\\n\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! 2\\n\\nJust dont try flashing it at security: q\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! 2\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nwe\\n>\\nAttractive range Easy\\n\\nFast deliv\\nof products een customisation & | & | \\n\\nAttractive range\\nof products\\n\\nEasy\\n\\nFast delive\\n customisation\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-937508703912579\n",
      "Processing: hd-937508703912579\n",
      "this is result {'video': 'hd-937508703912579', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-935558767885747\n",
      "Processing: hd-935558767885747\n",
      "this is result {'video': 'hd-935558767885747', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-935530867630269\n",
      "Processing: hd-935530867630269\n",
      "this is result {'video': 'hd-935530867630269', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-935168780798574\n",
      "Processing: hd-935168780798574\n",
      "this is result {'video': 'hd-935168780798574', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-932296771464171\n",
      "Processing: hd-932296771464171\n",
      "this is result {'video': 'hd-932296771464171', 'visual_features': {'dominant_colors': [((127.71560000000001, 143.9805, 170.0011), 1), ((101.5818, 124.0476, 158.8992), 1), ((84.64840000000001, 106.3116, 142.5867), 1), ((98.62530000000001, 120.8168, 148.7554), 1), ((95.2089, 115.8246, 145.945), 1)], 'transitions': 5, 'duration': 16.666666666666668}, 'text_data': 'y mulhivense\\nof jusenomenenn!\\n\\ntina\\n\\nHi! SS\\n\\nES \\\\\\\\k\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy HUSTLEZY\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy  HUSTLEZY\\n\\nFor Your Most\\nMemorable Moments HUSTLEZY HUSTLEZY\\n\\nKesariya\\nRanbir & Alia\\nSN\\na\\nco =\\n\\nS sell ndaf-\\n\\n=, deik aah = HUSTLEZY h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery Easy\\nof products customisation\\n\\ni, fi\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n= @\\n\\nAttractive range\\nFast delive\\nepee tl\\n\\nEas\\nusto! and ition'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-932085787962122\n",
      "Processing: hd-932085787962122\n",
      "this is result {'video': 'hd-932085787962122', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-932038864470963\n",
      "Processing: hd-932038864470963\n",
      "this is result {'video': 'hd-932038864470963', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-929830031529018\n",
      "Processing: hd-929830031529018\n",
      "this is result {'video': 'hd-929830031529018', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-929511878466995\n",
      "Processing: hd-929511878466995\n",
      "this is result {'video': 'hd-929511878466995', 'visual_features': {'dominant_colors': [((192.8855, 195.41570000000002, 197.5197), 1), ((174.8136, 181.90980000000002, 197.29850000000002), 1), ((174.3502, 177.0001, 188.5534), 1), ((169.31230000000002, 171.15, 180.4999), 1), ((155.0868, 155.43210000000002, 167.72240000000002), 1)], 'transitions': 7, 'duration': 18.566666666666666}, 'text_data': 'HUSTLEZY\\n\\nMy boyfriend was so excited\\nto show me what he got & { A\\\\\\nHUSTLEZY\\n\\nMy boyfriend was so excited\\nto show me what he got &@ ]\\nLA\\nHUSTLEZY\\n\\n_\\n\\nMy boyfriend was so excited\\nto show me what he got & HUSTLEZY\\n\\n= uy boyfriend was so excited\\n\\nto show me what he got &\\n\\n HUSTLEZY\\n\\nSEER.\\n\\nMAN YOUN You onan\\nOY YOU Guns oe =. HUSTLEZY h\\nHUSTLEZY Ph\\n|\\n\\n7)\\n\\nHUSTLEZY AY\\nh \\\\\\nHUSTLEZY HUSTLEZY HUSTLEZY a\\n\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n@'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-929300948587514\n",
      "Processing: hd-929300948587514\n",
      "this is result {'video': 'hd-929300948587514', 'visual_features': {'dominant_colors': [((121.0096, 134.9734, 157.3854), 1), ((110.38810000000001, 126.0416, 147.978), 1), ((105.614, 124.08130000000001, 144.9416), 1), ((137.6326, 146.3538, 165.1663), 1), ((112.56660000000001, 121.75200000000001, 140.32670000000002), 1)], 'transitions': 5, 'duration': 9.566666666666666}, 'text_data': \"Virat & Anushka @ 7 |\\n11/12117- CO |\\n\\nfx @-\\n\\n server fA\\n\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n h\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n4@'ww.hustlezy.com\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-925596815118953\n",
      "Processing: hd-925596815118953\n",
      "this is result {'video': 'hd-925596815118953', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-924865635226814\n",
      "Processing: hd-924865635226814\n",
      "this is result {'video': 'hd-924865635226814', 'visual_features': {'dominant_colors': [((55.337300000000006, 58.6858, 61.622), 1), ((55.3421, 58.6893, 61.616400000000006), 1), ((88.64280000000001, 108.92460000000001, 123.0747), 1), ((89.2733, 108.5978, 125.1858), 1), ((89.717, 109.4223, 137.9291), 1)], 'transitions': 6, 'duration': 15.2}, 'text_data': \"ie\\n\\nHUSTLEZY\\n\\nEverything is as promised!\\nThe quality and service are par\\nexcellence. A great buy! 6\\n\\nHUSTLEZY\\n\\nEverything is as promised!\\nThe quality and service are par\\nexcellence. A great buy! ie\\n\\nHUSTLEZY\\n\\n*\\n\\nwn\\nCc\\nKe)\\nS\\n\\n\\nSs)\\n\\nQ\\nx\\na\\n>\\n=\\nze)\\no\\nae)\\n\\n\\n)\\nx<\\nlu\\n\\nWSS\\nSCS,\\n\\nGreat value for money. Service is\\nalso too good. Highly recommended.\\n\\nLee\\nLL ttl tiie\\n\\nseewRNnn.\\n\\naBRwaaer\\n\\n:\\n< ;\\nSauRawen sss\\neS ARAREREN AS\\nSS Sy\\n.\\n4\\nyy\\n\\nSAR 4\\n\\nHUSTLEZY\\n\\nExceeded my expectations!\\nGreat value for money. Service is\\nalso too good. Highly recommended.\\n\\na\\n\\nLy\\n\\na\\n\\nLZ Se\\nLAL LY Lap\\n\\nLZZ\\n\\nLi iptt_\\nLitt peZ 6\\n\\nHUSTLEZY\\n\\nHf\\nYP\\nHTS\\n\\nExcellent Product\\nAttractive Design and Unique.\\nLoved the product! HUSTLEZY\\n\\nGreat stuff! I'm buying from\\nthem for the Ist time. But Im\\nsurely coming for more. HUSTLEZY\\n\\nGreat stuff! I'm buying from\\nthem for the Ist time. But Im\\nsurely coming for more. 6\\n\\nHUSTLEZY\\n\\nIts a cute gift for couples\\nWould suggest people 6\\n\\nHUSTLEZY\\n\\nIts a cute gift for couples\\nWould suggest people HUSTLEZY\\n\\nGet Your\\nPersonalised Illusion Lamps HUSTLEZY\\n\\nGet Your\\nPersonalised Illusion Lamps 6\\n\\nHUSTLEZY\\n\\nWT\\nAEE EE EEE ge 6\\n\\nHUSTLEZY\\n\\nNiven\\n\\nepee sete ieee\\nAEE EE EEE ge h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nAttractive range Fast delivery Easy\\nof products customisation f\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n\\n& |\\nAttractive rang Fast delivery Easy\\nof products customisation h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery\\nof products athe\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-924585008982148\n",
      "Processing: hd-924585008982148\n",
      "this is result {'video': 'hd-924585008982148', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-621652523105267\n",
      "Processing: hd-621652523105267\n",
      "this is result {'video': 'hd-621652523105267', 'visual_features': {'dominant_colors': [((127.71560000000001, 143.9805, 170.0011), 1), ((101.5818, 124.0476, 158.8992), 1), ((84.64840000000001, 106.3116, 142.5867), 1), ((98.62530000000001, 120.8168, 148.7554), 1), ((95.2089, 115.8246, 145.945), 1)], 'transitions': 5, 'duration': 16.666666666666668}, 'text_data': 'y mulhivense\\nof jusenomenenn!\\n\\ntina\\n\\nHi! SS\\n\\nES \\\\\\\\k\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy HUSTLEZY\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy  HUSTLEZY\\n\\nFor Your Most\\nMemorable Moments HUSTLEZY HUSTLEZY\\n\\nKesariya\\nRanbir & Alia\\nSN\\na\\nco =\\n\\nS sell ndaf-\\n\\n=, deik aah = HUSTLEZY h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery Easy\\nof products customisation\\n\\ni, fi\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n= @\\n\\nAttractive range\\nFast delive\\nepee tl\\n\\nEas\\nusto! and ition'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-620702145697389\n",
      "Processing: hd-620702145697389\n",
      "this is result {'video': 'hd-620702145697389', 'visual_features': {'dominant_colors': [((115.042, 120.3473, 136.5343), 1), ((114.9179, 120.20620000000001, 136.83270000000002), 1), ((98.6579, 111.1293, 131.1556), 1), ((91.01440000000001, 102.39450000000001, 120.26050000000001), 1), ((81.37960000000001, 93.5806, 109.61500000000001), 1)], 'transitions': 1, 'duration': 14.9}, 'text_data': 'HUSTLEZY\\n\\nLighting up memories! HUSTLEZY\\n\\nLighting up memories! HUSTLEZY\\n\\nLighting up memories!'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-6174004652651971\n",
      "Processing: hd-6174004652651971\n",
      "this is result {'video': 'hd-6174004652651971', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-617288786873081\n",
      "Processing: hd-617288786873081\n",
      "this is result {'video': 'hd-617288786873081', 'visual_features': {'dominant_colors': [((55.337300000000006, 58.6858, 61.622), 1), ((55.3421, 58.6893, 61.616400000000006), 1), ((88.64280000000001, 108.92460000000001, 123.0747), 1), ((89.2733, 108.5978, 125.1858), 1), ((89.717, 109.4223, 137.9291), 1)], 'transitions': 6, 'duration': 15.2}, 'text_data': \"ie\\n\\nHUSTLEZY\\n\\nEverything is as promised!\\nThe quality and service are par\\nexcellence. A great buy! 6\\n\\nHUSTLEZY\\n\\nEverything is as promised!\\nThe quality and service are par\\nexcellence. A great buy! ie\\n\\nHUSTLEZY\\n\\n*\\n\\nwn\\nCc\\nKe)\\nS\\n\\n\\nSs)\\n\\nQ\\nx\\na\\n>\\n=\\nze)\\no\\nae)\\n\\n\\n)\\nx<\\nlu\\n\\nWSS\\nSCS,\\n\\nGreat value for money. Service is\\nalso too good. Highly recommended.\\n\\nLee\\nLL ttl tiie\\n\\nseewRNnn.\\n\\naBRwaaer\\n\\n:\\n< ;\\nSauRawen sss\\neS ARAREREN AS\\nSS Sy\\n.\\n4\\nyy\\n\\nSAR 4\\n\\nHUSTLEZY\\n\\nExceeded my expectations!\\nGreat value for money. Service is\\nalso too good. Highly recommended.\\n\\na\\n\\nLy\\n\\na\\n\\nLZ Se\\nLAL LY Lap\\n\\nLZZ\\n\\nLi iptt_\\nLitt peZ 6\\n\\nHUSTLEZY\\n\\nHf\\nYP\\nHTS\\n\\nExcellent Product\\nAttractive Design and Unique.\\nLoved the product! HUSTLEZY\\n\\nGreat stuff! I'm buying from\\nthem for the Ist time. But Im\\nsurely coming for more. HUSTLEZY\\n\\nGreat stuff! I'm buying from\\nthem for the Ist time. But Im\\nsurely coming for more. 6\\n\\nHUSTLEZY\\n\\nIts a cute gift for couples\\nWould suggest people 6\\n\\nHUSTLEZY\\n\\nIts a cute gift for couples\\nWould suggest people HUSTLEZY\\n\\nGet Your\\nPersonalised Illusion Lamps HUSTLEZY\\n\\nGet Your\\nPersonalised Illusion Lamps 6\\n\\nHUSTLEZY\\n\\nWT\\nAEE EE EEE ge 6\\n\\nHUSTLEZY\\n\\nNiven\\n\\nepee sete ieee\\nAEE EE EEE ge h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nAttractive range Fast delivery Easy\\nof products customisation f\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n\\n& |\\nAttractive rang Fast delivery Easy\\nof products customisation h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery\\nof products athe\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-613417017284998\n",
      "Processing: hd-613417017284998\n",
      "this is result {'video': 'hd-613417017284998', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-613197413789434\n",
      "Processing: hd-613197413789434\n",
      "this is result {'video': 'hd-613197413789434', 'visual_features': {'dominant_colors': [((76.9354, 76.52080000000001, 77.7629), 1), ((80.2666, 74.90740000000001, 75.1889), 1), ((71.0707, 62.202600000000004, 57.465300000000006), 1), ((76.016, 72.8609, 74.8662), 1), ((62.1674, 61.875800000000005, 78.37610000000001), 1)], 'transitions': 1, 'duration': 13.733333333333333}, 'text_data': 'Let the\\nwalls do\\n\\nthe\\nTalking! rea HUSLEZ & |\\n3\\nEasy\\noY customisation /\\n\\nHUSTLEZY\\nWWW.HUSTLEZY.COM\\n\\n& | &b\\nfos)\\nAttractive range Easy\\n\\nFast delivery\\n\\nof products customisation'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-612555930635832\n",
      "Processing: hd-612555930635832\n",
      "this is result {'video': 'hd-612555930635832', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-611188517518682\n",
      "Processing: hd-611188517518682\n",
      "this is result {'video': 'hd-611188517518682', 'visual_features': {'dominant_colors': [((55.337300000000006, 58.6858, 61.622), 1), ((55.3421, 58.6893, 61.616400000000006), 1), ((88.64280000000001, 108.92460000000001, 123.0747), 1), ((89.2733, 108.5978, 125.1858), 1), ((89.717, 109.4223, 137.9291), 1)], 'transitions': 6, 'duration': 15.2}, 'text_data': \"ie\\n\\nHUSTLEZY\\n\\nEverything is as promised!\\nThe quality and service are par\\nexcellence. A great buy! 6\\n\\nHUSTLEZY\\n\\nEverything is as promised!\\nThe quality and service are par\\nexcellence. A great buy! ie\\n\\nHUSTLEZY\\n\\n*\\n\\nwn\\nCc\\nKe)\\nS\\n\\n\\nSs)\\n\\nQ\\nx\\na\\n>\\n=\\nze)\\no\\nae)\\n\\n\\n)\\nx<\\nlu\\n\\nWSS\\nSCS,\\n\\nGreat value for money. Service is\\nalso too good. Highly recommended.\\n\\nLee\\nLL ttl tiie\\n\\nseewRNnn.\\n\\naBRwaaer\\n\\n:\\n< ;\\nSauRawen sss\\neS ARAREREN AS\\nSS Sy\\n.\\n4\\nyy\\n\\nSAR 4\\n\\nHUSTLEZY\\n\\nExceeded my expectations!\\nGreat value for money. Service is\\nalso too good. Highly recommended.\\n\\na\\n\\nLy\\n\\na\\n\\nLZ Se\\nLAL LY Lap\\n\\nLZZ\\n\\nLi iptt_\\nLitt peZ 6\\n\\nHUSTLEZY\\n\\nHf\\nYP\\nHTS\\n\\nExcellent Product\\nAttractive Design and Unique.\\nLoved the product! HUSTLEZY\\n\\nGreat stuff! I'm buying from\\nthem for the Ist time. But Im\\nsurely coming for more. HUSTLEZY\\n\\nGreat stuff! I'm buying from\\nthem for the Ist time. But Im\\nsurely coming for more. 6\\n\\nHUSTLEZY\\n\\nIts a cute gift for couples\\nWould suggest people 6\\n\\nHUSTLEZY\\n\\nIts a cute gift for couples\\nWould suggest people HUSTLEZY\\n\\nGet Your\\nPersonalised Illusion Lamps HUSTLEZY\\n\\nGet Your\\nPersonalised Illusion Lamps 6\\n\\nHUSTLEZY\\n\\nWT\\nAEE EE EEE ge 6\\n\\nHUSTLEZY\\n\\nNiven\\n\\nepee sete ieee\\nAEE EE EEE ge h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nAttractive range Fast delivery Easy\\nof products customisation f\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n\\n& |\\nAttractive rang Fast delivery Easy\\nof products customisation h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery\\nof products athe\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-6107397609317402\n",
      "Processing: hd-6107397609317402\n",
      "this is result {'video': 'hd-6107397609317402', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-604285914607200\n",
      "Processing: hd-604285914607200\n",
      "this is result {'video': 'hd-604285914607200', 'visual_features': {'dominant_colors': [((83.6459, 94.9988, 116.16130000000001), 1), ((83.7882, 95.2906, 116.01100000000001), 1), ((71.2689, 81.92, 112.5963), 1), ((102.51, 114.39420000000001, 141.0738), 1), ((97.6222, 108.3208, 132.4489), 1)], 'transitions': 7, 'duration': 17.4}, 'text_data': 'LET YOUR\\nPRIDE SHINE % LETYOUR\\nPRIDE SHINE +'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-603099807587246\n",
      "Processing: hd-603099807587246\n",
      "this is result {'video': 'hd-603099807587246', 'visual_features': {'dominant_colors': [((80.38810000000001, 92.1911, 96.1456), 15), ((80.5827, 92.2163, 96.25890000000001), 2), ((80.6401, 92.17580000000001, 96.337), 1), ((80.5988, 92.218, 96.2651), 1), ((80.5904, 92.2158, 96.2569), 1)], 'transitions': 0, 'duration': 19.91991991991992}, 'text_data': 'NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code NightShot-LED Spotify Plaques\\n\\nCustomizable Photo\\n\\nCustomizable\\nTitle Song\\n\\nScannable\\nSpotify Code'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-911482386703699\n",
      "Processing: hd-911482386703699\n",
      "this is result {'video': 'hd-911482386703699', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-909937876815529\n",
      "Processing: hd-909937876815529\n",
      "this is result {'video': 'hd-909937876815529', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-909067460285978\n",
      "Processing: hd-909067460285978\n",
      "this is result {'video': 'hd-909067460285978', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-906909830682725\n",
      "Processing: hd-906909830682725\n",
      "this is result {'video': 'hd-906909830682725', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-906506897404894\n",
      "Processing: hd-906506897404894\n",
      "this is result {'video': 'hd-906506897404894', 'visual_features': {'dominant_colors': [((42.1927, 55.5552, 83.4286), 1), ((60.053200000000004, 72.4803, 97.1965), 1), ((36.298300000000005, 42.7913, 48.376400000000004), 1), ((40.2244, 47.117200000000004, 54.3795), 1), ((49.5703, 64.6305, 78.2029), 1)], 'transitions': 5, 'duration': 13.833333333333334}, 'text_data': 'with a picture with my\\n\\ndogs!\\n\\nn\\nx\\n2\\n\\nE\\noO\\nE\\nnol\\no\\na\\nS\\no\\n\\n(5) z\\nao)\\no\\n>\\n2 I loved it!\\n\\nPersonalized Acrylic\\n\\nLED Table Lamp\\nFor Your Loved Ones It was amazing, my\\nboyfriend loved it!\\n\\nPersonalized Acrylic\\nLED Table Lamp\\nFor Your Loved Ones It was amazing, my\\nboyfriend loved it!\\n\\nPersonalized Acrylic\\nLED Table Lamp\\nFor Your Loved Ones A beautiful customised\\nitem to gift your loved\\nones!\\n\\naa ic\\nLED Table/Lamp\\nFor Your Loved Ones A beautiful customised\\nitem to gift your loved\\n\\nNk\\n\\nLED Table Lamp\\nFor Your Loved Ones It was a gift to my\\nfriend and they loved it! 5 |  It was a gift to my\\n\\nfriend and they loved it!\\n\\nIt was amazing, my\\nboyfriend loved it!\\n\\n~~.)\\n95) Moved it!  | 5 It was a gift to my\\nfriend and they loved it!\\n\\nA beautiful customised\\n9 5 item to gift your loved\\n\\nones!\\nee)\\n| 5 | 5 | It was amazing, my\\nboyfriend loved it!\\n\\n95 oe | Starting From a\\n@ Just 21,999.00 he\\n\\naf ve\\n\\n| Starting From ir\\n@Just z1299.00\\n\\n2 1249 only\\nShop Now -\\n\\ncee'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-905844110841635\n",
      "Processing: hd-905844110841635\n",
      "this is result {'video': 'hd-905844110841635', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-905545323817883\n",
      "Processing: hd-905545323817883\n",
      "this is result {'video': 'hd-905545323817883', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-904815481005158\n",
      "Processing: hd-904815481005158\n",
      "this is result {'video': 'hd-904815481005158', 'visual_features': {'dominant_colors': [((126.81500000000001, 128.61860000000001, 146.2529), 1), ((128.9521, 124.7733, 127.9805), 1), ((127.3764, 125.753, 129.49360000000001), 1), ((14.9029, 116.7659, 149.2707), 1), ((118.95320000000001, 135.8726, 170.50830000000002), 1)], 'transitions': 9, 'duration': 15.933333333333334}, 'text_data': 'HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY\\n\\nHUSTLEZY HUSTLEZY\\n\\n-\\na HUSTLEZ fi\\n\\nHUSTLEZY\\nShop No hh\\n\\nHUSTLEZY\\nShop Now\\n\\nwww.hustlezy.com\\naks 4\\n\\nBe FAST *\\n+ =) o\\n\\nAttractive Range ; Easy\\nAt Products Fast Delivery Customization h\\n\\nHUSTLEZY\\nShop Now\\n\\nwww.hustlezy.com\\n\\n+ We q\\n\\n_ o\\n: ip 3\\n\\nAttractive Range ; Easy\\nAt Products Fast Delivery Customization'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-904480964010630\n",
      "Processing: hd-904480964010630\n",
      "this is result {'video': 'hd-904480964010630', 'visual_features': {'dominant_colors': [((127.71560000000001, 143.9805, 170.0011), 1), ((101.5818, 124.0476, 158.8992), 1), ((84.64840000000001, 106.3116, 142.5867), 1), ((98.62530000000001, 120.8168, 148.7554), 1), ((95.2089, 115.8246, 145.945), 1)], 'transitions': 5, 'duration': 16.666666666666668}, 'text_data': 'y mulhivense\\nof jusenomenenn!\\n\\ntina\\n\\nHi! SS\\n\\nES \\\\\\\\k\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy HUSTLEZY\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy  HUSTLEZY\\n\\nFor Your Most\\nMemorable Moments HUSTLEZY HUSTLEZY\\n\\nKesariya\\nRanbir & Alia\\nSN\\na\\nco =\\n\\nS sell ndaf-\\n\\n=, deik aah = HUSTLEZY h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery Easy\\nof products customisation\\n\\ni, fi\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n= @\\n\\nAttractive range\\nFast delive\\nepee tl\\n\\nEas\\nusto! and ition'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-903960640750545\n",
      "Processing: hd-903960640750545\n",
      "this is result {'video': 'hd-903960640750545', 'visual_features': {'dominant_colors': [((55.337300000000006, 58.6858, 61.622), 1), ((55.3421, 58.6893, 61.616400000000006), 1), ((88.64280000000001, 108.92460000000001, 123.0747), 1), ((89.2733, 108.5978, 125.1858), 1), ((89.717, 109.4223, 137.9291), 1)], 'transitions': 6, 'duration': 15.2}, 'text_data': \"ie\\n\\nHUSTLEZY\\n\\nEverything is as promised!\\nThe quality and service are par\\nexcellence. A great buy! 6\\n\\nHUSTLEZY\\n\\nEverything is as promised!\\nThe quality and service are par\\nexcellence. A great buy! ie\\n\\nHUSTLEZY\\n\\n*\\n\\nwn\\nCc\\nKe)\\nS\\n\\n\\nSs)\\n\\nQ\\nx\\na\\n>\\n=\\nze)\\no\\nae)\\n\\n\\n)\\nx<\\nlu\\n\\nWSS\\nSCS,\\n\\nGreat value for money. Service is\\nalso too good. Highly recommended.\\n\\nLee\\nLL ttl tiie\\n\\nseewRNnn.\\n\\naBRwaaer\\n\\n:\\n< ;\\nSauRawen sss\\neS ARAREREN AS\\nSS Sy\\n.\\n4\\nyy\\n\\nSAR 4\\n\\nHUSTLEZY\\n\\nExceeded my expectations!\\nGreat value for money. Service is\\nalso too good. Highly recommended.\\n\\na\\n\\nLy\\n\\na\\n\\nLZ Se\\nLAL LY Lap\\n\\nLZZ\\n\\nLi iptt_\\nLitt peZ 6\\n\\nHUSTLEZY\\n\\nHf\\nYP\\nHTS\\n\\nExcellent Product\\nAttractive Design and Unique.\\nLoved the product! HUSTLEZY\\n\\nGreat stuff! I'm buying from\\nthem for the Ist time. But Im\\nsurely coming for more. HUSTLEZY\\n\\nGreat stuff! I'm buying from\\nthem for the Ist time. But Im\\nsurely coming for more. 6\\n\\nHUSTLEZY\\n\\nIts a cute gift for couples\\nWould suggest people 6\\n\\nHUSTLEZY\\n\\nIts a cute gift for couples\\nWould suggest people HUSTLEZY\\n\\nGet Your\\nPersonalised Illusion Lamps HUSTLEZY\\n\\nGet Your\\nPersonalised Illusion Lamps 6\\n\\nHUSTLEZY\\n\\nWT\\nAEE EE EEE ge 6\\n\\nHUSTLEZY\\n\\nNiven\\n\\nepee sete ieee\\nAEE EE EEE ge h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nAttractive range Fast delivery Easy\\nof products customisation f\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n\\n& |\\nAttractive rang Fast delivery Easy\\nof products customisation h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery\\nof products athe\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-902843234362370\n",
      "Processing: hd-902843234362370\n",
      "this is result {'video': 'hd-902843234362370', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-902309670925392\n",
      "Processing: hd-902309670925392\n",
      "this is result {'video': 'hd-902309670925392', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-9020567984620018\n",
      "Processing: hd-9020567984620018\n",
      "this is result {'video': 'hd-9020567984620018', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-901695498551491\n",
      "Processing: hd-901695498551491\n",
      "this is result {'video': 'hd-901695498551491', 'visual_features': {'dominant_colors': [((60.943200000000004, 55.573600000000006, 45.1064), 1), ((60.1235, 54.2881, 44.724700000000006), 1), ((57.273300000000006, 51.8303, 42.169000000000004), 1), ((144.0719, 158.14770000000001, 165.4686), 1), ((84.7919, 94.9681, 99.3861), 1)], 'transitions': 4, 'duration': 16.766666666666666}, 'text_data': 'ane iOa ie\\n\\nHUSTLEZY a\\n\\nHUSTLEZY\\nShop Now h\\n\\nHUSTLEZY\\nShop Now\\n\\nWe a\\n\\nmy FAST o\\n+ 7 oe\\n\\nAttractive Range Easy\\nAt Products Fast Delivery Customization'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-901272811190482\n",
      "Processing: hd-901272811190482\n",
      "this is result {'video': 'hd-901272811190482', 'visual_features': {'dominant_colors': [((127.71560000000001, 143.9805, 170.0011), 1), ((101.5818, 124.0476, 158.8992), 1), ((84.64840000000001, 106.3116, 142.5867), 1), ((98.62530000000001, 120.8168, 148.7554), 1), ((95.2089, 115.8246, 145.945), 1)], 'transitions': 5, 'duration': 16.666666666666668}, 'text_data': 'y mulhivense\\nof jusenomenenn!\\n\\ntina\\n\\nHi! SS\\n\\nES \\\\\\\\k\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy HUSTLEZY\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy  HUSTLEZY\\n\\nFor Your Most\\nMemorable Moments HUSTLEZY HUSTLEZY\\n\\nKesariya\\nRanbir & Alia\\nSN\\na\\nco =\\n\\nS sell ndaf-\\n\\n=, deik aah = HUSTLEZY h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery Easy\\nof products customisation\\n\\ni, fi\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n= @\\n\\nAttractive range\\nFast delive\\nepee tl\\n\\nEas\\nusto! and ition'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8995485367146316\n",
      "Processing: hd-8995485367146316\n",
      "this is result {'video': 'hd-8995485367146316', 'visual_features': {'dominant_colors': [((129.7374, 146.79170000000002, 152.42520000000002), 1), ((129.9078, 147.0496, 152.5256), 1), ((133.0109, 144.3932, 154.3015), 1), ((128.6303, 139.1468, 146.088), 1), ((126.42790000000001, 136.3923, 141.96630000000002), 1)], 'transitions': 1, 'duration': 11.7}, 'text_data': 'HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY fa\\n\\nHUSTLEZY HUSTLEZY\\n\\nSHOP NOW\\n\\nfe\\naS\\nAttractive range Easy\\n\\nFast delivery\\nof products Y customisation'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-898967424867870\n",
      "Processing: hd-898967424867870\n",
      "this is result {'video': 'hd-898967424867870', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-898103501380741\n",
      "Processing: hd-898103501380741\n",
      "this is result {'video': 'hd-898103501380741', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-897088088160051\n",
      "Processing: hd-897088088160051\n",
      "this is result {'video': 'hd-897088088160051', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-896589688256009\n",
      "Processing: hd-896589688256009\n",
      "this is result {'video': 'hd-896589688256009', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-895042408159688\n",
      "Processing: hd-895042408159688\n",
      "this is result {'video': 'hd-895042408159688', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-894559812351386\n",
      "Processing: hd-894559812351386\n",
      "this is result {'video': 'hd-894559812351386', 'visual_features': {'dominant_colors': [((197.0676, 199.38240000000002, 200.9772), 1), ((169.6987, 178.274, 199.6939), 1), ((184.6233, 186.2594, 195.2791), 1), ((177.7546, 179.1211, 188.32850000000002), 1), ((162.3778, 163.7296, 176.4379), 1)], 'transitions': 9, 'duration': 18.566666666666666}, 'text_data': 'L4\\n\\n) HUSTLEZY\\n| L |\\nat\\n\\nMy boyfriend was so excited\\nto show me what he got & | a\\nHUSTLEZY\\n\\na 4\\n\\nMy boyfriend was so excited\\nto show me what he got @ ni\\nHUSTLEZY\\n\\nN\\n\\nMy boyfriend was so excited\\nto show me what he got & |\\nPy \\n| f\\nHUSTLEZY\\n=\\nMy boyfri\\n\\nto show me\\n\\ne i)\\n\\nHUSTLEZY HUSTLEZY i\\n\\nHUSTLEZY 0\\nHUSTLEZY a\\n\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n@,'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-894457734962164\n",
      "Processing: hd-894457734962164\n",
      "this is result {'video': 'hd-894457734962164', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-894066258497958\n",
      "Processing: hd-894066258497958\n",
      "this is result {'video': 'hd-894066258497958', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-893539262677484\n",
      "Processing: hd-893539262677484\n",
      "this is result {'video': 'hd-893539262677484', 'visual_features': {'dominant_colors': [((88.3835, 90.1057, 92.7043), 1), ((81.8792, 83.2368, 86.1269), 1), ((69.44630000000001, 74.6301, 79.9996), 1), ((103.217, 135.14860000000002, 176.65890000000002), 1), ((98.3519, 129.6784, 170.4553), 1)], 'transitions': 8, 'duration': 23.133333333333333}, 'text_data': 'HUSTLEZY HUSTLEZY HUSTLEZY\\n\\nKEEPS\\n\\nyourOR YOUR ORDER\\n\\nOWN YOUR ours WITH PIE\\n\\nwanna HUSTLEZY 14\\nHUSTLEZY\\nMy HUSTLEZY. 4 HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY a\\n\\nHUSTLEZY\\nSho, h\\n\\nHUSTLEZY\\nShop Now\\n\\nha \\na\\n\\nAttractive Range\\n\\nAt Products Fast Delivery\\n\\nEasy\\nCustomization h\\n\\nHUSTLEZY\\nShop Now\\n\\nhe gh\\na | +\\n\\nAttractive Range\\n\\nAt Products Fast Delivery\\n\\na\\nCustomization h\\n\\nHUSTLEZY\\nShop Now\\n\\nhe ogy\\na | +\\n\\nAttractive Range\\n\\nAt Products Fast Delivery\\n\\na\\nCustomization'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-893173505441981\n",
      "Processing: hd-893173505441981\n",
      "this is result {'video': 'hd-893173505441981', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-892383375224287\n",
      "Processing: hd-892383375224287\n",
      "this is result {'video': 'hd-892383375224287', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-891661008828094\n",
      "Processing: hd-891661008828094\n",
      "this is result {'video': 'hd-891661008828094', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-891391212618023\n",
      "Processing: hd-891391212618023\n",
      "this is result {'video': 'hd-891391212618023', 'visual_features': {'dominant_colors': [((40.1036, 49.063300000000005, 60.1227), 1), ((54.093, 63.001900000000006, 75.28190000000001), 1), ((57.5636, 67.7836, 83.1187), 1), ((104.9689, 122.56, 157.12640000000002), 1), ((120.02340000000001, 138.0585, 176.0252), 1)], 'transitions': 2, 'duration': 14.133333333333333}, 'text_data': 'LOVE LAMP\\nPERSONALIZED LOVE LAMP\\nPERSONALIZED PLACE YOUR\\n\\n\"NAMES\\n~~ | PLACE YOUR\\n_ NAMES\\n= ZZ | _ :\\nPLACE*-YOUR\\nNAMES ,\\nAND A VERY\\nSPECIAL DATE \\nAND A VERY\\nSPECIAL DATE <A\\nTAND A VERY\\n\\nSPECIAL DATE ) ANDA\\' VERY\\nSPECIAL DATE'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-890166872024685\n",
      "Processing: hd-890166872024685\n",
      "this is result {'video': 'hd-890166872024685', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-889728479746704\n",
      "Processing: hd-889728479746704\n",
      "this is result {'video': 'hd-889728479746704', 'visual_features': {'dominant_colors': [((88.3835, 90.1057, 92.7043), 1), ((81.8792, 83.2368, 86.1269), 1), ((69.44630000000001, 74.6301, 79.9996), 1), ((103.217, 135.14860000000002, 176.65890000000002), 1), ((98.3519, 129.6784, 170.4553), 1)], 'transitions': 8, 'duration': 23.133333333333333}, 'text_data': 'HUSTLEZY HUSTLEZY HUSTLEZY\\n\\nKEEPS\\n\\nyourOR YOUR ORDER\\n\\nOWN YOUR ours WITH PIE\\n\\nwanna HUSTLEZY 14\\nHUSTLEZY\\nMy HUSTLEZY. 4 HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY a\\n\\nHUSTLEZY\\nSho, h\\n\\nHUSTLEZY\\nShop Now\\n\\nha \\na\\n\\nAttractive Range\\n\\nAt Products Fast Delivery\\n\\nEasy\\nCustomization h\\n\\nHUSTLEZY\\nShop Now\\n\\nhe gh\\na | +\\n\\nAttractive Range\\n\\nAt Products Fast Delivery\\n\\na\\nCustomization h\\n\\nHUSTLEZY\\nShop Now\\n\\nhe ogy\\na | +\\n\\nAttractive Range\\n\\nAt Products Fast Delivery\\n\\na\\nCustomization'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-888593019388197\n",
      "Processing: hd-888593019388197\n",
      "this is result {'video': 'hd-888593019388197', 'visual_features': {'dominant_colors': [((67.0586, 141.9863, 166.566), 1), ((66.6198, 145.8624, 168.3177), 1), ((69.5428, 99.1118, 129.6456), 1), ((65.3339, 123.0955, 149.1014), 1), ((74.8097, 145.1355, 170.54500000000002), 1)], 'transitions': 4, 'duration': 17.4}, 'text_data': 'He got me the cutest gift with picture of us @ He got me the cutest gift with picture of us %& 2\\n\\nHUSTLEZY He got me the cutest gift with picture of us @ aS\\n\\nHe got me the cutest gift with picture of us @& He got me the cutest gift with picture of us 44 He got me the cutest gift with picture of us 44\\n\\nThe Nigh;\\nLord Hues WO Met\\n\\nys\\n\\n~\\n<) Wty, He got me the cutest gift with picture of us #4 He got me the cutest gift with picture of us 44 He got me the cutest gift with picture of us 44 He got me the cutest gift with picture of us 44 He got me the cutest gift with picture of us 44 oN\\n\\nHe got me the cutest gift with picture of us @& oN\\n\\nHe got me the cutest gift with picture of us @& He got me the cutest gift with picture of us #4\\n\\nm. I a\\n\\nat\\n\\nThe Night We Met He got me the cutest gift with picture of us 44 He got me the cutest gift with picture of us #4 HUSTLEZY\\n& | & |  fl\\n\\nHUSTLEZY\\n\\n& | & | \\n\\nAttractive range\\nof products Fost delivery\" customisation\\n\\nfy'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-885689066019680\n",
      "Processing: hd-885689066019680\n",
      "this is result {'video': 'hd-885689066019680', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-885670366433640\n",
      "Processing: hd-885670366433640\n",
      "this is result {'video': 'hd-885670366433640', 'visual_features': {'dominant_colors': [((37.6229, 76.2752, 149.1895), 1), ((35.9318, 66.8463, 131.80960000000002), 1), ((27.143700000000003, 49.141200000000005, 106.9756), 1), ((44.2479, 77.5086, 116.1439), 1), ((37.9638, 77.9847, 127.71390000000001), 1)], 'transitions': 8, 'duration': 19.133333333333333}, 'text_data': \"Imagine receiving this beautiful camera\\nroll keychain this Valentine's day Imagine receiving this beautiful camera\\nroll keychain this Valentine's day il\\n\\n_ foo ef Imagine receiving this beautiful \\nroll keychain this Valentin roll keychain Valentine's day\\n\\nImagine receivii is beautiful camera |\\n\\n~ oo ae 4 Imagine peiving this beautiful camega\\nroll keychain this Valentine's day r\\n\\nWr Tr BD: Imagine receiving this beautiful camera\\nroll keychain this Valentine's day e\\ng\\n\\nig this beautiful era\\nis Valentine's\\n\\nIm:\\nrol f\\n\\ngine rec is beautiful camera\\nI keychaii alentinesday _@ i\\n\\n9\\n2\\na\\n>\\n\\\\ magine receiv ae\\nkeychain this Valentine's day s beautiful camera\\nis Valentine's day >\\n\\nSr ar Wb: HUSTLEZY\\n\\n& | \\n\\nAttractive range! rast delivery Easy\\nof products customisation HUSTLEZY\\n\\nSHOP NOW\\n\\nie\\nci\\nAttractive range Easy\\n\\nFast deliver\\nof products J customisation h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nity\\nAe\\nAttractive range Easy\\n\\nFast delivery\\n\\nof products customisation a\\n\\nHUSTLEZY\\n\\nes | \\n\\nFast delivery Eas|\\ncustomisation\\n\\nafte\\n\\naS\\n\\nAttractive range\\nof products h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nity\\naS\\nAttractive range Easy\\n\\nFast delivery\\n\\nof products customisation\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-885209946993560\n",
      "Processing: hd-885209946993560\n",
      "this is result {'video': 'hd-885209946993560', 'visual_features': {'dominant_colors': [((197.00070000000002, 199.4559, 200.9419), 1), ((169.7367, 178.3076, 199.6712), 1), ((184.6749, 186.2974, 195.42430000000002), 1), ((177.9735, 179.1964, 188.6276), 1), ((162.5084, 163.73340000000002, 176.5335), 1)], 'transitions': 8, 'duration': 18.566666666666666}, 'text_data': '|\\nn\\\\\\n\\n} HUSTLEZY\\nI a\\nA J\\n\\nMy boyfriend was so excited\\nto show me what he got & | a\\nHUSTLEZY\\n\\nMy boyfriend was so excited\\nto show me what he got & 0\\nHUSTLEZY\\n\\n=\\n\\nMy boyfriend was so excited\\nto show me what he got & = |\\nMy Boye was so excited\\nto show me what he got & oy\\nHUSTLEZY\\n\\n as\\n|\\nNv\\n\\nHUSTLEZY HUSTLEZY Ai\\n\\nHUSTLEZY a\\n\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n@,'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-882993126248062\n",
      "Processing: hd-882993126248062\n",
      "this is result {'video': 'hd-882993126248062', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-882867522830120\n",
      "Processing: hd-882867522830120\n",
      "this is result {'video': 'hd-882867522830120', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-882019143545185\n",
      "Processing: hd-882019143545185\n",
      "this is result {'video': 'hd-882019143545185', 'visual_features': {'dominant_colors': [((77.3836, 92.3279, 108.3499), 1), ((83.3159, 94.56230000000001, 108.5942), 1), ((80.8858, 95.8392, 110.4551), 1), ((86.5366, 111.65910000000001, 151.50910000000002), 1), ((67.181, 90.321, 151.96), 1)], 'transitions': 8, 'duration': 16.366666666666667}, 'text_data': 'some A. forever * Some bonds are meant to last forever ** om Gently clean the glass\\nProtective cover\\n\\nwith @ soft cloth .\\n\\nTHANK YOU FOR YOUR ORDER\\n\\nCrafted By Hand Made With Love are meant to last orev, Nore\\n\\n* how You sof YP vour Nustiony lamp \\n\\nAX\\n\\nBlais wei,), are\\n\\nCoretulty ne \" Gently cte \"rh the Glossy\\nBM the sige, Protective covey with a On clos  ee\\n\\nes\\n\\n\\n\\nss mith e@re c \\n_ estes\\n\\n Pesion \\n\\nwally Clean the Glass\\noa ts a SOff clom\\n\\nwith i,\\n\\nmeant to last forever *% ~\\n\\nChal Chale Apne Ghar ~ ;\\n\\n@hustlezy_\\n\\nChal Chale Apne Ghar\\n\\n= ca\\n\\neant to last forever -*y @hustlezy_\\n\\nSome bonds are meant to last forever - Some bonds are meant to last forever @hustlezy_\\n\\nSome bonds are meant to last forever Some bonds are meant to last forever  h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nWy,\\n& | %\\nAttractive range Easy\\n\\nFast delivery\\nof products customisation h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nwy\\n4S\\nAttractive range Easy\\n\\nFast deliver\\nof products Y customisation'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-881925359723909\n",
      "Processing: hd-881925359723909\n",
      "this is result {'video': 'hd-881925359723909', 'visual_features': {'dominant_colors': [((55.337300000000006, 58.6858, 61.622), 1), ((55.3421, 58.6893, 61.616400000000006), 1), ((88.64280000000001, 108.92460000000001, 123.0747), 1), ((89.2733, 108.5978, 125.1858), 1), ((89.717, 109.4223, 137.9291), 1)], 'transitions': 6, 'duration': 15.2}, 'text_data': \"ie\\n\\nHUSTLEZY\\n\\nEverything is as promised!\\nThe quality and service are par\\nexcellence. A great buy! 6\\n\\nHUSTLEZY\\n\\nEverything is as promised!\\nThe quality and service are par\\nexcellence. A great buy! ie\\n\\nHUSTLEZY\\n\\n*\\n\\nwn\\nCc\\nKe)\\nS\\n\\n\\nSs)\\n\\nQ\\nx\\na\\n>\\n=\\nze)\\no\\nae)\\n\\n\\n)\\nx<\\nlu\\n\\nWSS\\nSCS,\\n\\nGreat value for money. Service is\\nalso too good. Highly recommended.\\n\\nLee\\nLL ttl tiie\\n\\nseewRNnn.\\n\\naBRwaaer\\n\\n:\\n< ;\\nSauRawen sss\\neS ARAREREN AS\\nSS Sy\\n.\\n4\\nyy\\n\\nSAR 4\\n\\nHUSTLEZY\\n\\nExceeded my expectations!\\nGreat value for money. Service is\\nalso too good. Highly recommended.\\n\\na\\n\\nLy\\n\\na\\n\\nLZ Se\\nLAL LY Lap\\n\\nLZZ\\n\\nLi iptt_\\nLitt peZ 6\\n\\nHUSTLEZY\\n\\nHf\\nYP\\nHTS\\n\\nExcellent Product\\nAttractive Design and Unique.\\nLoved the product! HUSTLEZY\\n\\nGreat stuff! I'm buying from\\nthem for the Ist time. But Im\\nsurely coming for more. HUSTLEZY\\n\\nGreat stuff! I'm buying from\\nthem for the Ist time. But Im\\nsurely coming for more. 6\\n\\nHUSTLEZY\\n\\nIts a cute gift for couples\\nWould suggest people 6\\n\\nHUSTLEZY\\n\\nIts a cute gift for couples\\nWould suggest people HUSTLEZY\\n\\nGet Your\\nPersonalised Illusion Lamps HUSTLEZY\\n\\nGet Your\\nPersonalised Illusion Lamps 6\\n\\nHUSTLEZY\\n\\nWT\\nAEE EE EEE ge 6\\n\\nHUSTLEZY\\n\\nNiven\\n\\nepee sete ieee\\nAEE EE EEE ge h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nAttractive range Fast delivery Easy\\nof products customisation f\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n\\n& |\\nAttractive rang Fast delivery Easy\\nof products customisation h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery\\nof products athe\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-881342303358042\n",
      "Processing: hd-881342303358042\n",
      "this is result {'video': 'hd-881342303358042', 'visual_features': {'dominant_colors': [((114.09870000000001, 169.7157, 172.5592), 1), ((113.77940000000001, 169.811, 172.3261), 1), ((113.8751, 169.7614, 172.41920000000002), 1), ((113.735, 169.7741, 172.3406), 1), ((113.6453, 169.809, 172.2821), 1)], 'transitions': 9, 'duration': 21.166666666666668}, 'text_data': \"Tell us you're a football fan without\\n\\nactually ~- telling us. I'll go first. Tell us you're a football fan without\\n\\nactually ~~ telling us. I'll go first. %\\n\\nTell us you're a football fan without\\n\\nactually ~~ telling us. I'll go first. %\\n\\nTell us you're a football fan without\\n\\nactually ~~ telling us. I'll go first. %\\n\\nTell us you're a football fan without\\n\\nactually ~~ telling us. I'll go first. GET YOUR LUMINOUS LOGO NOW! { or\\n\\n~ ft\\n\\nGET YOUR LUMINOUS LOGO NOW!\\n\\nHUSTLEZY GET YOUR LUMINOUS LOGO NOW! | HUSTLEZY\\n\\nGET YOUR LUMINOUS LOGO NOW! HUSTLEZY HUSTLEZY HUSTLEZY BA:\\nb e\\nC (3) le)\\n\\noe\\n\\nWa EUs Al\\n\\nHUSTLEZY\\n\\n7\\n\\nee Oe oe\\n\\nCUSTOMISATION AVAILABLE!\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8806609246079208\n",
      "Processing: hd-8806609246079208\n",
      "this is result {'video': 'hd-8806609246079208', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-880568190186256\n",
      "Processing: hd-880568190186256\n",
      "this is result {'video': 'hd-880568190186256', 'visual_features': {'dominant_colors': [((184.3398, 109.8662, 17.2589), 1), ((36.9028, 47.6225, 52.2409), 1), ((41.017700000000005, 47.9979, 49.4388), 1), ((43.080000000000005, 50.0657, 49.9728), 1), ((40.0704, 47.985600000000005, 50.5394), 1)], 'transitions': 5, 'duration': 18.833272114068187}, 'text_data': '_ as\\n\\\\rsnneeemeuetnl\\n| is | SS Bed eo\\n\\\\\\n\\n~\\nPS\\na 4\\n\\nane jaeeen a6 i 2\\n8\\nQ\\n2\\n2\\n3\\n8\\n8 title. \\' ;\\nmien\\n\\n= ie tal a | IEEE RRR RRR RSPR R Rea\\n: aie\\n\\njw -\\n\\n| a  r |\\n\\nie = ne 2A 4\\n\\na *\\n\\na -\\n\\na\\n\\nty 1G il\\n\\\\Utuneeenesssses!! wa\\nOnn\\n: <\\nBana |\\neas i\\npotiu fa\\n\\nHUSTLEZY fa\\n\\nHUSTLEZY\\n\\naS eb\\n\\nAttractive range! Fact deliver Easy\\nof products delivery\" customisation\\n\\nSe'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-880340126836307\n",
      "Processing: hd-880340126836307\n",
      "this is result {'video': 'hd-880340126836307', 'visual_features': {'dominant_colors': [((102.51230000000001, 114.52720000000001, 132.9002), 1), ((102.5167, 113.5724, 128.8305), 1), ((106.1512, 117.3991, 129.61090000000002), 1), ((107.6436, 119.81790000000001, 131.8808), 1), ((111.78020000000001, 121.2172, 142.78), 1)], 'transitions': 5, 'duration': 18.833333333333332}, 'text_data': '@ nikuofficial_01\\n\\nI NEED to get this for my bf &\\n\\nxz\\ng\\n7!\\nrs]\\nPad\\niN\\n\\n4 0\\nfut\\nes\\n3\\n\\nmy\\noF for my bf \\n\\n@ nikuofficial_O1\\nINEED to get\\n\\nx\\ng\\ncat\\n2\\n>\\nN\\nun)\\n_ Oo\\nfat\\nxo) @ nikuofficial_01\\n\\nI NEED to get this for my bf \\nReply\\n\\nz\\n2\\na\\nro)\\n>\\ni)\\n109\\n3 0\\nBw\\nBo @ nikuofficial_01\\nI NEED to get this for my bf & nikuofficial & nikuofficial_01\\nI NEED to get this for my bf @ nikuofficial_01 2:\\nI NEED to get this for my bf @ nikuofficial_01\\nI NEED to get this for my bf @ @ nikuofficial_01\\nI NEED to get this for my bf & nikuofficial_01\\nI NEED to get this for my bf & nikuofficial_01 2:\\nI NEED to get this for my bf & nikuofficial_01\\nI NEED to get this for my bf & nikuofficial_01\\nI NEED to get this for my bf & @ nikuofficial_01\\nI NEED to get this for my bf & @ nikuofficial_01\\nI NEED to get this for my bf & HUSTLEZY HUSTLEZY'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8796411607036992\n",
      "Processing: hd-8796411607036992\n",
      "this is result {'video': 'hd-8796411607036992', 'visual_features': {'dominant_colors': [((123.1255, 142.66140000000001, 149.9293), 1), ((123.09440000000001, 142.6823, 149.93030000000002), 1), ((126.9397, 141.2715, 154.5523), 1), ((119.2351, 131.94140000000002, 141.6231), 1), ((116.7629, 129.0337, 137.21030000000002), 1)], 'transitions': 1, 'duration': 12.0}, 'text_data': 'ad\\nUa\\n\\n\\\\ Sr)\\n\\napn J NY\\n\\nene / HUSTLEZY h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nvy,\\nwey\\n4S\\nAttractive range Easy\\n\\nFast delivery\\n\\nof products customisation'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-879631723735807\n",
      "Processing: hd-879631723735807\n",
      "this is result {'video': 'hd-879631723735807', 'visual_features': {'dominant_colors': [((183.4101, 174.89350000000002, 171.57340000000002), 1), ((182.5924, 175.0035, 171.02790000000002), 1), ((180.3655, 172.9982, 169.11260000000001), 1), ((49.2295, 119.09410000000001, 147.9128), 1), ((44.2488, 122.6187, 158.4302), 1)], 'transitions': 6, 'duration': 16.5}, 'text_data': \"HUSTLEZY HUSTLEZY\\n\\n) 5 HUSTLEZY HUSTLEZY\\n\\nbaad oom\\n\\n<\\n\\ne\\nSTRANGE TRAILS\\nspy BS (j\\nES\\n\\nimer *G\\n\\noe\\ne\\n\\nHorry Styies\\n\\nStephen Sanches Cults\\nTyler, The Creator\\n\\nMas\\n\\nCurrent Joys\\n\\nAppoars on wom\\n\\n< @\\nSTRANGE TRAILS\\n\\nSect y\\n\\nSHUFFLED WITH\\n\\nBon Iver Beech Baby + Harry Styles\\n\\nStephen Sanchez Until | F + Cults\\ny + Current Joys & + Tyler, The Creator\\nT F N' + M83\\nAppears on\\n *end credit  fi\\n\\nHUSTLEZY hh\\n\\nHUSTLEZY\\nShop Now\\n\\nAttractive Range Fast Delivery\\n\\nEasy\\nAt Products Customization hh\\n\\nHUSTLEZY\\nShop Now\\n\\n* ~ * q-\\na oy )\\n\\n& | -o\\n\\nAttractive Range Eas)\\n\\nAt Products Fast Delivery\\n\\na\\nCustomization hh\\n\\nHUSTLEZY\\nShop Now\\n\\n* x * q-\\n= oO\\nel a o\\nAttractive Range Fast Delivery Easy\\n\\nAt Products Customization\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-879049300656635\n",
      "Processing: hd-879049300656635\n",
      "this is result {'video': 'hd-879049300656635', 'visual_features': {'dominant_colors': [((40.1036, 49.063300000000005, 60.1227), 1), ((54.093, 63.001900000000006, 75.28190000000001), 1), ((57.5636, 67.7836, 83.1187), 1), ((104.9689, 122.56, 157.12640000000002), 1), ((120.02340000000001, 138.0585, 176.0252), 1)], 'transitions': 2, 'duration': 14.133333333333333}, 'text_data': 'LOVE LAMP\\nPERSONALIZED LOVE LAMP\\nPERSONALIZED PLACE YOUR\\n\\n\"NAMES\\n~~ | PLACE YOUR\\n_ NAMES\\n= ZZ | _ :\\nPLACE*-YOUR\\nNAMES ,\\nAND A VERY\\nSPECIAL DATE \\nAND A VERY\\nSPECIAL DATE <A\\nTAND A VERY\\n\\nSPECIAL DATE ) ANDA\\' VERY\\nSPECIAL DATE'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877975993416760\n",
      "Processing: hd-877975993416760\n",
      "this is result {'video': 'hd-877975993416760', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877662697022279\n",
      "Processing: hd-877662697022279\n",
      "this is result {'video': 'hd-877662697022279', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877511836784655\n",
      "Processing: hd-877511836784655\n",
      "this is result {'video': 'hd-877511836784655', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877210454387561\n",
      "Processing: hd-877210454387561\n",
      "this is result {'video': 'hd-877210454387561', 'visual_features': {'dominant_colors': [((235.0475, 235.0077, 230.5274), 1), ((235.06990000000002, 234.9726, 230.4563), 1), ((235.07180000000002, 234.9794, 230.4567), 1), ((235.0697, 234.9806, 230.4599), 1), ((109.11890000000001, 117.7168, 138.6926), 1)], 'transitions': 5, 'duration': 18.833333333333332}, 'text_data': '@ee0eo Airte! LTE 4:08 PM =>\\n\\n< Messages Shubh <3 Details\\n\\nHey babe, you know\\nabout that thing you kept\\ntelling about??\\n\\n| got it for you, come\\n\\ndown!!\\nThis better not be a\\njoke...\\n\\nSo my boyfriend texted\\nme saying he has a suprise\\nfor me!! @eeeo Airte! LTE 4:08 PM =>\\n\\n< Messages Shubh <3 Details\\n\\nHey babe, you know\\nabout that thing you kept\\ntelling about??\\n\\n| got it for you, come\\n\\ndown!!\\nThis better not be a\\njoke...\\n\\nSo my boyfriend texted\\nme saying he has a suprise\\nfor me!! e@eeeo Airte! LTE 4:08 PM =>\\n\\n< Messages Shubh <3 Details\\n\\nHey babe, you know\\nabout that thing you kept\\ntelling about??\\n\\n| got it for you, come\\n\\ndown!!\\nThis better not be a\\njoke...\\n\\nSo my boyfriend texted\\nme saying he has a suprise\\nfor me!! e@eeeo Airte! LTE 4:08 PM =>\\n\\n< Messages Shubh <3 Details\\n\\nHey babe, you know\\nabout that thing you kept\\ntelling about??\\n\\n| got it for you, come\\n\\ndown!!\\nThis better not be a\\njoke...\\n\\nSo my boyfriend texted\\nme saying he has a suprise\\nfor me!! fi\\n\\nHUSTLEZY fi\\n\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877129693575192\n",
      "Processing: hd-877129693575192\n",
      "this is result {'video': 'hd-877129693575192', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-875485623676104\n",
      "Processing: hd-875485623676104\n",
      "this is result {'video': 'hd-875485623676104', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874747697073121\n",
      "Processing: hd-874747697073121\n",
      "this is result {'video': 'hd-874747697073121', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874543520932484\n",
      "Processing: hd-874543520932484\n",
      "this is result {'video': 'hd-874543520932484', 'visual_features': {'dominant_colors': [((114.09870000000001, 169.7157, 172.5592), 1), ((113.77940000000001, 169.811, 172.3261), 1), ((113.8751, 169.7614, 172.41920000000002), 1), ((113.735, 169.7741, 172.3406), 1), ((113.6453, 169.809, 172.2821), 1)], 'transitions': 9, 'duration': 21.166666666666668}, 'text_data': \"Tell us you're a football fan without\\n\\nactually ~- telling us. I'll go first. Tell us you're a football fan without\\n\\nactually ~~ telling us. I'll go first. %\\n\\nTell us you're a football fan without\\n\\nactually ~~ telling us. I'll go first. %\\n\\nTell us you're a football fan without\\n\\nactually ~~ telling us. I'll go first. %\\n\\nTell us you're a football fan without\\n\\nactually ~~ telling us. I'll go first. GET YOUR LUMINOUS LOGO NOW! { or\\n\\n~ ft\\n\\nGET YOUR LUMINOUS LOGO NOW!\\n\\nHUSTLEZY GET YOUR LUMINOUS LOGO NOW! | HUSTLEZY\\n\\nGET YOUR LUMINOUS LOGO NOW! HUSTLEZY HUSTLEZY HUSTLEZY BA:\\nb e\\nC (3) le)\\n\\noe\\n\\nWa EUs Al\\n\\nHUSTLEZY\\n\\n7\\n\\nee Oe oe\\n\\nCUSTOMISATION AVAILABLE!\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874190910572544\n",
      "Processing: hd-874190910572544\n",
      "this is result {'video': 'hd-874190910572544', 'visual_features': {'dominant_colors': [((127.71560000000001, 143.9805, 170.0011), 1), ((101.5818, 124.0476, 158.8992), 1), ((84.64840000000001, 106.3116, 142.5867), 1), ((98.62530000000001, 120.8168, 148.7554), 1), ((95.2089, 115.8246, 145.945), 1)], 'transitions': 5, 'duration': 16.666666666666668}, 'text_data': 'y mulhivense\\nof jusenomenenn!\\n\\ntina\\n\\nHi! SS\\n\\nES \\\\\\\\k\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy HUSTLEZY\\n\\nHUSTLEZY\\n\\nGet The Best Gifts Only On\\nHustlezy  HUSTLEZY\\n\\nFor Your Most\\nMemorable Moments HUSTLEZY HUSTLEZY\\n\\nKesariya\\nRanbir & Alia\\nSN\\na\\nco =\\n\\nS sell ndaf-\\n\\n=, deik aah = HUSTLEZY h\\nHUSTLEZY\\n\\nSHOP NOW\\n= | \\n\\nAttractive range Fast delivery Easy\\nof products customisation\\n\\ni, fi\\n\\nHUSTLEZY\\n\\nSHOP NOW\\n= @\\n\\nAttractive range\\nFast delive\\nepee tl\\n\\nEas\\nusto! and ition'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874084244131796\n",
      "Processing: hd-874084244131796\n",
      "this is result {'video': 'hd-874084244131796', 'visual_features': {'dominant_colors': [((102.51230000000001, 114.52720000000001, 132.9002), 1), ((102.5167, 113.5724, 128.8305), 1), ((106.1512, 117.3991, 129.61090000000002), 1), ((107.6436, 119.81790000000001, 131.8808), 1), ((111.78020000000001, 121.2172, 142.78), 1)], 'transitions': 5, 'duration': 18.833333333333332}, 'text_data': '@ nikuofficial_01\\n\\nI NEED to get this for my bf &\\n\\nxz\\ng\\n7!\\nrs]\\nPad\\niN\\n\\n4 0\\nfut\\nes\\n3\\n\\nmy\\noF for my bf \\n\\n@ nikuofficial_O1\\nINEED to get\\n\\nx\\ng\\ncat\\n2\\n>\\nN\\nun)\\n_ Oo\\nfat\\nxo) @ nikuofficial_01\\n\\nI NEED to get this for my bf \\nReply\\n\\nz\\n2\\na\\nro)\\n>\\ni)\\n109\\n3 0\\nBw\\nBo @ nikuofficial_01\\nI NEED to get this for my bf & nikuofficial & nikuofficial_01\\nI NEED to get this for my bf @ nikuofficial_01 2:\\nI NEED to get this for my bf @ nikuofficial_01\\nI NEED to get this for my bf @ @ nikuofficial_01\\nI NEED to get this for my bf & nikuofficial_01\\nI NEED to get this for my bf & nikuofficial_01 2:\\nI NEED to get this for my bf & nikuofficial_01\\nI NEED to get this for my bf & nikuofficial_01\\nI NEED to get this for my bf & @ nikuofficial_01\\nI NEED to get this for my bf & @ nikuofficial_01\\nI NEED to get this for my bf & HUSTLEZY HUSTLEZY'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-873560550525047\n",
      "Processing: hd-873560550525047\n",
      "this is result {'video': 'hd-873560550525047', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-873043573965895\n",
      "Processing: hd-873043573965895\n",
      "this is result {'video': 'hd-873043573965895', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-872760463806517\n",
      "Processing: hd-872760463806517\n",
      "this is result {'video': 'hd-872760463806517', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-872400620956045\n",
      "Processing: hd-872400620956045\n",
      "this is result {'video': 'hd-872400620956045', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-872222594086011\n",
      "Processing: hd-872222594086011\n",
      "this is result {'video': 'hd-872222594086011', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8715627171842855\n",
      "Processing: hd-8715627171842855\n",
      "this is result {'video': 'hd-8715627171842855', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-871286287458461\n",
      "Processing: hd-871286287458461\n",
      "this is result {'video': 'hd-871286287458461', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-871185627435460\n",
      "Processing: hd-871185627435460\n",
      "this is result {'video': 'hd-871185627435460', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-818776323774715\n",
      "Processing: hd-818776323774715\n",
      "this is result {'video': 'hd-818776323774715', 'visual_features': {'dominant_colors': [((197.00070000000002, 199.4559, 200.9419), 1), ((169.7367, 178.3076, 199.6712), 1), ((184.6749, 186.2974, 195.42430000000002), 1), ((177.9735, 179.1964, 188.6276), 1), ((162.5084, 163.73340000000002, 176.5335), 1)], 'transitions': 8, 'duration': 18.566666666666666}, 'text_data': '|\\nn\\\\\\n\\n} HUSTLEZY\\nI a\\nA J\\n\\nMy boyfriend was so excited\\nto show me what he got & | a\\nHUSTLEZY\\n\\nMy boyfriend was so excited\\nto show me what he got & 0\\nHUSTLEZY\\n\\n=\\n\\nMy boyfriend was so excited\\nto show me what he got & = |\\nMy Boye was so excited\\nto show me what he got & oy\\nHUSTLEZY\\n\\n as\\n|\\nNv\\n\\nHUSTLEZY HUSTLEZY Ai\\n\\nHUSTLEZY a\\n\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n@,'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-818462803696191\n",
      "Processing: hd-818462803696191\n",
      "this is result {'video': 'hd-818462803696191', 'visual_features': {'dominant_colors': [((197.00070000000002, 199.4559, 200.9419), 1), ((169.7367, 178.3076, 199.6712), 1), ((184.6749, 186.2974, 195.42430000000002), 1), ((177.9735, 179.1964, 188.6276), 1), ((162.5084, 163.73340000000002, 176.5335), 1)], 'transitions': 8, 'duration': 18.566666666666666}, 'text_data': '|\\nn\\\\\\n\\n} HUSTLEZY\\nI a\\nA J\\n\\nMy boyfriend was so excited\\nto show me what he got & | a\\nHUSTLEZY\\n\\nMy boyfriend was so excited\\nto show me what he got & 0\\nHUSTLEZY\\n\\n=\\n\\nMy boyfriend was so excited\\nto show me what he got & = |\\nMy Boye was so excited\\nto show me what he got & oy\\nHUSTLEZY\\n\\n as\\n|\\nNv\\n\\nHUSTLEZY HUSTLEZY Ai\\n\\nHUSTLEZY a\\n\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n@,'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-817763467176157\n",
      "Processing: hd-817763467176157\n",
      "this is result {'video': 'hd-817763467176157', 'visual_features': {'dominant_colors': [((174.2681, 169.87290000000002, 178.1218), 1), ((173.0745, 168.63490000000002, 178.0112), 1), ((176.45520000000002, 172.2117, 179.36020000000002), 1), ((177.0358, 171.3617, 173.9686), 1), ((180.03050000000002, 170.6566, 172.63490000000002), 1)], 'transitions': 0, 'duration': 22.0}, 'text_data': 'He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4\\n\\n= i)\\n\\n4 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\n\\nwith pictures of us %\\n\\nDe He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-817475239730695\n",
      "Processing: hd-817475239730695\n",
      "this is result {'video': 'hd-817475239730695', 'visual_features': {'dominant_colors': [((162.738, 172.1322, 195.38060000000002), 1), ((164.6121, 172.9941, 193.5393), 1), ((174.82160000000002, 182.1211, 196.3606), 1), ((178.6114, 185.35330000000002, 196.7475), 1), ((179.34560000000002, 186.4318, 197.2319), 1)], 'transitions': 0, 'duration': 13.066666666666666}, 'text_data': \"HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\\n\\nSSHUSTLEZY HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at securit HUST!\\n\\nReply to Divyanas comment\\n\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security!  A\\n\\nHUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security!  HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess!\\nJust dont try flashing it at security: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at security HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\naccess! &P\\n\\nJust dont try flashing it at securit: HUSTLEZY\\n\\nReply to Divyanas comment\\nForget the Dil-Luminati Fan Pit\\npasses, this keychain's your true VIP\\n\\naccess! 2\\nJust dont try flashing it at security:\"}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-817135236672734\n",
      "Processing: hd-817135236672734\n",
      "this is result {'video': 'hd-817135236672734', 'visual_features': {'dominant_colors': [((136.5566, 118.4003, 59.1584), 1), ((20.9134, 29.807000000000002, 33.3522), 1), ((24.3199, 30.0441, 31.1522), 1), ((25.9284, 31.7575, 31.7119), 1), ((23.9681, 30.652700000000003, 32.607800000000005), 1)], 'transitions': 6, 'duration': 19.998664529914528}, 'text_data': '7t0e tay\\n\\n(ip iy) amin!\\n\\nraw\\ne SG i\\n\\n:\\n\\nS|\\n\\n=\\nv\\nie)\\naR\\n2\\n>\\nN\\n9\\nis) a LMP mie\\n= MEER ER ERT EE TRERETILL nenertsy peat\\nTUT T ee\\na fi\\n\\nHUSTLEZY fl\\n\\nHUSTLEZY\\n\\na> a\\n\\nAttractive range A s\\nFast deliver\\nof products Y customisation\\n\\noe'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-816335920524988\n",
      "Processing: hd-816335920524988\n",
      "this is result {'video': 'hd-816335920524988', 'visual_features': {'dominant_colors': [((192.8855, 195.41570000000002, 197.5197), 1), ((174.8136, 181.90980000000002, 197.29850000000002), 1), ((174.3502, 177.0001, 188.5534), 1), ((169.31230000000002, 171.15, 180.4999), 1), ((155.0868, 155.43210000000002, 167.72240000000002), 1)], 'transitions': 7, 'duration': 18.566666666666666}, 'text_data': 'HUSTLEZY\\n\\nMy boyfriend was so excited\\nto show me what he got & { A\\\\\\nHUSTLEZY\\n\\nMy boyfriend was so excited\\nto show me what he got &@ ]\\nLA\\nHUSTLEZY\\n\\n_\\n\\nMy boyfriend was so excited\\nto show me what he got & HUSTLEZY\\n\\n= uy boyfriend was so excited\\n\\nto show me what he got &\\n\\n HUSTLEZY\\n\\nSEER.\\n\\nMAN YOUN You onan\\nOY YOU Guns oe =. HUSTLEZY h\\nHUSTLEZY Ph\\n|\\n\\n7)\\n\\nHUSTLEZY AY\\nh \\\\\\nHUSTLEZY HUSTLEZY HUSTLEZY a\\n\\nHUSTLEZY\\n\\n#GiftEzwithHustlezy\\n\\n@'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-814072014151046\n",
      "Processing: hd-814072014151046\n",
      "this is result {'video': 'hd-814072014151046', 'visual_features': {'dominant_colors': [((125.18870000000001, 158.2698, 195.2244), 1), ((119.2309, 150.5593, 188.14870000000002), 1), ((117.7821, 148.9939, 186.75410000000002), 1), ((140.2981, 155.8392, 183.3502), 1), ((142.0641, 157.0436, 181.38590000000002), 1)], 'transitions': 2, 'duration': 13.233333333333333}, 'text_data': 'HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY HUSTLEZY [i\\n\\nHUSTLEZY\\n\\nSHOP NOW fi\\n\\nHUSTLEZY\\n\\nS| & | \\n\\nWww\\nAttractive range Fast delivery Eas\\nof products customisation h\\nHUSTLEZY\\n\\nSHOP NOW\\n\\nwee\\nax\\nAttractive range Easy\\n\\nFast deliver\\nof products Y customisation'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-811606650922029\n",
      "Processing: hd-811606650922029\n",
      "this is result {'video': 'hd-811606650922029', 'visual_features': {'dominant_colors': [((174.2681, 169.87290000000002, 178.1218), 1), ((173.0745, 168.63490000000002, 178.0112), 1), ((176.45520000000002, 172.2117, 179.36020000000002), 1), ((177.0358, 171.3617, 173.9686), 1), ((180.03050000000002, 170.6566, 172.63490000000002), 1)], 'transitions': 0, 'duration': 22.0}, 'text_data': 'He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4\\n\\n= i)\\n\\n4 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\nwith pictures of us 44 He got me the cutest camera roll keychain\\n\\nwith pictures of us %\\n\\nDe He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4 He got me the cutest camera roll keychain\\nwith pictures of us #4'}\n",
      "/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8111507755613955\n",
      "Processing: hd-8111507755613955\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/ImageFile.py:547\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[1;32m    548\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature extraction complete! Results saved to video_features.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Call the function with dataset file\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mprocess_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos_without_faces.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 42\u001b[0m, in \u001b[0;36mprocess_videos\u001b[0;34m(video_dir, dataset_file)\u001b[0m\n\u001b[1;32m     40\u001b[0m visual_features \u001b[38;5;241m=\u001b[39m extract_visual_features(video_path)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# audio_features = extract_audio_features(video_path)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m text_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_from_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m\"\u001b[39m: video_file,\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisual_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: visual_features,\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# \"audio_features\": audio_features,\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_data\u001b[39m\u001b[38;5;124m\"\u001b[39m: text_data\n\u001b[1;32m     49\u001b[0m }\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis is result\u001b[39m\u001b[38;5;124m\"\u001b[39m,result)\n",
      "Cell \u001b[0;32mIn[40], line 17\u001b[0m, in \u001b[0;36mextract_text_from_frames\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Convert to grayscale for OCR\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m---> 17\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     texts\u001b[38;5;241m.\u001b[39mappend(text\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m     19\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pytesseract/pytesseract.py:486\u001b[0m, in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m--> 486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pytesseract/pytesseract.py:489\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    487\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[1;32m    488\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[0;32m--> 489\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    490\u001b[0m }[output_type]()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pytesseract/pytesseract.py:341\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_and_get_output\u001b[39m(\n\u001b[1;32m    333\u001b[0m     image,\n\u001b[1;32m    334\u001b[0m     extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m     return_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    340\u001b[0m ):\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[1;32m    342\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    343\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[1;32m    344\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    350\u001b[0m         }\n\u001b[1;32m    352\u001b[0m         run_tesseract(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pytesseract/pytesseract.py:216\u001b[0m, in \u001b[0;36msave\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    214\u001b[0m         image, extension \u001b[38;5;241m=\u001b[39m prepare(image)\n\u001b[1;32m    215\u001b[0m         input_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_input\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 216\u001b[0m         \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\u001b[38;5;241m.\u001b[39mname, input_file_name\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2568\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2565\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[1;32m   2567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2568\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/PngImagePlugin.py:1431\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[1;32m   1428\u001b[0m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001b[1;32m   1429\u001b[0m     )\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/ImageFile.py:551\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    549\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 551\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    553\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/ImageFile.py:570\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 570\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    571\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import ffmpeg\n",
    "\n",
    "def has_audio(video_path):\n",
    "    try:\n",
    "        probe = ffmpeg.probe(video_path)\n",
    "        for stream in probe['streams']:\n",
    "            if stream['codec_type'] == 'audio':\n",
    "                return True\n",
    "        return False\n",
    "    except ffmpeg.Error:\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_videos(video_dir, dataset_file):\n",
    "    # Read the dataset\n",
    "    filtered_videos = pd.read_excel(dataset_file)\n",
    "    # print(filtered_videos)\n",
    "    # Filter for videos without faces and not processed\n",
    "    print(video_dir)\n",
    "    # Extract video IDs from URLs\n",
    "    video_ids = filtered_videos['Video URL'].apply(lambda url: url.split('/')[-1])\n",
    "    results = []\n",
    "    print(os.path.exists(video_dir))\n",
    "\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        video_file = f\"{video_id}\"\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "        print(video_path)\n",
    "        if os.path.exists(video_path):\n",
    "            print(f\"Processing: {video_file}\")\n",
    "            try:\n",
    "                if not has_audio(video_path):\n",
    "                    print(f\"No audio stream found in {video_path}\")\n",
    "                    return None\n",
    "                # Extract features\n",
    "                visual_features = extract_visual_features(video_path)\n",
    "                # audio_features = extract_audio_features(video_path)\n",
    "                text_data = extract_text_from_frames(video_path)\n",
    "\n",
    "                result = {\n",
    "                    \"video\": video_file,\n",
    "                    \"visual_features\": visual_features,\n",
    "                    # \"audio_features\": audio_features,\n",
    "                    \"text_data\": text_data\n",
    "                }\n",
    "                print(\"this is result\",result)\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n",
    "\n",
    "    # Save results to a JSON file\n",
    "    with open(\"video_features.json\", \"w\") as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "\n",
    "    print(\"Feature extraction complete! Results saved to video_features.json\")\n",
    "\n",
    "# Call the function with dataset file\n",
    "process_videos(\"/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos\", \"/home/harshit/Desktop/hi/influencer_analysis/notebooks/videos_without_faces.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-999607261342550\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-999607261342550: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6.25M/6.25M [00:03<00:00, 1.85MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 174.7ms\n",
      "Speed: 11.3ms preprocess, 174.7ms inference, 1331.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_120.jpg: 640x384 4 persons, 10.6ms\n",
      "Speed: 3.8ms preprocess, 10.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_150.jpg: 640x384 4 persons, 14.0ms\n",
      "Speed: 4.6ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_180.jpg: 640x384 2 persons, 14.5ms\n",
      "Speed: 4.7ms preprocess, 14.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_210.jpg: 640x384 2 persons, 14.2ms\n",
      "Speed: 4.6ms preprocess, 14.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_240.jpg: 640x384 3 persons, 18.8ms\n",
      "Speed: 4.8ms preprocess, 18.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_270.jpg: 640x384 2 persons, 17.9ms\n",
      "Speed: 5.1ms preprocess, 17.9ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_30.jpg: 640x384 3 persons, 1 cell phone, 29.0ms\n",
      "Speed: 5.6ms preprocess, 29.0ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_300.jpg: 640x384 3 persons, 1 tv, 20.3ms\n",
      "Speed: 5.5ms preprocess, 20.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_330.jpg: 640x384 2 persons, 13.9ms\n",
      "Speed: 4.6ms preprocess, 13.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_360.jpg: 640x384 4 persons, 13.8ms\n",
      "Speed: 4.4ms preprocess, 13.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_390.jpg: 640x384 3 persons, 15.0ms\n",
      "Speed: 4.6ms preprocess, 15.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_60.jpg: 640x384 4 persons, 14.1ms\n",
      "Speed: 4.6ms preprocess, 14.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-999607261342550/frame_90.jpg: 640x384 6 persons, 12.5ms\n",
      "Speed: 4.4ms preprocess, 12.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-997580728807604\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-997580728807604: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_0.jpg: 640x640 1 person, 1 chair, 1 clock, 9.3ms\n",
      "Speed: 6.8ms preprocess, 9.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_120.jpg: 640x640 1 person, 1 clock, 9.6ms\n",
      "Speed: 6.7ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_150.jpg: 640x640 1 person, 2 clocks, 10.7ms\n",
      "Speed: 5.5ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_180.jpg: 640x640 1 person, 1 chair, 10.3ms\n",
      "Speed: 7.4ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_210.jpg: 640x640 2 persons, 13.1ms\n",
      "Speed: 6.9ms preprocess, 13.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_240.jpg: 640x640 2 persons, 1 chair, 1 clock, 10.9ms\n",
      "Speed: 6.9ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_270.jpg: 640x640 2 persons, 1 chair, 12.7ms\n",
      "Speed: 5.4ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_30.jpg: 640x640 1 person, 1 chair, 1 clock, 14.4ms\n",
      "Speed: 6.4ms preprocess, 14.4ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_300.jpg: 640x640 (no detections), 12.0ms\n",
      "Speed: 8.4ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_330.jpg: 640x640 (no detections), 12.9ms\n",
      "Speed: 7.5ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_60.jpg: 640x640 2 persons, 1 bowl, 14.2ms\n",
      "Speed: 7.8ms preprocess, 14.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-997580728807604/frame_90.jpg: 640x640 3 persons, 16.3ms\n",
      "Speed: 8.6ms preprocess, 16.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-992418235673669\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-992418235673669: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_0.jpg: 640x384 2 persons, 17.8ms\n",
      "Speed: 5.1ms preprocess, 17.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_120.jpg: 640x384 1 person, 1 tv, 14.7ms\n",
      "Speed: 4.5ms preprocess, 14.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_150.jpg: 640x384 2 persons, 1 tv, 1 cell phone, 14.6ms\n",
      "Speed: 4.9ms preprocess, 14.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_180.jpg: 640x384 3 persons, 1 book, 12.8ms\n",
      "Speed: 4.4ms preprocess, 12.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_210.jpg: 640x384 3 persons, 1 cell phone, 15.0ms\n",
      "Speed: 4.8ms preprocess, 15.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_240.jpg: 640x384 2 persons, 1 cell phone, 20.0ms\n",
      "Speed: 4.6ms preprocess, 20.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_270.jpg: 640x384 1 person, 1 cell phone, 14.6ms\n",
      "Speed: 4.9ms preprocess, 14.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_30.jpg: 640x384 1 person, 13.6ms\n",
      "Speed: 3.7ms preprocess, 13.6ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_300.jpg: 640x384 2 persons, 1 cell phone, 12.2ms\n",
      "Speed: 3.5ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_330.jpg: 640x384 3 persons, 1 tv, 1 cell phone, 8.7ms\n",
      "Speed: 2.9ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_360.jpg: 640x384 2 persons, 1 cell phone, 9.7ms\n",
      "Speed: 3.1ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_390.jpg: 640x384 3 persons, 1 cell phone, 10.0ms\n",
      "Speed: 3.7ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_420.jpg: 640x384 2 persons, 1 cell phone, 10.1ms\n",
      "Speed: 3.5ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_450.jpg: 640x384 1 bicycle, 8.7ms\n",
      "Speed: 3.2ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_480.jpg: 640x384 1 person, 9.3ms\n",
      "Speed: 3.4ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_510.jpg: 640x384 1 bicycle, 1 motorcycle, 17.2ms\n",
      "Speed: 3.1ms preprocess, 17.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_540.jpg: 640x384 1 person, 19.8ms\n",
      "Speed: 3.7ms preprocess, 19.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_570.jpg: 640x384 1 person, 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_60.jpg: 640x384 1 person, 9.0ms\n",
      "Speed: 2.8ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_600.jpg: 640x384 1 person, 10.3ms\n",
      "Speed: 3.5ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-992418235673669/frame_90.jpg: 640x384 1 cell phone, 9.0ms\n",
      "Speed: 2.9ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-991636695150147\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-991636695150147: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.3ms\n",
      "Speed: 3.2ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_120.jpg: 640x384 4 persons, 19.4ms\n",
      "Speed: 4.0ms preprocess, 19.4ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_150.jpg: 640x384 4 persons, 10.5ms\n",
      "Speed: 3.6ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_180.jpg: 640x384 2 persons, 11.4ms\n",
      "Speed: 3.7ms preprocess, 11.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_210.jpg: 640x384 2 persons, 10.4ms\n",
      "Speed: 3.6ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_240.jpg: 640x384 3 persons, 9.7ms\n",
      "Speed: 3.9ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_270.jpg: 640x384 2 persons, 9.5ms\n",
      "Speed: 3.1ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.1ms\n",
      "Speed: 3.7ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_300.jpg: 640x384 3 persons, 1 tv, 9.4ms\n",
      "Speed: 2.8ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_330.jpg: 640x384 2 persons, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_360.jpg: 640x384 4 persons, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_390.jpg: 640x384 3 persons, 10.0ms\n",
      "Speed: 3.4ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_60.jpg: 640x384 4 persons, 11.1ms\n",
      "Speed: 3.9ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-991636695150147/frame_90.jpg: 640x384 6 persons, 13.6ms\n",
      "Speed: 3.7ms preprocess, 13.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989969399547901\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989969399547901: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_0.jpg: 640x384 (no detections), 9.5ms\n",
      "Speed: 3.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_120.jpg: 640x384 3 persons, 8.6ms\n",
      "Speed: 3.2ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_150.jpg: 640x384 2 persons, 11.1ms\n",
      "Speed: 3.7ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_180.jpg: 640x384 1 person, 9.3ms\n",
      "Speed: 3.8ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_210.jpg: 640x384 1 person, 9.1ms\n",
      "Speed: 3.4ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_240.jpg: 640x384 3 persons, 9.0ms\n",
      "Speed: 3.1ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_270.jpg: 640x384 1 person, 2 cell phones, 9.4ms\n",
      "Speed: 3.1ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_30.jpg: 640x384 1 person, 9.6ms\n",
      "Speed: 3.5ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_300.jpg: 640x384 1 person, 1 cell phone, 9.1ms\n",
      "Speed: 3.2ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_330.jpg: 640x384 7 persons, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_360.jpg: 640x384 1 person, 1 cell phone, 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_390.jpg: 640x384 1 person, 1 train, 1 keyboard, 9.3ms\n",
      "Speed: 3.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_420.jpg: 640x384 3 persons, 13.6ms\n",
      "Speed: 4.6ms preprocess, 13.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_450.jpg: 640x384 2 persons, 34.4ms\n",
      "Speed: 5.0ms preprocess, 34.4ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_480.jpg: 640x384 2 persons, 3 cars, 17.0ms\n",
      "Speed: 4.8ms preprocess, 17.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_510.jpg: 640x384 (no detections), 15.8ms\n",
      "Speed: 4.8ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_540.jpg: 640x384 (no detections), 15.9ms\n",
      "Speed: 4.6ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_60.jpg: 640x384 2 persons, 29.3ms\n",
      "Speed: 5.0ms preprocess, 29.3ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989969399547901/frame_90.jpg: 640x384 1 person, 1 remote, 15.9ms\n",
      "Speed: 5.6ms preprocess, 15.9ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989930303148492\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989930303148492: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_0.jpg: 640x384 (no detections), 16.6ms\n",
      "Speed: 5.3ms preprocess, 16.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_116.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_116.jpg: 640x384 (no detections), 14.2ms\n",
      "Speed: 4.4ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_145.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_145.jpg: 640x384 2 persons, 2 books, 13.6ms\n",
      "Speed: 4.2ms preprocess, 13.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_174.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_174.jpg: 640x384 1 person, 14.6ms\n",
      "Speed: 4.7ms preprocess, 14.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_203.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_203.jpg: 640x384 1 person, 25.6ms\n",
      "Speed: 5.3ms preprocess, 25.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_232.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_232.jpg: 640x384 2 persons, 1 bed, 9.2ms\n",
      "Speed: 3.9ms preprocess, 9.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_261.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_261.jpg: 640x384 1 person, 1 bus, 1 cell phone, 9.0ms\n",
      "Speed: 3.5ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_29.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_29.jpg: 640x384 1 tv, 1 mouse, 9.6ms\n",
      "Speed: 3.1ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_290.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_290.jpg: 640x384 1 person, 1 laptop, 1 book, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_319.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_319.jpg: 640x384 1 cell phone, 10.3ms\n",
      "Speed: 3.8ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_348.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_348.jpg: 640x384 2 persons, 3 cell phones, 1 clock, 9.3ms\n",
      "Speed: 3.5ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_377.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_377.jpg: 640x384 2 persons, 2 cell phones, 9.1ms\n",
      "Speed: 3.4ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_406.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_406.jpg: 640x384 2 persons, 8.9ms\n",
      "Speed: 2.8ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_435.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_435.jpg: 640x384 1 person, 8.8ms\n",
      "Speed: 3.4ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_464.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_464.jpg: 640x384 1 person, 9.3ms\n",
      "Speed: 3.8ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_493.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_493.jpg: 640x384 1 person, 8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_522.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_522.jpg: 640x384 1 person, 8.8ms\n",
      "Speed: 3.4ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_551.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_551.jpg: 640x384 (no detections), 10.2ms\n",
      "Speed: 3.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_58.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_58.jpg: 640x384 1 person, 1 bus, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_580.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_580.jpg: 640x384 (no detections), 16.6ms\n",
      "Speed: 4.3ms preprocess, 16.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_87.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989930303148492/frame_87.jpg: 640x384 (no detections), 14.3ms\n",
      "Speed: 4.8ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989654009083459\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989654009083459: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_0.jpg: 640x384 2 persons, 13.9ms\n",
      "Speed: 4.9ms preprocess, 13.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_120.jpg: 640x384 3 persons, 14.3ms\n",
      "Speed: 4.7ms preprocess, 14.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_150.jpg: 640x384 1 person, 14.3ms\n",
      "Speed: 4.8ms preprocess, 14.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_180.jpg: 640x384 1 person, 15.2ms\n",
      "Speed: 5.0ms preprocess, 15.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_210.jpg: 640x384 2 persons, 14.4ms\n",
      "Speed: 4.7ms preprocess, 14.4ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_240.jpg: 640x384 (no detections), 14.1ms\n",
      "Speed: 4.7ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_270.jpg: 640x384 (no detections), 14.2ms\n",
      "Speed: 4.7ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_30.jpg: 640x384 1 parking meter, 13.7ms\n",
      "Speed: 4.8ms preprocess, 13.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_300.jpg: 640x384 2 persons, 13.7ms\n",
      "Speed: 4.3ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_60.jpg: 640x384 (no detections), 13.5ms\n",
      "Speed: 4.2ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989654009083459/frame_90.jpg: 640x384 (no detections), 12.8ms\n",
      "Speed: 4.2ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989600295478567\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989600295478567: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 15.7ms\n",
      "Speed: 4.7ms preprocess, 15.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_120.jpg: 640x384 4 persons, 13.8ms\n",
      "Speed: 4.5ms preprocess, 13.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_150.jpg: 640x384 4 persons, 12.6ms\n",
      "Speed: 4.4ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_180.jpg: 640x384 2 persons, 13.7ms\n",
      "Speed: 4.6ms preprocess, 13.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_210.jpg: 640x384 2 persons, 12.4ms\n",
      "Speed: 4.6ms preprocess, 12.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_240.jpg: 640x384 3 persons, 12.5ms\n",
      "Speed: 4.2ms preprocess, 12.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_270.jpg: 640x384 2 persons, 13.8ms\n",
      "Speed: 4.6ms preprocess, 13.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_30.jpg: 640x384 3 persons, 1 cell phone, 28.3ms\n",
      "Speed: 5.0ms preprocess, 28.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_300.jpg: 640x384 3 persons, 1 tv, 14.2ms\n",
      "Speed: 4.8ms preprocess, 14.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_330.jpg: 640x384 2 persons, 16.3ms\n",
      "Speed: 4.7ms preprocess, 16.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_360.jpg: 640x384 4 persons, 17.5ms\n",
      "Speed: 4.4ms preprocess, 17.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_390.jpg: 640x384 3 persons, 12.2ms\n",
      "Speed: 4.1ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_60.jpg: 640x384 4 persons, 31.9ms\n",
      "Speed: 5.3ms preprocess, 31.9ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989600295478567/frame_90.jpg: 640x384 6 persons, 15.7ms\n",
      "Speed: 4.0ms preprocess, 15.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989284361966196\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-989284361966196: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.4ms\n",
      "Speed: 3.3ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_120.jpg: 640x384 4 persons, 7.7ms\n",
      "Speed: 3.3ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_150.jpg: 640x384 4 persons, 14.0ms\n",
      "Speed: 2.8ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_180.jpg: 640x384 2 persons, 9.1ms\n",
      "Speed: 3.5ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_210.jpg: 640x384 2 persons, 8.9ms\n",
      "Speed: 3.1ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_240.jpg: 640x384 3 persons, 8.9ms\n",
      "Speed: 3.3ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_270.jpg: 640x384 2 persons, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_30.jpg: 640x384 3 persons, 1 cell phone, 35.6ms\n",
      "Speed: 4.8ms preprocess, 35.6ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_300.jpg: 640x384 3 persons, 1 tv, 23.9ms\n",
      "Speed: 4.5ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_330.jpg: 640x384 2 persons, 11.7ms\n",
      "Speed: 3.1ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_360.jpg: 640x384 4 persons, 9.7ms\n",
      "Speed: 3.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_390.jpg: 640x384 3 persons, 9.7ms\n",
      "Speed: 3.7ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_60.jpg: 640x384 4 persons, 9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-989284361966196/frame_90.jpg: 640x384 6 persons, 8.9ms\n",
      "Speed: 3.0ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-988185795921355\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-988185795921355: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.3ms\n",
      "Speed: 3.2ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_120.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 2.8ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_150.jpg: 640x384 4 persons, 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_180.jpg: 640x384 2 persons, 8.5ms\n",
      "Speed: 3.0ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_210.jpg: 640x384 2 persons, 8.7ms\n",
      "Speed: 3.1ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_240.jpg: 640x384 3 persons, 10.2ms\n",
      "Speed: 3.9ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_270.jpg: 640x384 2 persons, 9.1ms\n",
      "Speed: 4.2ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_30.jpg: 640x384 3 persons, 1 cell phone, 30.7ms\n",
      "Speed: 3.8ms preprocess, 30.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_300.jpg: 640x384 3 persons, 1 tv, 11.7ms\n",
      "Speed: 3.9ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_330.jpg: 640x384 2 persons, 11.9ms\n",
      "Speed: 3.3ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_360.jpg: 640x384 4 persons, 10.7ms\n",
      "Speed: 3.4ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_390.jpg: 640x384 3 persons, 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_60.jpg: 640x384 4 persons, 9.6ms\n",
      "Speed: 3.5ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-988185795921355/frame_90.jpg: 640x384 6 persons, 17.6ms\n",
      "Speed: 3.0ms preprocess, 17.6ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-987287402378278\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-987287402378278: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_0.jpg: 640x544 2 cups, 102.8ms\n",
      "Speed: 5.8ms preprocess, 102.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_120.jpg: 640x544 2 persons, 1 wine glass, 1 dining table, 1 book, 7.9ms\n",
      "Speed: 5.1ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_150.jpg: 640x544 2 persons, 1 chair, 1 book, 8.9ms\n",
      "Speed: 4.4ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_180.jpg: 640x544 2 persons, 1 chair, 9.7ms\n",
      "Speed: 4.3ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_210.jpg: 640x544 3 persons, 11.7ms\n",
      "Speed: 5.3ms preprocess, 11.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_240.jpg: 640x544 2 persons, 1 cup, 13.5ms\n",
      "Speed: 7.8ms preprocess, 13.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_270.jpg: 640x544 2 persons, 1 cup, 14.6ms\n",
      "Speed: 6.7ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_30.jpg: 640x544 1 cup, 1 dining table, 14.6ms\n",
      "Speed: 7.6ms preprocess, 14.6ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_300.jpg: 640x544 1 person, 2 cups, 13.7ms\n",
      "Speed: 7.4ms preprocess, 13.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_330.jpg: 640x544 2 cups, 1 chair, 1 dining table, 14.4ms\n",
      "Speed: 7.5ms preprocess, 14.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_360.jpg: 640x544 1 chair, 1 couch, 1 dining table, 14.1ms\n",
      "Speed: 7.4ms preprocess, 14.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_390.jpg: 640x544 1 cup, 1 chair, 1 couch, 17.6ms\n",
      "Speed: 8.0ms preprocess, 17.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_420.jpg: 640x544 1 cup, 1 dining table, 18.3ms\n",
      "Speed: 7.8ms preprocess, 18.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_60.jpg: 640x544 (no detections), 16.8ms\n",
      "Speed: 7.8ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987287402378278/frame_90.jpg: 640x544 1 person, 1 scissors, 1 teddy bear, 17.3ms\n",
      "Speed: 8.0ms preprocess, 17.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-987232088920289\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-987232088920289: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 14.9ms\n",
      "Speed: 4.8ms preprocess, 14.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_120.jpg: 640x384 4 persons, 12.2ms\n",
      "Speed: 4.0ms preprocess, 12.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_150.jpg: 640x384 4 persons, 12.5ms\n",
      "Speed: 4.2ms preprocess, 12.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_180.jpg: 640x384 2 persons, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_210.jpg: 640x384 2 persons, 10.3ms\n",
      "Speed: 3.5ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_240.jpg: 640x384 3 persons, 9.6ms\n",
      "Speed: 3.5ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_270.jpg: 640x384 2 persons, 10.3ms\n",
      "Speed: 3.7ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_30.jpg: 640x384 3 persons, 1 cell phone, 14.3ms\n",
      "Speed: 3.4ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_300.jpg: 640x384 3 persons, 1 tv, 9.5ms\n",
      "Speed: 3.7ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_330.jpg: 640x384 2 persons, 9.6ms\n",
      "Speed: 3.6ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_360.jpg: 640x384 4 persons, 11.1ms\n",
      "Speed: 3.9ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_390.jpg: 640x384 3 persons, 9.3ms\n",
      "Speed: 3.0ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_60.jpg: 640x384 4 persons, 8.9ms\n",
      "Speed: 3.4ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-987232088920289/frame_90.jpg: 640x384 6 persons, 13.7ms\n",
      "Speed: 3.5ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-986360206629277\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-986360206629277: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_0.jpg: 640x384 1 dog, 1 chair, 13.2ms\n",
      "Speed: 3.4ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_120.jpg: 640x384 1 person, 1 chair, 2 clocks, 11.2ms\n",
      "Speed: 3.6ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_150.jpg: 640x384 1 person, 1 chair, 1 clock, 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_180.jpg: 640x384 1 person, 9.4ms\n",
      "Speed: 3.4ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_210.jpg: 640x384 3 persons, 1 chair, 15.1ms\n",
      "Speed: 3.2ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_240.jpg: 640x384 1 person, 1 chair, 1 clock, 1 teddy bear, 8.9ms\n",
      "Speed: 2.7ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_270.jpg: 640x384 1 person, 1 dog, 1 teddy bear, 14.7ms\n",
      "Speed: 4.5ms preprocess, 14.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_30.jpg: 640x384 1 dog, 1 chair, 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_300.jpg: 640x384 2 persons, 11.1ms\n",
      "Speed: 4.0ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_330.jpg: 640x384 (no detections), 11.9ms\n",
      "Speed: 5.0ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_60.jpg: 640x384 2 persons, 1 chair, 9.8ms\n",
      "Speed: 3.7ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-986360206629277/frame_90.jpg: 640x384 3 persons, 1 bench, 2 clocks, 24.0ms\n",
      "Speed: 3.5ms preprocess, 24.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-978448136455993\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-978448136455993: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.4ms\n",
      "Speed: 3.9ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_120.jpg: 640x384 4 persons, 9.4ms\n",
      "Speed: 3.2ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_150.jpg: 640x384 4 persons, 30.4ms\n",
      "Speed: 2.9ms preprocess, 30.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_180.jpg: 640x384 2 persons, 9.6ms\n",
      "Speed: 4.0ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_210.jpg: 640x384 2 persons, 10.4ms\n",
      "Speed: 4.0ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_240.jpg: 640x384 3 persons, 8.5ms\n",
      "Speed: 3.1ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_270.jpg: 640x384 2 persons, 7.8ms\n",
      "Speed: 2.8ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_30.jpg: 640x384 3 persons, 1 cell phone, 8.5ms\n",
      "Speed: 2.6ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_300.jpg: 640x384 3 persons, 1 tv, 7.7ms\n",
      "Speed: 2.7ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_330.jpg: 640x384 2 persons, 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_360.jpg: 640x384 4 persons, 9.1ms\n",
      "Speed: 3.1ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_390.jpg: 640x384 3 persons, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_60.jpg: 640x384 4 persons, 13.0ms\n",
      "Speed: 4.1ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-978448136455993/frame_90.jpg: 640x384 6 persons, 7.1ms\n",
      "Speed: 3.1ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-977008307250628\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-977008307250628: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 13.0ms\n",
      "Speed: 3.3ms preprocess, 13.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_120.jpg: 640x384 4 persons, 17.3ms\n",
      "Speed: 4.8ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_150.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 3.3ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_180.jpg: 640x384 2 persons, 7.7ms\n",
      "Speed: 2.9ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_210.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 2.5ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_240.jpg: 640x384 3 persons, 12.9ms\n",
      "Speed: 2.8ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_270.jpg: 640x384 2 persons, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_30.jpg: 640x384 3 persons, 1 cell phone, 11.6ms\n",
      "Speed: 4.5ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_300.jpg: 640x384 3 persons, 1 tv, 14.8ms\n",
      "Speed: 4.2ms preprocess, 14.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_330.jpg: 640x384 2 persons, 14.3ms\n",
      "Speed: 4.2ms preprocess, 14.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_360.jpg: 640x384 4 persons, 10.3ms\n",
      "Speed: 3.5ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_390.jpg: 640x384 3 persons, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_60.jpg: 640x384 4 persons, 12.4ms\n",
      "Speed: 3.9ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-977008307250628/frame_90.jpg: 640x384 6 persons, 9.2ms\n",
      "Speed: 3.2ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-975523146942238\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-975523146942238: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_0.jpg: 640x384 1 person, 1 potted plant, 7.4ms\n",
      "Speed: 2.3ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_120.jpg: 640x384 2 persons, 7.5ms\n",
      "Speed: 3.0ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_150.jpg: 640x384 3 persons, 7.8ms\n",
      "Speed: 2.5ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_180.jpg: 640x384 1 person, 1 potted plant, 1 book, 8.2ms\n",
      "Speed: 2.9ms preprocess, 8.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_210.jpg: 640x384 1 person, 2 potted plants, 1 book, 1 vase, 9.2ms\n",
      "Speed: 3.4ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_240.jpg: 640x384 2 potted plants, 1 book, 1 vase, 7.3ms\n",
      "Speed: 2.4ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_270.jpg: 640x384 1 book, 8.0ms\n",
      "Speed: 2.8ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_30.jpg: 640x384 3 persons, 1 cup, 1 potted plant, 1 book, 7.4ms\n",
      "Speed: 2.6ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_300.jpg: 640x384 1 book, 9.0ms\n",
      "Speed: 2.7ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_330.jpg: 640x384 1 suitcase, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_360.jpg: 640x384 1 bowl, 1 dining table, 24.2ms\n",
      "Speed: 3.7ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_390.jpg: 640x384 1 book, 9.2ms\n",
      "Speed: 2.7ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_420.jpg: 640x384 (no detections), 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_450.jpg: 640x384 (no detections), 8.2ms\n",
      "Speed: 3.0ms preprocess, 8.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_480.jpg: 640x384 (no detections), 8.5ms\n",
      "Speed: 2.6ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_60.jpg: 640x384 1 person, 1 potted plant, 7.9ms\n",
      "Speed: 2.7ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-975523146942238/frame_90.jpg: 640x384 1 person, 8.2ms\n",
      "Speed: 2.8ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-967731231014052\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-967731231014052: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.3ms\n",
      "Speed: 2.5ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_120.jpg: 640x384 4 persons, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_150.jpg: 640x384 4 persons, 7.7ms\n",
      "Speed: 2.5ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_180.jpg: 640x384 2 persons, 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_210.jpg: 640x384 2 persons, 7.7ms\n",
      "Speed: 3.0ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_240.jpg: 640x384 3 persons, 8.6ms\n",
      "Speed: 2.6ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_270.jpg: 640x384 2 persons, 8.6ms\n",
      "Speed: 2.6ms preprocess, 8.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_30.jpg: 640x384 3 persons, 1 cell phone, 8.4ms\n",
      "Speed: 3.3ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_300.jpg: 640x384 3 persons, 1 tv, 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_330.jpg: 640x384 2 persons, 8.8ms\n",
      "Speed: 3.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_360.jpg: 640x384 4 persons, 11.6ms\n",
      "Speed: 3.5ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_390.jpg: 640x384 3 persons, 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_60.jpg: 640x384 4 persons, 11.4ms\n",
      "Speed: 4.0ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-967731231014052/frame_90.jpg: 640x384 6 persons, 9.6ms\n",
      "Speed: 3.1ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-966715248087290\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-966715248087290: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_120.jpg: 640x384 4 persons, 9.0ms\n",
      "Speed: 4.3ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_150.jpg: 640x384 4 persons, 9.8ms\n",
      "Speed: 3.9ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_180.jpg: 640x384 2 persons, 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_210.jpg: 640x384 2 persons, 12.4ms\n",
      "Speed: 3.4ms preprocess, 12.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_240.jpg: 640x384 3 persons, 10.5ms\n",
      "Speed: 3.4ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_270.jpg: 640x384 2 persons, 8.5ms\n",
      "Speed: 4.1ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.2ms\n",
      "Speed: 3.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_300.jpg: 640x384 3 persons, 1 tv, 8.7ms\n",
      "Speed: 3.0ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_330.jpg: 640x384 2 persons, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_360.jpg: 640x384 4 persons, 8.2ms\n",
      "Speed: 3.0ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_390.jpg: 640x384 3 persons, 11.7ms\n",
      "Speed: 4.0ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_60.jpg: 640x384 4 persons, 11.8ms\n",
      "Speed: 4.3ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966715248087290/frame_90.jpg: 640x384 6 persons, 8.1ms\n",
      "Speed: 2.7ms preprocess, 8.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-966458824582483\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-966458824582483: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.6ms\n",
      "Speed: 2.3ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_120.jpg: 640x384 4 persons, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_150.jpg: 640x384 4 persons, 13.3ms\n",
      "Speed: 3.4ms preprocess, 13.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_180.jpg: 640x384 2 persons, 9.0ms\n",
      "Speed: 2.5ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_210.jpg: 640x384 2 persons, 9.7ms\n",
      "Speed: 4.1ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_240.jpg: 640x384 3 persons, 9.0ms\n",
      "Speed: 4.2ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_270.jpg: 640x384 2 persons, 11.2ms\n",
      "Speed: 3.9ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_30.jpg: 640x384 3 persons, 1 cell phone, 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_300.jpg: 640x384 3 persons, 1 tv, 12.7ms\n",
      "Speed: 3.7ms preprocess, 12.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_330.jpg: 640x384 2 persons, 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_360.jpg: 640x384 4 persons, 9.2ms\n",
      "Speed: 3.0ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_390.jpg: 640x384 3 persons, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_60.jpg: 640x384 4 persons, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966458824582483/frame_90.jpg: 640x384 6 persons, 7.2ms\n",
      "Speed: 3.1ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-966019214364727\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-966019214364727: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_120.jpg: 640x384 4 persons, 7.8ms\n",
      "Speed: 2.7ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_150.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 3.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_180.jpg: 640x384 2 persons, 7.7ms\n",
      "Speed: 2.9ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_210.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 2.7ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_240.jpg: 640x384 3 persons, 8.9ms\n",
      "Speed: 3.1ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_270.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 3.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_30.jpg: 640x384 3 persons, 1 cell phone, 7.5ms\n",
      "Speed: 2.7ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_300.jpg: 640x384 3 persons, 1 tv, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_330.jpg: 640x384 2 persons, 9.3ms\n",
      "Speed: 2.7ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_360.jpg: 640x384 4 persons, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_390.jpg: 640x384 3 persons, 7.4ms\n",
      "Speed: 2.8ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_60.jpg: 640x384 4 persons, 8.9ms\n",
      "Speed: 2.9ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-966019214364727/frame_90.jpg: 640x384 6 persons, 8.2ms\n",
      "Speed: 2.7ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-964733417506862\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-964733417506862: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_0.jpg: 640x640 1 vase, 6.6ms\n",
      "Speed: 4.2ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_120.jpg: 640x640 1 person, 1 train, 11.7ms\n",
      "Speed: 3.9ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_150.jpg: 640x640 1 train, 7.9ms\n",
      "Speed: 4.0ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_180.jpg: 640x640 1 person, 1 giraffe, 7.7ms\n",
      "Speed: 4.0ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_210.jpg: 640x640 1 person, 1 giraffe, 8.9ms\n",
      "Speed: 4.2ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_240.jpg: 640x640 1 person, 9.3ms\n",
      "Speed: 4.9ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_270.jpg: 640x640 (no detections), 8.5ms\n",
      "Speed: 4.5ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_30.jpg: 640x640 2 persons, 1 tie, 9.6ms\n",
      "Speed: 3.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_300.jpg: 640x640 (no detections), 8.4ms\n",
      "Speed: 4.6ms preprocess, 8.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_330.jpg: 640x640 2 vases, 9.6ms\n",
      "Speed: 4.5ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_360.jpg: 640x640 (no detections), 8.8ms\n",
      "Speed: 4.4ms preprocess, 8.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_390.jpg: 640x640 (no detections), 7.9ms\n",
      "Speed: 4.1ms preprocess, 7.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_60.jpg: 640x640 1 person, 7.8ms\n",
      "Speed: 3.9ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-964733417506862/frame_90.jpg: 640x640 1 person, 8.4ms\n",
      "Speed: 3.9ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-958675741960412\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-958675741960412: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.8ms\n",
      "Speed: 3.0ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_120.jpg: 640x384 4 persons, 7.7ms\n",
      "Speed: 2.8ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_150.jpg: 640x384 4 persons, 9.3ms\n",
      "Speed: 3.3ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_180.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 3.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_210.jpg: 640x384 2 persons, 7.4ms\n",
      "Speed: 2.6ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_240.jpg: 640x384 3 persons, 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_270.jpg: 640x384 2 persons, 9.6ms\n",
      "Speed: 4.1ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.1ms\n",
      "Speed: 4.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_300.jpg: 640x384 3 persons, 1 tv, 12.7ms\n",
      "Speed: 4.0ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_330.jpg: 640x384 2 persons, 12.7ms\n",
      "Speed: 4.5ms preprocess, 12.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_360.jpg: 640x384 4 persons, 12.7ms\n",
      "Speed: 4.8ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_390.jpg: 640x384 3 persons, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_60.jpg: 640x384 4 persons, 12.6ms\n",
      "Speed: 4.6ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958675741960412/frame_90.jpg: 640x384 6 persons, 29.7ms\n",
      "Speed: 4.8ms preprocess, 29.7ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-958267042213267\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-958267042213267: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 10.8ms\n",
      "Speed: 3.2ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_120.jpg: 640x384 4 persons, 8.5ms\n",
      "Speed: 2.6ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_150.jpg: 640x384 4 persons, 9.8ms\n",
      "Speed: 4.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_180.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 3.2ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_210.jpg: 640x384 2 persons, 11.8ms\n",
      "Speed: 3.5ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_240.jpg: 640x384 3 persons, 7.3ms\n",
      "Speed: 2.8ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_270.jpg: 640x384 2 persons, 7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_30.jpg: 640x384 3 persons, 1 cell phone, 13.4ms\n",
      "Speed: 3.6ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_300.jpg: 640x384 3 persons, 1 tv, 12.9ms\n",
      "Speed: 4.0ms preprocess, 12.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_330.jpg: 640x384 2 persons, 11.1ms\n",
      "Speed: 4.1ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_360.jpg: 640x384 4 persons, 9.1ms\n",
      "Speed: 4.3ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_390.jpg: 640x384 3 persons, 12.3ms\n",
      "Speed: 4.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_60.jpg: 640x384 4 persons, 9.1ms\n",
      "Speed: 2.4ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-958267042213267/frame_90.jpg: 640x384 6 persons, 8.6ms\n",
      "Speed: 3.1ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-954440782897187\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-954440782897187: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_0.jpg: 640x384 1 person, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_120.jpg: 640x384 (no detections), 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_150.jpg: 640x384 (no detections), 21.2ms\n",
      "Speed: 4.3ms preprocess, 21.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_180.jpg: 640x384 1 banana, 17.9ms\n",
      "Speed: 3.3ms preprocess, 17.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_210.jpg: 640x384 (no detections), 27.7ms\n",
      "Speed: 4.6ms preprocess, 27.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_240.jpg: 640x384 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_270.jpg: 640x384 1 toothbrush, 10.8ms\n",
      "Speed: 4.3ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_30.jpg: 640x384 (no detections), 13.8ms\n",
      "Speed: 4.3ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_300.jpg: 640x384 2 persons, 14.7ms\n",
      "Speed: 4.2ms preprocess, 14.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_330.jpg: 640x384 2 persons, 10.5ms\n",
      "Speed: 3.6ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_360.jpg: 640x384 3 persons, 1 cell phone, 9.7ms\n",
      "Speed: 3.3ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_390.jpg: 640x384 1 person, 1 cell phone, 9.2ms\n",
      "Speed: 2.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_420.jpg: 640x384 1 person, 1 cell phone, 8.4ms\n",
      "Speed: 2.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_450.jpg: 640x384 2 persons, 1 cell phone, 13.7ms\n",
      "Speed: 4.0ms preprocess, 13.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_480.jpg: 640x384 4 persons, 1 cell phone, 16.3ms\n",
      "Speed: 4.3ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_510.jpg: 640x384 3 persons, 1 toilet, 1 tv, 13.1ms\n",
      "Speed: 3.2ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_540.jpg: 640x384 1 person, 1 toilet, 13.4ms\n",
      "Speed: 4.0ms preprocess, 13.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_570.jpg: 640x384 2 persons, 2 tvs, 15.9ms\n",
      "Speed: 4.2ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_60.jpg: 640x384 1 person, 12.3ms\n",
      "Speed: 3.5ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_600.jpg: 640x384 2 persons, 10.6ms\n",
      "Speed: 4.2ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_630.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_630.jpg: 640x384 (no detections), 12.7ms\n",
      "Speed: 4.2ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_660.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_660.jpg: 640x384 (no detections), 9.5ms\n",
      "Speed: 3.1ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-954440782897187/frame_90.jpg: 640x384 1 banana, 1 toilet, 8.9ms\n",
      "Speed: 3.0ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-951885082053340\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-951885082053340: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_0.jpg: 640x640 2 persons, 7.1ms\n",
      "Speed: 4.0ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_120.jpg: 640x640 1 person, 1 laptop, 1 cell phone, 7.6ms\n",
      "Speed: 3.2ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_150.jpg: 640x640 2 persons, 8.6ms\n",
      "Speed: 2.7ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_180.jpg: 640x640 2 persons, 10.3ms\n",
      "Speed: 3.6ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_210.jpg: 640x640 2 persons, 1 bird, 15.4ms\n",
      "Speed: 4.7ms preprocess, 15.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_240.jpg: 640x640 (no detections), 16.7ms\n",
      "Speed: 3.3ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_270.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 4.2ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_30.jpg: 640x640 2 persons, 15.2ms\n",
      "Speed: 3.6ms preprocess, 15.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_300.jpg: 640x640 (no detections), 14.3ms\n",
      "Speed: 4.6ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_330.jpg: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_60.jpg: 640x640 2 persons, 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951885082053340/frame_90.jpg: 640x640 1 person, 12.4ms\n",
      "Speed: 4.3ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-951491629353387\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-951491629353387: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.1ms\n",
      "Speed: 2.9ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_120.jpg: 640x384 4 persons, 6.7ms\n",
      "Speed: 2.3ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_150.jpg: 640x384 4 persons, 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_180.jpg: 640x384 2 persons, 8.0ms\n",
      "Speed: 2.2ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_210.jpg: 640x384 2 persons, 19.1ms\n",
      "Speed: 3.1ms preprocess, 19.1ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_240.jpg: 640x384 3 persons, 30.3ms\n",
      "Speed: 3.8ms preprocess, 30.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_270.jpg: 640x384 2 persons, 18.9ms\n",
      "Speed: 3.9ms preprocess, 18.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_30.jpg: 640x384 3 persons, 1 cell phone, 12.8ms\n",
      "Speed: 4.0ms preprocess, 12.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_300.jpg: 640x384 3 persons, 1 tv, 12.3ms\n",
      "Speed: 5.0ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_330.jpg: 640x384 2 persons, 10.3ms\n",
      "Speed: 3.4ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_360.jpg: 640x384 4 persons, 13.5ms\n",
      "Speed: 4.1ms preprocess, 13.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_390.jpg: 640x384 3 persons, 9.1ms\n",
      "Speed: 4.2ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_60.jpg: 640x384 4 persons, 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-951491629353387/frame_90.jpg: 640x384 6 persons, 8.1ms\n",
      "Speed: 2.5ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-946181943065342\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-946181943065342: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_120.jpg: 640x384 4 persons, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_150.jpg: 640x384 4 persons, 7.4ms\n",
      "Speed: 2.7ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_180.jpg: 640x384 2 persons, 11.5ms\n",
      "Speed: 4.2ms preprocess, 11.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_210.jpg: 640x384 2 persons, 12.6ms\n",
      "Speed: 3.5ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_240.jpg: 640x384 3 persons, 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_270.jpg: 640x384 2 persons, 11.8ms\n",
      "Speed: 3.8ms preprocess, 11.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_30.jpg: 640x384 3 persons, 1 cell phone, 13.8ms\n",
      "Speed: 3.6ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_300.jpg: 640x384 3 persons, 1 tv, 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_330.jpg: 640x384 2 persons, 7.4ms\n",
      "Speed: 2.4ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_360.jpg: 640x384 4 persons, 8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_390.jpg: 640x384 3 persons, 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_60.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 2.8ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-946181943065342/frame_90.jpg: 640x384 6 persons, 7.9ms\n",
      "Speed: 2.6ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-944981830978756\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-944981830978756: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_0.jpg: 640x640 2 persons, 7.1ms\n",
      "Speed: 5.1ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_120.jpg: 640x640 2 persons, 1 fork, 7.8ms\n",
      "Speed: 5.1ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_150.jpg: 640x640 6 persons, 8.2ms\n",
      "Speed: 4.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_180.jpg: 640x640 4 persons, 9.0ms\n",
      "Speed: 5.4ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_210.jpg: 640x640 4 persons, 1 bottle, 11.0ms\n",
      "Speed: 6.4ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_240.jpg: 640x640 2 persons, 12.0ms\n",
      "Speed: 5.8ms preprocess, 12.0ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_270.jpg: 640x640 4 persons, 10.0ms\n",
      "Speed: 5.6ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_30.jpg: 640x640 1 bottle, 8.9ms\n",
      "Speed: 6.4ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_300.jpg: 640x640 4 persons, 10.5ms\n",
      "Speed: 4.6ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_330.jpg: 640x640 (no detections), 8.9ms\n",
      "Speed: 5.7ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_360.jpg: 640x640 (no detections), 10.1ms\n",
      "Speed: 5.8ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_60.jpg: 640x640 1 person, 2 cell phones, 8.1ms\n",
      "Speed: 5.3ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944981830978756/frame_90.jpg: 640x640 (no detections), 7.7ms\n",
      "Speed: 5.0ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-944755280756437\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-944755280756437: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.8ms\n",
      "Speed: 2.5ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_120.jpg: 640x384 4 persons, 6.7ms\n",
      "Speed: 2.5ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_150.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 3.0ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_180.jpg: 640x384 2 persons, 13.2ms\n",
      "Speed: 3.2ms preprocess, 13.2ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_210.jpg: 640x384 2 persons, 11.9ms\n",
      "Speed: 3.4ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_240.jpg: 640x384 3 persons, 9.1ms\n",
      "Speed: 3.4ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_270.jpg: 640x384 2 persons, 9.9ms\n",
      "Speed: 3.8ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_30.jpg: 640x384 3 persons, 1 cell phone, 8.0ms\n",
      "Speed: 2.7ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_300.jpg: 640x384 3 persons, 1 tv, 7.8ms\n",
      "Speed: 2.7ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_330.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 2.6ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_360.jpg: 640x384 4 persons, 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_390.jpg: 640x384 3 persons, 7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_60.jpg: 640x384 4 persons, 7.4ms\n",
      "Speed: 2.8ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944755280756437/frame_90.jpg: 640x384 6 persons, 13.8ms\n",
      "Speed: 3.0ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-944160410298140\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-944160410298140: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 12.3ms\n",
      "Speed: 3.8ms preprocess, 12.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_120.jpg: 640x384 4 persons, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_150.jpg: 640x384 4 persons, 10.7ms\n",
      "Speed: 4.2ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_180.jpg: 640x384 2 persons, 10.7ms\n",
      "Speed: 4.3ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_210.jpg: 640x384 2 persons, 23.6ms\n",
      "Speed: 4.2ms preprocess, 23.6ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_240.jpg: 640x384 3 persons, 31.4ms\n",
      "Speed: 4.6ms preprocess, 31.4ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_270.jpg: 640x384 2 persons, 13.2ms\n",
      "Speed: 3.9ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_30.jpg: 640x384 3 persons, 1 cell phone, 8.9ms\n",
      "Speed: 3.2ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_300.jpg: 640x384 3 persons, 1 tv, 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_330.jpg: 640x384 2 persons, 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_360.jpg: 640x384 4 persons, 14.7ms\n",
      "Speed: 4.5ms preprocess, 14.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_390.jpg: 640x384 3 persons, 10.9ms\n",
      "Speed: 4.1ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_60.jpg: 640x384 4 persons, 13.3ms\n",
      "Speed: 3.9ms preprocess, 13.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-944160410298140/frame_90.jpg: 640x384 6 persons, 12.4ms\n",
      "Speed: 4.0ms preprocess, 12.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-942524046763053\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-942524046763053: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 14.7ms\n",
      "Speed: 4.2ms preprocess, 14.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_120.jpg: 640x384 4 persons, 18.2ms\n",
      "Speed: 3.7ms preprocess, 18.2ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_150.jpg: 640x384 4 persons, 25.6ms\n",
      "Speed: 3.8ms preprocess, 25.6ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_180.jpg: 640x384 2 persons, 13.6ms\n",
      "Speed: 3.8ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_210.jpg: 640x384 2 persons, 7.8ms\n",
      "Speed: 2.9ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_240.jpg: 640x384 3 persons, 8.9ms\n",
      "Speed: 3.2ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_270.jpg: 640x384 2 persons, 7.6ms\n",
      "Speed: 2.8ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_30.jpg: 640x384 3 persons, 1 cell phone, 7.9ms\n",
      "Speed: 2.6ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_300.jpg: 640x384 3 persons, 1 tv, 7.9ms\n",
      "Speed: 2.8ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_330.jpg: 640x384 2 persons, 8.9ms\n",
      "Speed: 2.7ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_360.jpg: 640x384 4 persons, 8.7ms\n",
      "Speed: 2.4ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_390.jpg: 640x384 3 persons, 9.5ms\n",
      "Speed: 3.6ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_60.jpg: 640x384 4 persons, 14.1ms\n",
      "Speed: 4.3ms preprocess, 14.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-942524046763053/frame_90.jpg: 640x384 6 persons, 21.1ms\n",
      "Speed: 5.1ms preprocess, 21.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-940634710428411\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-940634710428411: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_120.jpg: 640x384 4 persons, 18.4ms\n",
      "Speed: 3.3ms preprocess, 18.4ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_150.jpg: 640x384 4 persons, 7.1ms\n",
      "Speed: 3.2ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_180.jpg: 640x384 2 persons, 8.0ms\n",
      "Speed: 2.6ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_210.jpg: 640x384 2 persons, 7.9ms\n",
      "Speed: 3.1ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_240.jpg: 640x384 3 persons, 9.0ms\n",
      "Speed: 3.1ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_270.jpg: 640x384 2 persons, 10.5ms\n",
      "Speed: 3.4ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_300.jpg: 640x384 3 persons, 1 tv, 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_330.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_360.jpg: 640x384 4 persons, 7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_390.jpg: 640x384 3 persons, 8.4ms\n",
      "Speed: 3.0ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_60.jpg: 640x384 4 persons, 13.8ms\n",
      "Speed: 3.6ms preprocess, 13.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-940634710428411/frame_90.jpg: 640x384 6 persons, 22.8ms\n",
      "Speed: 3.8ms preprocess, 22.8ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-939795907980426\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-939795907980426: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_0.jpg: 640x640 (no detections), 7.8ms\n",
      "Speed: 7.5ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_120.jpg: 640x640 1 book, 7.1ms\n",
      "Speed: 6.7ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_150.jpg: 640x640 3 persons, 1 broccoli, 1 cell phone, 8.1ms\n",
      "Speed: 4.8ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_180.jpg: 640x640 4 persons, 1 cell phone, 18.5ms\n",
      "Speed: 5.0ms preprocess, 18.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_210.jpg: 640x640 2 persons, 1 cell phone, 21.4ms\n",
      "Speed: 6.3ms preprocess, 21.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_240.jpg: 640x640 2 persons, 8.2ms\n",
      "Speed: 5.3ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_270.jpg: 640x640 1 tv, 8.1ms\n",
      "Speed: 4.7ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_30.jpg: 640x640 (no detections), 7.7ms\n",
      "Speed: 4.5ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_300.jpg: 640x640 2 persons, 8.1ms\n",
      "Speed: 4.9ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_330.jpg: 640x640 3 persons, 1 tv, 11.2ms\n",
      "Speed: 6.4ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_360.jpg: 640x640 2 persons, 13.2ms\n",
      "Speed: 7.1ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_390.jpg: 640x640 1 cell phone, 17.6ms\n",
      "Speed: 7.4ms preprocess, 17.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_420.jpg: 640x640 (no detections), 17.2ms\n",
      "Speed: 7.9ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_450.jpg: 640x640 (no detections), 12.7ms\n",
      "Speed: 5.9ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_480.jpg: 640x640 (no detections), 11.5ms\n",
      "Speed: 7.3ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_510.jpg: 640x640 (no detections), 9.4ms\n",
      "Speed: 5.6ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_60.jpg: 640x640 (no detections), 8.0ms\n",
      "Speed: 5.1ms preprocess, 8.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-939795907980426/frame_90.jpg: 640x640 (no detections), 8.2ms\n",
      "Speed: 5.0ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-938232524809973\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-938232524809973: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_0.jpg: 640x384 3 persons, 2 remotes, 1 cell phone, 9.3ms\n",
      "Speed: 2.6ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_120.jpg: 640x384 5 persons, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_150.jpg: 640x384 5 persons, 12.1ms\n",
      "Speed: 3.7ms preprocess, 12.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_180.jpg: 640x384 3 persons, 13.5ms\n",
      "Speed: 4.5ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_210.jpg: 640x384 2 persons, 26.9ms\n",
      "Speed: 3.7ms preprocess, 26.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_240.jpg: 640x384 3 persons, 31.5ms\n",
      "Speed: 5.6ms preprocess, 31.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_270.jpg: 640x384 2 persons, 28.3ms\n",
      "Speed: 4.5ms preprocess, 28.3ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_30.jpg: 640x384 3 persons, 1 cell phone, 8.6ms\n",
      "Speed: 3.1ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_300.jpg: 640x384 3 persons, 1 tv, 9.5ms\n",
      "Speed: 3.0ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_330.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 3.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_360.jpg: 640x384 3 persons, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_390.jpg: 640x384 3 persons, 18.6ms\n",
      "Speed: 2.7ms preprocess, 18.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_420.jpg: 640x384 (no detections), 8.7ms\n",
      "Speed: 2.8ms preprocess, 8.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_450.jpg: 640x384 (no detections), 8.0ms\n",
      "Speed: 2.7ms preprocess, 8.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_60.jpg: 640x384 4 persons, 1 cell phone, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-938232524809973/frame_90.jpg: 640x384 7 persons, 9.1ms\n",
      "Speed: 2.9ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-937508703912579\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-937508703912579: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_120.jpg: 640x384 4 persons, 8.5ms\n",
      "Speed: 3.3ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_150.jpg: 640x384 4 persons, 12.5ms\n",
      "Speed: 4.2ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_180.jpg: 640x384 2 persons, 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_210.jpg: 640x384 2 persons, 10.0ms\n",
      "Speed: 3.6ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_240.jpg: 640x384 3 persons, 13.1ms\n",
      "Speed: 3.7ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_270.jpg: 640x384 2 persons, 11.1ms\n",
      "Speed: 3.6ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.2ms\n",
      "Speed: 3.2ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_300.jpg: 640x384 3 persons, 1 tv, 11.0ms\n",
      "Speed: 3.7ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_330.jpg: 640x384 2 persons, 11.0ms\n",
      "Speed: 4.2ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_360.jpg: 640x384 4 persons, 20.2ms\n",
      "Speed: 5.1ms preprocess, 20.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_390.jpg: 640x384 3 persons, 13.3ms\n",
      "Speed: 4.1ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_60.jpg: 640x384 4 persons, 14.3ms\n",
      "Speed: 4.5ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-937508703912579/frame_90.jpg: 640x384 6 persons, 12.5ms\n",
      "Speed: 3.4ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-935558767885747\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-935558767885747: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 17.9ms\n",
      "Speed: 4.1ms preprocess, 17.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_120.jpg: 640x384 4 persons, 7.1ms\n",
      "Speed: 2.6ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_150.jpg: 640x384 4 persons, 7.9ms\n",
      "Speed: 2.9ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_180.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_210.jpg: 640x384 2 persons, 8.5ms\n",
      "Speed: 3.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_240.jpg: 640x384 3 persons, 7.6ms\n",
      "Speed: 2.6ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_270.jpg: 640x384 2 persons, 9.0ms\n",
      "Speed: 2.8ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_30.jpg: 640x384 3 persons, 1 cell phone, 15.6ms\n",
      "Speed: 5.2ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_300.jpg: 640x384 3 persons, 1 tv, 12.4ms\n",
      "Speed: 3.8ms preprocess, 12.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_330.jpg: 640x384 2 persons, 10.4ms\n",
      "Speed: 3.9ms preprocess, 10.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_360.jpg: 640x384 4 persons, 11.9ms\n",
      "Speed: 3.2ms preprocess, 11.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_390.jpg: 640x384 3 persons, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_60.jpg: 640x384 4 persons, 7.3ms\n",
      "Speed: 2.6ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935558767885747/frame_90.jpg: 640x384 6 persons, 7.7ms\n",
      "Speed: 2.7ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-935530867630269\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-935530867630269: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 15.1ms\n",
      "Speed: 3.3ms preprocess, 15.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_120.jpg: 640x384 4 persons, 9.0ms\n",
      "Speed: 3.8ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_150.jpg: 640x384 4 persons, 13.5ms\n",
      "Speed: 4.1ms preprocess, 13.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_180.jpg: 640x384 2 persons, 11.5ms\n",
      "Speed: 3.1ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_210.jpg: 640x384 2 persons, 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_240.jpg: 640x384 3 persons, 12.8ms\n",
      "Speed: 3.9ms preprocess, 12.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_270.jpg: 640x384 2 persons, 30.6ms\n",
      "Speed: 4.5ms preprocess, 30.6ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_300.jpg: 640x384 3 persons, 1 tv, 9.3ms\n",
      "Speed: 4.0ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_330.jpg: 640x384 2 persons, 8.9ms\n",
      "Speed: 4.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_360.jpg: 640x384 4 persons, 8.2ms\n",
      "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_390.jpg: 640x384 3 persons, 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_60.jpg: 640x384 4 persons, 8.5ms\n",
      "Speed: 3.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935530867630269/frame_90.jpg: 640x384 6 persons, 8.3ms\n",
      "Speed: 3.0ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-935168780798574\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-935168780798574: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_120.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 2.5ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_150.jpg: 640x384 4 persons, 20.1ms\n",
      "Speed: 5.0ms preprocess, 20.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_180.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_210.jpg: 640x384 2 persons, 18.7ms\n",
      "Speed: 2.9ms preprocess, 18.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_240.jpg: 640x384 3 persons, 10.3ms\n",
      "Speed: 4.0ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_270.jpg: 640x384 2 persons, 12.8ms\n",
      "Speed: 3.5ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_30.jpg: 640x384 3 persons, 1 cell phone, 7.7ms\n",
      "Speed: 2.7ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_300.jpg: 640x384 3 persons, 1 tv, 7.8ms\n",
      "Speed: 3.3ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_330.jpg: 640x384 2 persons, 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_360.jpg: 640x384 4 persons, 26.6ms\n",
      "Speed: 3.4ms preprocess, 26.6ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_390.jpg: 640x384 3 persons, 10.6ms\n",
      "Speed: 4.1ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_60.jpg: 640x384 4 persons, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-935168780798574/frame_90.jpg: 640x384 6 persons, 10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-932296771464171\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-932296771464171: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_0.jpg: 640x384 1 person, 1 potted plant, 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_120.jpg: 640x384 2 persons, 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_150.jpg: 640x384 3 persons, 8.5ms\n",
      "Speed: 2.7ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_180.jpg: 640x384 1 person, 1 potted plant, 1 book, 8.7ms\n",
      "Speed: 2.8ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_210.jpg: 640x384 1 person, 2 potted plants, 1 book, 1 vase, 8.3ms\n",
      "Speed: 3.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_240.jpg: 640x384 2 potted plants, 1 book, 1 vase, 8.1ms\n",
      "Speed: 2.7ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_270.jpg: 640x384 1 book, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_30.jpg: 640x384 3 persons, 1 cup, 1 potted plant, 1 book, 10.6ms\n",
      "Speed: 3.4ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_300.jpg: 640x384 1 book, 13.8ms\n",
      "Speed: 4.2ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_330.jpg: 640x384 1 suitcase, 9.6ms\n",
      "Speed: 3.3ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_360.jpg: 640x384 1 bowl, 1 dining table, 8.1ms\n",
      "Speed: 2.5ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_390.jpg: 640x384 1 book, 9.3ms\n",
      "Speed: 3.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_420.jpg: 640x384 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_450.jpg: 640x384 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_480.jpg: 640x384 (no detections), 9.3ms\n",
      "Speed: 3.0ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_60.jpg: 640x384 1 person, 1 potted plant, 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932296771464171/frame_90.jpg: 640x384 1 person, 7.4ms\n",
      "Speed: 2.7ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-932085787962122\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-932085787962122: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.4ms\n",
      "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_120.jpg: 640x384 4 persons, 7.4ms\n",
      "Speed: 2.7ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_150.jpg: 640x384 4 persons, 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_180.jpg: 640x384 2 persons, 27.2ms\n",
      "Speed: 4.2ms preprocess, 27.2ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_210.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 3.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_240.jpg: 640x384 3 persons, 7.6ms\n",
      "Speed: 2.6ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_270.jpg: 640x384 2 persons, 7.5ms\n",
      "Speed: 2.4ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_300.jpg: 640x384 3 persons, 1 tv, 8.3ms\n",
      "Speed: 2.6ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_330.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 3.0ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_360.jpg: 640x384 4 persons, 10.2ms\n",
      "Speed: 3.2ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_390.jpg: 640x384 3 persons, 11.0ms\n",
      "Speed: 3.5ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_60.jpg: 640x384 4 persons, 12.1ms\n",
      "Speed: 3.1ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932085787962122/frame_90.jpg: 640x384 6 persons, 21.7ms\n",
      "Speed: 3.7ms preprocess, 21.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-932038864470963\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-932038864470963: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.6ms\n",
      "Speed: 2.6ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_120.jpg: 640x384 4 persons, 13.3ms\n",
      "Speed: 2.7ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_150.jpg: 640x384 4 persons, 7.3ms\n",
      "Speed: 2.5ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_180.jpg: 640x384 2 persons, 9.2ms\n",
      "Speed: 2.5ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_210.jpg: 640x384 2 persons, 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_240.jpg: 640x384 3 persons, 12.3ms\n",
      "Speed: 4.2ms preprocess, 12.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_270.jpg: 640x384 2 persons, 14.7ms\n",
      "Speed: 4.9ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_30.jpg: 640x384 3 persons, 1 cell phone, 12.6ms\n",
      "Speed: 4.3ms preprocess, 12.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_300.jpg: 640x384 3 persons, 1 tv, 13.6ms\n",
      "Speed: 3.8ms preprocess, 13.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_330.jpg: 640x384 2 persons, 15.2ms\n",
      "Speed: 3.9ms preprocess, 15.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_360.jpg: 640x384 4 persons, 12.2ms\n",
      "Speed: 3.6ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_390.jpg: 640x384 3 persons, 13.7ms\n",
      "Speed: 4.1ms preprocess, 13.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_60.jpg: 640x384 4 persons, 14.5ms\n",
      "Speed: 4.2ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-932038864470963/frame_90.jpg: 640x384 6 persons, 14.6ms\n",
      "Speed: 3.9ms preprocess, 14.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-929830031529018\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-929830031529018: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.3ms\n",
      "Speed: 2.7ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_120.jpg: 640x384 4 persons, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_150.jpg: 640x384 4 persons, 12.6ms\n",
      "Speed: 4.2ms preprocess, 12.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_180.jpg: 640x384 2 persons, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_210.jpg: 640x384 2 persons, 22.8ms\n",
      "Speed: 5.1ms preprocess, 22.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_240.jpg: 640x384 3 persons, 9.5ms\n",
      "Speed: 3.8ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_270.jpg: 640x384 2 persons, 28.2ms\n",
      "Speed: 3.9ms preprocess, 28.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_300.jpg: 640x384 3 persons, 1 tv, 9.9ms\n",
      "Speed: 3.7ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_330.jpg: 640x384 2 persons, 9.3ms\n",
      "Speed: 3.2ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_360.jpg: 640x384 4 persons, 11.4ms\n",
      "Speed: 3.9ms preprocess, 11.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_390.jpg: 640x384 3 persons, 31.7ms\n",
      "Speed: 5.1ms preprocess, 31.7ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_60.jpg: 640x384 4 persons, 13.9ms\n",
      "Speed: 4.5ms preprocess, 13.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929830031529018/frame_90.jpg: 640x384 6 persons, 9.4ms\n",
      "Speed: 2.7ms preprocess, 9.4ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-929511878466995\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-929511878466995: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_0.jpg: 640x384 (no detections), 8.8ms\n",
      "Speed: 3.7ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_120.jpg: 640x384 3 persons, 1 book, 9.6ms\n",
      "Speed: 3.7ms preprocess, 9.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_150.jpg: 640x384 2 persons, 31.9ms\n",
      "Speed: 4.9ms preprocess, 31.9ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_180.jpg: 640x384 1 person, 20.9ms\n",
      "Speed: 4.1ms preprocess, 20.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_210.jpg: 640x384 1 person, 12.3ms\n",
      "Speed: 4.2ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_240.jpg: 640x384 3 persons, 1 cell phone, 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_270.jpg: 640x384 1 person, 1 cell phone, 16.9ms\n",
      "Speed: 2.8ms preprocess, 16.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_30.jpg: 640x384 1 person, 7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_300.jpg: 640x384 1 person, 1 cell phone, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_330.jpg: 640x384 5 persons, 7.1ms\n",
      "Speed: 3.2ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_360.jpg: 640x384 1 person, 1 cell phone, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_390.jpg: 640x384 2 persons, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_420.jpg: 640x384 4 persons, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_450.jpg: 640x384 2 persons, 19.6ms\n",
      "Speed: 4.2ms preprocess, 19.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_480.jpg: 640x384 3 persons, 2 cars, 1 cell phone, 27.4ms\n",
      "Speed: 3.5ms preprocess, 27.4ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_510.jpg: 640x384 (no detections), 9.6ms\n",
      "Speed: 4.2ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_540.jpg: 640x384 (no detections), 10.2ms\n",
      "Speed: 3.2ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_60.jpg: 640x384 1 person, 8.8ms\n",
      "Speed: 2.8ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929511878466995/frame_90.jpg: 640x384 1 person, 7.4ms\n",
      "Speed: 2.6ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-929300948587514\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-929300948587514: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_0.jpg: 640x640 3 persons, 1 bed, 6.8ms\n",
      "Speed: 4.4ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_120.jpg: 640x640 1 person, 10.4ms\n",
      "Speed: 6.1ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_150.jpg: 640x640 2 persons, 1 cake, 12.9ms\n",
      "Speed: 6.4ms preprocess, 12.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_180.jpg: 640x640 2 persons, 1 tv, 13.3ms\n",
      "Speed: 7.7ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_210.jpg: 640x640 3 persons, 2 trains, 33.2ms\n",
      "Speed: 8.6ms preprocess, 33.2ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_240.jpg: 640x640 1 clock, 14.0ms\n",
      "Speed: 7.4ms preprocess, 14.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_270.jpg: 640x640 1 clock, 13.4ms\n",
      "Speed: 6.5ms preprocess, 13.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_30.jpg: 640x640 4 persons, 17.1ms\n",
      "Speed: 8.3ms preprocess, 17.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_60.jpg: 640x640 8 persons, 7.1ms\n",
      "Speed: 5.8ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-929300948587514/frame_90.jpg: 640x640 1 bed, 1 book, 23.0ms\n",
      "Speed: 7.2ms preprocess, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-925596815118953\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-925596815118953: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 10.8ms\n",
      "Speed: 4.1ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_120.jpg: 640x384 4 persons, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_150.jpg: 640x384 4 persons, 7.4ms\n",
      "Speed: 2.8ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_180.jpg: 640x384 2 persons, 8.7ms\n",
      "Speed: 2.4ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_210.jpg: 640x384 2 persons, 8.5ms\n",
      "Speed: 2.6ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_240.jpg: 640x384 3 persons, 9.4ms\n",
      "Speed: 3.3ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_270.jpg: 640x384 2 persons, 13.1ms\n",
      "Speed: 3.7ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_30.jpg: 640x384 3 persons, 1 cell phone, 13.5ms\n",
      "Speed: 4.2ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_300.jpg: 640x384 3 persons, 1 tv, 10.7ms\n",
      "Speed: 4.2ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_330.jpg: 640x384 2 persons, 12.8ms\n",
      "Speed: 4.1ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_360.jpg: 640x384 4 persons, 9.0ms\n",
      "Speed: 4.3ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_390.jpg: 640x384 3 persons, 9.5ms\n",
      "Speed: 2.9ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_60.jpg: 640x384 4 persons, 9.0ms\n",
      "Speed: 3.2ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-925596815118953/frame_90.jpg: 640x384 6 persons, 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-924865635226814\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-924865635226814: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_0.jpg: 640x384 2 tennis rackets, 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_120.jpg: 640x384 1 tennis racket, 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_150.jpg: 640x384 1 chair, 7.9ms\n",
      "Speed: 2.8ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_180.jpg: 640x384 1 chair, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_210.jpg: 640x384 1 tennis racket, 10.2ms\n",
      "Speed: 3.1ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_240.jpg: 640x384 1 tennis racket, 9.7ms\n",
      "Speed: 4.0ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_270.jpg: 640x384 1 tennis racket, 8.1ms\n",
      "Speed: 2.6ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_30.jpg: 640x384 2 tennis rackets, 8.2ms\n",
      "Speed: 2.7ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_300.jpg: 640x384 (no detections), 7.3ms\n",
      "Speed: 2.7ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_330.jpg: 640x384 1 person, 1 tennis racket, 1 cup, 13.0ms\n",
      "Speed: 3.5ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_360.jpg: 640x384 1 person, 1 tennis racket, 1 cup, 10.6ms\n",
      "Speed: 3.8ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_390.jpg: 640x384 (no detections), 9.7ms\n",
      "Speed: 3.7ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_420.jpg: 640x384 (no detections), 11.4ms\n",
      "Speed: 3.0ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_450.jpg: 640x384 (no detections), 10.7ms\n",
      "Speed: 3.3ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_60.jpg: 640x384 1 tennis racket, 10.6ms\n",
      "Speed: 3.8ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924865635226814/frame_90.jpg: 640x384 1 tennis racket, 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-924585008982148\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-924585008982148: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.9ms\n",
      "Speed: 2.5ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_120.jpg: 640x384 4 persons, 7.8ms\n",
      "Speed: 2.9ms preprocess, 7.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_150.jpg: 640x384 4 persons, 13.8ms\n",
      "Speed: 2.6ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_180.jpg: 640x384 2 persons, 7.4ms\n",
      "Speed: 3.0ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_210.jpg: 640x384 2 persons, 24.0ms\n",
      "Speed: 2.6ms preprocess, 24.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_240.jpg: 640x384 3 persons, 25.3ms\n",
      "Speed: 4.6ms preprocess, 25.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_270.jpg: 640x384 2 persons, 14.0ms\n",
      "Speed: 3.4ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_30.jpg: 640x384 3 persons, 1 cell phone, 7.3ms\n",
      "Speed: 2.7ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_300.jpg: 640x384 3 persons, 1 tv, 8.6ms\n",
      "Speed: 2.7ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_330.jpg: 640x384 2 persons, 8.7ms\n",
      "Speed: 3.4ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_360.jpg: 640x384 4 persons, 8.5ms\n",
      "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_390.jpg: 640x384 3 persons, 7.4ms\n",
      "Speed: 3.3ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_60.jpg: 640x384 4 persons, 8.1ms\n",
      "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-924585008982148/frame_90.jpg: 640x384 6 persons, 8.0ms\n",
      "Speed: 2.7ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-621652523105267\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-621652523105267: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_0.jpg: 640x384 1 person, 1 potted plant, 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_120.jpg: 640x384 2 persons, 7.8ms\n",
      "Speed: 2.9ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_150.jpg: 640x384 3 persons, 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_180.jpg: 640x384 1 person, 1 potted plant, 1 book, 9.2ms\n",
      "Speed: 3.5ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_210.jpg: 640x384 1 person, 2 potted plants, 1 book, 1 vase, 8.5ms\n",
      "Speed: 2.9ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_240.jpg: 640x384 2 potted plants, 1 book, 1 vase, 10.7ms\n",
      "Speed: 3.4ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_270.jpg: 640x384 1 book, 12.1ms\n",
      "Speed: 4.3ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_30.jpg: 640x384 3 persons, 1 cup, 1 potted plant, 1 book, 12.1ms\n",
      "Speed: 4.5ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_300.jpg: 640x384 1 book, 12.1ms\n",
      "Speed: 4.1ms preprocess, 12.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_330.jpg: 640x384 1 suitcase, 9.5ms\n",
      "Speed: 2.9ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_360.jpg: 640x384 1 bowl, 1 dining table, 11.8ms\n",
      "Speed: 3.1ms preprocess, 11.8ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_390.jpg: 640x384 1 book, 30.6ms\n",
      "Speed: 4.9ms preprocess, 30.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_420.jpg: 640x384 (no detections), 20.3ms\n",
      "Speed: 3.6ms preprocess, 20.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_450.jpg: 640x384 (no detections), 7.4ms\n",
      "Speed: 2.8ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_480.jpg: 640x384 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_60.jpg: 640x384 1 person, 1 potted plant, 15.6ms\n",
      "Speed: 3.2ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-621652523105267/frame_90.jpg: 640x384 1 person, 9.6ms\n",
      "Speed: 3.8ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-620702145697389\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-620702145697389: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_0.jpg: 640x384 1 bottle, 12.1ms\n",
      "Speed: 4.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_120.jpg: 640x384 (no detections), 11.0ms\n",
      "Speed: 3.6ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_150.jpg: 640x384 (no detections), 17.8ms\n",
      "Speed: 6.3ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_180.jpg: 640x384 (no detections), 19.3ms\n",
      "Speed: 5.5ms preprocess, 19.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_210.jpg: 640x384 1 motorcycle, 10.5ms\n",
      "Speed: 4.7ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_240.jpg: 640x384 2 persons, 1 potted plant, 1 dining table, 1 vase, 12.0ms\n",
      "Speed: 4.1ms preprocess, 12.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_270.jpg: 640x384 1 person, 1 dining table, 8.9ms\n",
      "Speed: 3.1ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_30.jpg: 640x384 1 bottle, 1 book, 1 vase, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_300.jpg: 640x384 2 persons, 1 cake, 1 potted plant, 1 dining table, 8.4ms\n",
      "Speed: 2.5ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_330.jpg: 640x384 1 person, 2 cakes, 1 dining table, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_360.jpg: 640x384 (no detections), 10.6ms\n",
      "Speed: 4.1ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_390.jpg: 640x384 (no detections), 11.3ms\n",
      "Speed: 4.5ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_420.jpg: 640x384 (no detections), 15.7ms\n",
      "Speed: 3.8ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_60.jpg: 640x384 1 bottle, 34.8ms\n",
      "Speed: 5.4ms preprocess, 34.8ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-620702145697389/frame_90.jpg: 640x384 1 bottle, 20.5ms\n",
      "Speed: 5.3ms preprocess, 20.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-6174004652651971\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-6174004652651971: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 10.3ms\n",
      "Speed: 3.7ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_120.jpg: 640x384 4 persons, 8.7ms\n",
      "Speed: 3.1ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_150.jpg: 640x384 4 persons, 14.9ms\n",
      "Speed: 4.8ms preprocess, 14.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_180.jpg: 640x384 2 persons, 10.4ms\n",
      "Speed: 3.5ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_210.jpg: 640x384 2 persons, 19.3ms\n",
      "Speed: 4.5ms preprocess, 19.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_240.jpg: 640x384 3 persons, 18.5ms\n",
      "Speed: 3.5ms preprocess, 18.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_270.jpg: 640x384 2 persons, 9.4ms\n",
      "Speed: 2.9ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_30.jpg: 640x384 3 persons, 1 cell phone, 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_300.jpg: 640x384 3 persons, 1 tv, 15.8ms\n",
      "Speed: 3.7ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_330.jpg: 640x384 2 persons, 24.7ms\n",
      "Speed: 4.2ms preprocess, 24.7ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_360.jpg: 640x384 4 persons, 12.7ms\n",
      "Speed: 3.6ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_390.jpg: 640x384 3 persons, 11.1ms\n",
      "Speed: 4.0ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_60.jpg: 640x384 4 persons, 9.4ms\n",
      "Speed: 3.2ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6174004652651971/frame_90.jpg: 640x384 6 persons, 9.4ms\n",
      "Speed: 2.6ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-617288786873081\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-617288786873081: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_0.jpg: 640x384 2 tennis rackets, 7.7ms\n",
      "Speed: 2.4ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_120.jpg: 640x384 1 tennis racket, 7.3ms\n",
      "Speed: 2.4ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_150.jpg: 640x384 1 chair, 8.4ms\n",
      "Speed: 2.7ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_180.jpg: 640x384 1 chair, 11.7ms\n",
      "Speed: 4.1ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_210.jpg: 640x384 1 tennis racket, 13.1ms\n",
      "Speed: 4.0ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_240.jpg: 640x384 1 tennis racket, 13.2ms\n",
      "Speed: 4.3ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_270.jpg: 640x384 1 tennis racket, 12.7ms\n",
      "Speed: 4.0ms preprocess, 12.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_30.jpg: 640x384 2 tennis rackets, 12.6ms\n",
      "Speed: 4.0ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_300.jpg: 640x384 (no detections), 12.4ms\n",
      "Speed: 4.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_330.jpg: 640x384 1 person, 1 tennis racket, 1 cup, 12.9ms\n",
      "Speed: 4.2ms preprocess, 12.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_360.jpg: 640x384 1 person, 1 tennis racket, 1 cup, 11.1ms\n",
      "Speed: 4.1ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_390.jpg: 640x384 (no detections), 16.5ms\n",
      "Speed: 4.7ms preprocess, 16.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_420.jpg: 640x384 (no detections), 15.3ms\n",
      "Speed: 4.0ms preprocess, 15.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_450.jpg: 640x384 (no detections), 12.3ms\n",
      "Speed: 3.7ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_60.jpg: 640x384 1 tennis racket, 12.6ms\n",
      "Speed: 4.0ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-617288786873081/frame_90.jpg: 640x384 1 tennis racket, 10.3ms\n",
      "Speed: 4.1ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-613417017284998\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-613417017284998: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.0ms\n",
      "Speed: 3.3ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_120.jpg: 640x384 4 persons, 7.2ms\n",
      "Speed: 2.7ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_150.jpg: 640x384 4 persons, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_180.jpg: 640x384 2 persons, 7.8ms\n",
      "Speed: 2.8ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_210.jpg: 640x384 2 persons, 9.1ms\n",
      "Speed: 2.8ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_240.jpg: 640x384 3 persons, 11.7ms\n",
      "Speed: 4.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_270.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_30.jpg: 640x384 3 persons, 1 cell phone, 13.5ms\n",
      "Speed: 3.9ms preprocess, 13.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_300.jpg: 640x384 3 persons, 1 tv, 10.0ms\n",
      "Speed: 3.4ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_330.jpg: 640x384 2 persons, 30.6ms\n",
      "Speed: 3.8ms preprocess, 30.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_360.jpg: 640x384 4 persons, 22.4ms\n",
      "Speed: 4.7ms preprocess, 22.4ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_390.jpg: 640x384 3 persons, 12.1ms\n",
      "Speed: 4.0ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_60.jpg: 640x384 4 persons, 8.2ms\n",
      "Speed: 3.0ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613417017284998/frame_90.jpg: 640x384 6 persons, 8.6ms\n",
      "Speed: 2.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-613197413789434\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-613197413789434: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_0.jpg: 640x384 1 couch, 1 potted plant, 8.3ms\n",
      "Speed: 2.5ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_120.jpg: 640x384 1 couch, 1 potted plant, 8.6ms\n",
      "Speed: 2.9ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_150.jpg: 640x384 1 chair, 1 couch, 2 potted plants, 9.1ms\n",
      "Speed: 3.6ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_180.jpg: 640x384 1 couch, 2 potted plants, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_210.jpg: 640x384 1 chair, 1 couch, 2 potted plants, 12.4ms\n",
      "Speed: 4.0ms preprocess, 12.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_240.jpg: 640x384 1 couch, 2 potted plants, 13.4ms\n",
      "Speed: 3.4ms preprocess, 13.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_270.jpg: 640x384 1 person, 1 chair, 1 couch, 2 potted plants, 13.8ms\n",
      "Speed: 3.1ms preprocess, 13.8ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_30.jpg: 640x384 1 chair, 1 couch, 12.6ms\n",
      "Speed: 4.0ms preprocess, 12.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_300.jpg: 640x384 1 couch, 10.6ms\n",
      "Speed: 5.1ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_330.jpg: 640x384 2 books, 14.6ms\n",
      "Speed: 4.0ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_360.jpg: 640x384 (no detections), 11.9ms\n",
      "Speed: 4.1ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_390.jpg: 640x384 (no detections), 12.7ms\n",
      "Speed: 3.5ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_60.jpg: 640x384 1 couch, 12.3ms\n",
      "Speed: 4.2ms preprocess, 12.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-613197413789434/frame_90.jpg: 640x384 1 potted plant, 9.6ms\n",
      "Speed: 4.1ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-612555930635832\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-612555930635832: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.1ms\n",
      "Speed: 2.7ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_120.jpg: 640x384 4 persons, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_150.jpg: 640x384 4 persons, 12.2ms\n",
      "Speed: 3.7ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_180.jpg: 640x384 2 persons, 13.2ms\n",
      "Speed: 4.1ms preprocess, 13.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_210.jpg: 640x384 2 persons, 13.8ms\n",
      "Speed: 4.3ms preprocess, 13.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_240.jpg: 640x384 3 persons, 10.8ms\n",
      "Speed: 4.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_270.jpg: 640x384 2 persons, 12.3ms\n",
      "Speed: 3.9ms preprocess, 12.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_30.jpg: 640x384 3 persons, 1 cell phone, 12.4ms\n",
      "Speed: 3.9ms preprocess, 12.4ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_300.jpg: 640x384 3 persons, 1 tv, 28.4ms\n",
      "Speed: 4.8ms preprocess, 28.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_330.jpg: 640x384 2 persons, 22.2ms\n",
      "Speed: 4.3ms preprocess, 22.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_360.jpg: 640x384 4 persons, 7.7ms\n",
      "Speed: 3.0ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_390.jpg: 640x384 3 persons, 11.0ms\n",
      "Speed: 3.6ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_60.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 2.9ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-612555930635832/frame_90.jpg: 640x384 6 persons, 9.4ms\n",
      "Speed: 2.7ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-611188517518682\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-611188517518682: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_0.jpg: 640x384 2 tennis rackets, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_120.jpg: 640x384 1 tennis racket, 7.5ms\n",
      "Speed: 3.3ms preprocess, 7.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_150.jpg: 640x384 1 chair, 7.6ms\n",
      "Speed: 2.8ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_180.jpg: 640x384 1 chair, 19.4ms\n",
      "Speed: 2.9ms preprocess, 19.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_210.jpg: 640x384 1 tennis racket, 27.0ms\n",
      "Speed: 4.2ms preprocess, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_240.jpg: 640x384 1 tennis racket, 11.9ms\n",
      "Speed: 4.2ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_270.jpg: 640x384 1 tennis racket, 9.9ms\n",
      "Speed: 3.9ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_30.jpg: 640x384 2 tennis rackets, 12.2ms\n",
      "Speed: 4.0ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_300.jpg: 640x384 (no detections), 11.9ms\n",
      "Speed: 4.2ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_330.jpg: 640x384 1 person, 1 tennis racket, 1 cup, 12.3ms\n",
      "Speed: 4.4ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_360.jpg: 640x384 1 person, 1 tennis racket, 1 cup, 15.5ms\n",
      "Speed: 4.2ms preprocess, 15.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_390.jpg: 640x384 (no detections), 12.0ms\n",
      "Speed: 3.6ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_420.jpg: 640x384 (no detections), 7.5ms\n",
      "Speed: 2.8ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_450.jpg: 640x384 (no detections), 7.8ms\n",
      "Speed: 2.8ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_60.jpg: 640x384 1 tennis racket, 8.3ms\n",
      "Speed: 2.7ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-611188517518682/frame_90.jpg: 640x384 1 tennis racket, 29.2ms\n",
      "Speed: 3.7ms preprocess, 29.2ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-6107397609317402\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-6107397609317402: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.9ms\n",
      "Speed: 3.0ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_120.jpg: 640x384 4 persons, 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_150.jpg: 640x384 4 persons, 7.8ms\n",
      "Speed: 2.7ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_180.jpg: 640x384 2 persons, 23.9ms\n",
      "Speed: 4.0ms preprocess, 23.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_210.jpg: 640x384 2 persons, 12.9ms\n",
      "Speed: 3.2ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_240.jpg: 640x384 3 persons, 18.1ms\n",
      "Speed: 5.2ms preprocess, 18.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_270.jpg: 640x384 2 persons, 7.8ms\n",
      "Speed: 2.6ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_30.jpg: 640x384 3 persons, 1 cell phone, 12.7ms\n",
      "Speed: 3.1ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_300.jpg: 640x384 3 persons, 1 tv, 17.0ms\n",
      "Speed: 3.3ms preprocess, 17.0ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_330.jpg: 640x384 2 persons, 10.8ms\n",
      "Speed: 3.2ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_360.jpg: 640x384 4 persons, 9.3ms\n",
      "Speed: 3.1ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_390.jpg: 640x384 3 persons, 9.1ms\n",
      "Speed: 3.1ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_60.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 3.2ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6107397609317402/frame_90.jpg: 640x384 6 persons, 9.0ms\n",
      "Speed: 2.9ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-604285914607200\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-604285914607200: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_0.jpg: 640x640 3 persons, 7.3ms\n",
      "Speed: 4.4ms preprocess, 7.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_120.jpg: 640x640 2 persons, 2 toothbrushs, 8.4ms\n",
      "Speed: 4.1ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_150.jpg: 640x640 1 cake, 1 toothbrush, 8.3ms\n",
      "Speed: 4.0ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_180.jpg: 640x640 (no detections), 29.4ms\n",
      "Speed: 6.4ms preprocess, 29.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_210.jpg: 640x640 (no detections), 27.9ms\n",
      "Speed: 6.8ms preprocess, 27.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_240.jpg: 640x640 (no detections), 11.4ms\n",
      "Speed: 5.2ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_270.jpg: 640x640 1 person, 9.5ms\n",
      "Speed: 4.4ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_30.jpg: 640x640 4 persons, 9.3ms\n",
      "Speed: 4.7ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_300.jpg: 640x640 1 umbrella, 1 potted plant, 7.6ms\n",
      "Speed: 3.8ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_330.jpg: 640x640 1 umbrella, 1 potted plant, 1 vase, 9.1ms\n",
      "Speed: 4.6ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_360.jpg: 640x640 1 potted plant, 1 vase, 10.1ms\n",
      "Speed: 5.3ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_390.jpg: 640x640 1 cup, 1 vase, 8.1ms\n",
      "Speed: 4.1ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_420.jpg: 640x640 1 vase, 9.2ms\n",
      "Speed: 4.3ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_450.jpg: 640x640 1 vase, 8.6ms\n",
      "Speed: 4.1ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_480.jpg: 640x640 1 vase, 29.4ms\n",
      "Speed: 5.6ms preprocess, 29.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_510.jpg: 640x640 1 vase, 15.2ms\n",
      "Speed: 6.7ms preprocess, 15.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_60.jpg: 640x640 1 person, 1 book, 26.2ms\n",
      "Speed: 6.3ms preprocess, 26.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-604285914607200/frame_90.jpg: 640x640 2 persons, 10.3ms\n",
      "Speed: 5.5ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-603099807587246\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-603099807587246: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_0.jpg: 640x640 2 persons, 7.3ms\n",
      "Speed: 4.2ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_116.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_116.jpg: 640x640 2 persons, 12.2ms\n",
      "Speed: 3.8ms preprocess, 12.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_145.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_145.jpg: 640x640 2 persons, 9.0ms\n",
      "Speed: 3.7ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_174.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_174.jpg: 640x640 2 persons, 8.1ms\n",
      "Speed: 4.1ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_203.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_203.jpg: 640x640 2 persons, 12.4ms\n",
      "Speed: 4.1ms preprocess, 12.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_232.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_232.jpg: 640x640 2 persons, 12.1ms\n",
      "Speed: 6.4ms preprocess, 12.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_261.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_261.jpg: 640x640 2 persons, 16.5ms\n",
      "Speed: 5.3ms preprocess, 16.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_29.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_29.jpg: 640x640 2 persons, 17.9ms\n",
      "Speed: 7.3ms preprocess, 17.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_290.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_290.jpg: 640x640 2 persons, 26.0ms\n",
      "Speed: 7.7ms preprocess, 26.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_319.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_319.jpg: 640x640 2 persons, 9.1ms\n",
      "Speed: 5.1ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_348.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_348.jpg: 640x640 2 persons, 10.2ms\n",
      "Speed: 4.9ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_377.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_377.jpg: 640x640 2 persons, 8.5ms\n",
      "Speed: 4.9ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_406.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_406.jpg: 640x640 2 persons, 9.7ms\n",
      "Speed: 4.3ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_435.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_435.jpg: 640x640 2 persons, 26.4ms\n",
      "Speed: 5.3ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_464.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_464.jpg: 640x640 2 persons, 13.6ms\n",
      "Speed: 5.7ms preprocess, 13.6ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_493.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_493.jpg: 640x640 2 persons, 12.7ms\n",
      "Speed: 6.3ms preprocess, 12.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_522.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_522.jpg: 640x640 2 persons, 13.0ms\n",
      "Speed: 6.0ms preprocess, 13.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_551.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_551.jpg: 640x640 2 persons, 11.6ms\n",
      "Speed: 5.1ms preprocess, 11.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_58.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_58.jpg: 640x640 2 persons, 13.0ms\n",
      "Speed: 5.1ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_580.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_580.jpg: 640x640 2 persons, 10.7ms\n",
      "Speed: 5.4ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_87.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-603099807587246/frame_87.jpg: 640x640 2 persons, 7.5ms\n",
      "Speed: 3.8ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-911482386703699\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-911482386703699: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.0ms\n",
      "Speed: 4.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_120.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 2.9ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_150.jpg: 640x384 4 persons, 9.2ms\n",
      "Speed: 2.7ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_180.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 2.9ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_210.jpg: 640x384 2 persons, 23.9ms\n",
      "Speed: 3.8ms preprocess, 23.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_240.jpg: 640x384 3 persons, 21.5ms\n",
      "Speed: 3.5ms preprocess, 21.5ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_270.jpg: 640x384 2 persons, 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_30.jpg: 640x384 3 persons, 1 cell phone, 27.6ms\n",
      "Speed: 3.7ms preprocess, 27.6ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_300.jpg: 640x384 3 persons, 1 tv, 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_330.jpg: 640x384 2 persons, 9.4ms\n",
      "Speed: 3.3ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_360.jpg: 640x384 4 persons, 8.8ms\n",
      "Speed: 3.2ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_390.jpg: 640x384 3 persons, 8.1ms\n",
      "Speed: 3.0ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_60.jpg: 640x384 4 persons, 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-911482386703699/frame_90.jpg: 640x384 6 persons, 12.4ms\n",
      "Speed: 3.6ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-909937876815529\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-909937876815529: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 21.3ms\n",
      "Speed: 3.3ms preprocess, 21.3ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_120.jpg: 640x384 4 persons, 11.2ms\n",
      "Speed: 3.3ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_150.jpg: 640x384 4 persons, 7.0ms\n",
      "Speed: 2.2ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_180.jpg: 640x384 2 persons, 8.6ms\n",
      "Speed: 2.5ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_210.jpg: 640x384 2 persons, 8.4ms\n",
      "Speed: 2.6ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_240.jpg: 640x384 3 persons, 8.8ms\n",
      "Speed: 2.6ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_270.jpg: 640x384 2 persons, 7.9ms\n",
      "Speed: 2.8ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.0ms\n",
      "Speed: 3.2ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_300.jpg: 640x384 3 persons, 1 tv, 9.4ms\n",
      "Speed: 3.2ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_330.jpg: 640x384 2 persons, 13.4ms\n",
      "Speed: 3.8ms preprocess, 13.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_360.jpg: 640x384 4 persons, 24.3ms\n",
      "Speed: 6.0ms preprocess, 24.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_390.jpg: 640x384 3 persons, 12.1ms\n",
      "Speed: 3.6ms preprocess, 12.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_60.jpg: 640x384 4 persons, 8.3ms\n",
      "Speed: 3.3ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909937876815529/frame_90.jpg: 640x384 6 persons, 8.7ms\n",
      "Speed: 3.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-909067460285978\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-909067460285978: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 13.6ms\n",
      "Speed: 2.5ms preprocess, 13.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_120.jpg: 640x384 4 persons, 8.0ms\n",
      "Speed: 3.3ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_150.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 2.8ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_180.jpg: 640x384 2 persons, 7.6ms\n",
      "Speed: 3.0ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_210.jpg: 640x384 2 persons, 7.9ms\n",
      "Speed: 3.2ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_240.jpg: 640x384 3 persons, 9.5ms\n",
      "Speed: 2.9ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_270.jpg: 640x384 2 persons, 24.7ms\n",
      "Speed: 3.8ms preprocess, 24.7ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_30.jpg: 640x384 3 persons, 1 cell phone, 13.0ms\n",
      "Speed: 3.2ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_300.jpg: 640x384 3 persons, 1 tv, 10.2ms\n",
      "Speed: 4.2ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_330.jpg: 640x384 2 persons, 14.8ms\n",
      "Speed: 3.7ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_360.jpg: 640x384 4 persons, 7.7ms\n",
      "Speed: 2.8ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_390.jpg: 640x384 3 persons, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_60.jpg: 640x384 4 persons, 7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-909067460285978/frame_90.jpg: 640x384 6 persons, 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-906909830682725\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-906909830682725: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.0ms\n",
      "Speed: 2.7ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_120.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 2.9ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_150.jpg: 640x384 4 persons, 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_180.jpg: 640x384 2 persons, 12.9ms\n",
      "Speed: 3.8ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_210.jpg: 640x384 2 persons, 11.3ms\n",
      "Speed: 4.1ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_240.jpg: 640x384 3 persons, 9.6ms\n",
      "Speed: 4.1ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_270.jpg: 640x384 2 persons, 13.2ms\n",
      "Speed: 4.1ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_30.jpg: 640x384 3 persons, 1 cell phone, 13.1ms\n",
      "Speed: 3.8ms preprocess, 13.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_300.jpg: 640x384 3 persons, 1 tv, 12.4ms\n",
      "Speed: 3.9ms preprocess, 12.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_330.jpg: 640x384 2 persons, 13.3ms\n",
      "Speed: 4.2ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_360.jpg: 640x384 4 persons, 18.1ms\n",
      "Speed: 5.2ms preprocess, 18.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_390.jpg: 640x384 3 persons, 20.4ms\n",
      "Speed: 3.3ms preprocess, 20.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_60.jpg: 640x384 4 persons, 23.8ms\n",
      "Speed: 3.9ms preprocess, 23.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906909830682725/frame_90.jpg: 640x384 6 persons, 8.3ms\n",
      "Speed: 3.6ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-906506897404894\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-906506897404894: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_0.jpg: 640x640 2 vases, 14.6ms\n",
      "Speed: 7.3ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_120.jpg: 640x640 (no detections), 9.9ms\n",
      "Speed: 7.6ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_150.jpg: 640x640 (no detections), 31.2ms\n",
      "Speed: 8.7ms preprocess, 31.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_180.jpg: 640x640 1 giraffe, 13.1ms\n",
      "Speed: 8.4ms preprocess, 13.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_210.jpg: 640x640 (no detections), 10.9ms\n",
      "Speed: 7.3ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_240.jpg: 640x640 (no detections), 11.7ms\n",
      "Speed: 4.5ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_270.jpg: 640x640 (no detections), 12.7ms\n",
      "Speed: 4.6ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_30.jpg: 640x640 1 person, 1 tie, 1 vase, 14.0ms\n",
      "Speed: 7.5ms preprocess, 14.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_300.jpg: 640x640 (no detections), 11.7ms\n",
      "Speed: 6.7ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_330.jpg: 640x640 (no detections), 7.8ms\n",
      "Speed: 4.2ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_360.jpg: 640x640 (no detections), 8.5ms\n",
      "Speed: 4.6ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_390.jpg: 640x640 (no detections), 7.8ms\n",
      "Speed: 4.9ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_60.jpg: 640x640 1 person, 3 books, 7.6ms\n",
      "Speed: 4.2ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-906506897404894/frame_90.jpg: 640x640 1 person, 1 book, 10.4ms\n",
      "Speed: 5.4ms preprocess, 10.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-905844110841635\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-905844110841635: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_120.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_150.jpg: 640x384 4 persons, 7.5ms\n",
      "Speed: 2.7ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_180.jpg: 640x384 2 persons, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_210.jpg: 640x384 2 persons, 7.4ms\n",
      "Speed: 2.6ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_240.jpg: 640x384 3 persons, 8.0ms\n",
      "Speed: 2.7ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_270.jpg: 640x384 2 persons, 8.0ms\n",
      "Speed: 2.8ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_300.jpg: 640x384 3 persons, 1 tv, 8.4ms\n",
      "Speed: 2.9ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_330.jpg: 640x384 2 persons, 10.2ms\n",
      "Speed: 3.5ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_360.jpg: 640x384 4 persons, 16.7ms\n",
      "Speed: 3.7ms preprocess, 16.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_390.jpg: 640x384 3 persons, 13.2ms\n",
      "Speed: 4.0ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_60.jpg: 640x384 4 persons, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905844110841635/frame_90.jpg: 640x384 6 persons, 20.1ms\n",
      "Speed: 4.8ms preprocess, 20.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-905545323817883\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-905545323817883: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_120.jpg: 640x384 4 persons, 7.2ms\n",
      "Speed: 2.4ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_150.jpg: 640x384 4 persons, 16.0ms\n",
      "Speed: 3.8ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_180.jpg: 640x384 2 persons, 28.5ms\n",
      "Speed: 4.1ms preprocess, 28.5ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_210.jpg: 640x384 2 persons, 13.1ms\n",
      "Speed: 3.6ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_240.jpg: 640x384 3 persons, 8.6ms\n",
      "Speed: 2.8ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_270.jpg: 640x384 2 persons, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.5ms\n",
      "Speed: 3.6ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_300.jpg: 640x384 3 persons, 1 tv, 9.2ms\n",
      "Speed: 3.1ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_330.jpg: 640x384 2 persons, 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_360.jpg: 640x384 4 persons, 8.0ms\n",
      "Speed: 2.4ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_390.jpg: 640x384 3 persons, 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_60.jpg: 640x384 4 persons, 28.0ms\n",
      "Speed: 3.8ms preprocess, 28.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-905545323817883/frame_90.jpg: 640x384 6 persons, 12.5ms\n",
      "Speed: 4.2ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-904815481005158\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-904815481005158: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_0.jpg: 640x384 1 person, 1 chair, 7.4ms\n",
      "Speed: 2.3ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_120.jpg: 640x384 3 persons, 1 cell phone, 7.9ms\n",
      "Speed: 2.7ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_150.jpg: 640x384 6 persons, 1 cell phone, 7.7ms\n",
      "Speed: 3.0ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_180.jpg: 640x384 3 persons, 1 cell phone, 8.0ms\n",
      "Speed: 2.8ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_210.jpg: 640x384 1 dining table, 11.4ms\n",
      "Speed: 4.1ms preprocess, 11.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_240.jpg: 640x384 1 cell phone, 12.8ms\n",
      "Speed: 4.2ms preprocess, 12.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_270.jpg: 640x384 2 persons, 11.3ms\n",
      "Speed: 4.9ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_30.jpg: 640x384 2 persons, 14.3ms\n",
      "Speed: 5.0ms preprocess, 14.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_300.jpg: 640x384 1 person, 1 tv, 12.2ms\n",
      "Speed: 4.0ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_330.jpg: 640x384 1 tennis racket, 1 toilet, 8.3ms\n",
      "Speed: 3.1ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_360.jpg: 640x384 (no detections), 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_390.jpg: 640x384 (no detections), 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_420.jpg: 640x384 (no detections), 14.0ms\n",
      "Speed: 4.1ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_450.jpg: 640x384 (no detections), 9.5ms\n",
      "Speed: 4.1ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_60.jpg: 640x384 2 persons, 13.3ms\n",
      "Speed: 4.3ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904815481005158/frame_90.jpg: 640x384 1 person, 1 bowl, 15.2ms\n",
      "Speed: 3.9ms preprocess, 15.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-904480964010630\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-904480964010630: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_0.jpg: 640x384 1 person, 1 potted plant, 9.1ms\n",
      "Speed: 2.8ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_120.jpg: 640x384 2 persons, 7.9ms\n",
      "Speed: 2.6ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_150.jpg: 640x384 3 persons, 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_180.jpg: 640x384 1 person, 1 potted plant, 1 book, 8.5ms\n",
      "Speed: 2.8ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_210.jpg: 640x384 1 person, 2 potted plants, 1 book, 1 vase, 7.7ms\n",
      "Speed: 2.3ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_240.jpg: 640x384 2 potted plants, 1 book, 1 vase, 8.8ms\n",
      "Speed: 3.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_270.jpg: 640x384 1 book, 10.7ms\n",
      "Speed: 4.1ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_30.jpg: 640x384 3 persons, 1 cup, 1 potted plant, 1 book, 10.7ms\n",
      "Speed: 3.3ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_300.jpg: 640x384 1 book, 12.1ms\n",
      "Speed: 4.2ms preprocess, 12.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_330.jpg: 640x384 1 suitcase, 8.7ms\n",
      "Speed: 3.2ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_360.jpg: 640x384 1 bowl, 1 dining table, 8.7ms\n",
      "Speed: 3.0ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_390.jpg: 640x384 1 book, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_420.jpg: 640x384 (no detections), 12.5ms\n",
      "Speed: 3.0ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_450.jpg: 640x384 (no detections), 18.0ms\n",
      "Speed: 4.2ms preprocess, 18.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_480.jpg: 640x384 (no detections), 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_60.jpg: 640x384 1 person, 1 potted plant, 28.7ms\n",
      "Speed: 3.0ms preprocess, 28.7ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-904480964010630/frame_90.jpg: 640x384 1 person, 25.1ms\n",
      "Speed: 4.2ms preprocess, 25.1ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-903960640750545\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-903960640750545: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_0.jpg: 640x384 2 tennis rackets, 7.7ms\n",
      "Speed: 2.5ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_120.jpg: 640x384 1 tennis racket, 9.5ms\n",
      "Speed: 3.3ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_150.jpg: 640x384 1 chair, 7.7ms\n",
      "Speed: 2.8ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_180.jpg: 640x384 1 chair, 8.4ms\n",
      "Speed: 2.5ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_210.jpg: 640x384 1 tennis racket, 9.2ms\n",
      "Speed: 2.7ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_240.jpg: 640x384 1 tennis racket, 12.2ms\n",
      "Speed: 4.4ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_270.jpg: 640x384 1 tennis racket, 17.4ms\n",
      "Speed: 4.1ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_30.jpg: 640x384 2 tennis rackets, 9.4ms\n",
      "Speed: 3.6ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_300.jpg: 640x384 (no detections), 9.3ms\n",
      "Speed: 2.6ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_330.jpg: 640x384 1 person, 1 tennis racket, 1 cup, 8.3ms\n",
      "Speed: 2.7ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_360.jpg: 640x384 1 person, 1 tennis racket, 1 cup, 9.5ms\n",
      "Speed: 3.2ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_390.jpg: 640x384 (no detections), 9.4ms\n",
      "Speed: 2.8ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_420.jpg: 640x384 (no detections), 8.3ms\n",
      "Speed: 3.2ms preprocess, 8.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_450.jpg: 640x384 (no detections), 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_60.jpg: 640x384 1 tennis racket, 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-903960640750545/frame_90.jpg: 640x384 1 tennis racket, 10.5ms\n",
      "Speed: 4.2ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-902843234362370\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-902843234362370: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.3ms\n",
      "Speed: 2.6ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_120.jpg: 640x384 4 persons, 7.8ms\n",
      "Speed: 2.8ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_150.jpg: 640x384 4 persons, 8.5ms\n",
      "Speed: 3.0ms preprocess, 8.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_180.jpg: 640x384 2 persons, 8.8ms\n",
      "Speed: 2.8ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_210.jpg: 640x384 2 persons, 11.2ms\n",
      "Speed: 4.3ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_240.jpg: 640x384 3 persons, 32.2ms\n",
      "Speed: 5.3ms preprocess, 32.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_270.jpg: 640x384 2 persons, 16.8ms\n",
      "Speed: 4.3ms preprocess, 16.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_30.jpg: 640x384 3 persons, 1 cell phone, 12.5ms\n",
      "Speed: 4.2ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_300.jpg: 640x384 3 persons, 1 tv, 12.7ms\n",
      "Speed: 3.6ms preprocess, 12.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_330.jpg: 640x384 2 persons, 12.8ms\n",
      "Speed: 3.4ms preprocess, 12.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_360.jpg: 640x384 4 persons, 24.2ms\n",
      "Speed: 4.4ms preprocess, 24.2ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_390.jpg: 640x384 3 persons, 8.1ms\n",
      "Speed: 2.9ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_60.jpg: 640x384 4 persons, 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902843234362370/frame_90.jpg: 640x384 6 persons, 9.7ms\n",
      "Speed: 3.1ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-902309670925392\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-902309670925392: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.9ms\n",
      "Speed: 2.5ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_120.jpg: 640x384 4 persons, 7.9ms\n",
      "Speed: 3.4ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_150.jpg: 640x384 4 persons, 11.7ms\n",
      "Speed: 4.1ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_180.jpg: 640x384 2 persons, 10.4ms\n",
      "Speed: 3.8ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_210.jpg: 640x384 2 persons, 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_240.jpg: 640x384 3 persons, 8.5ms\n",
      "Speed: 3.1ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_270.jpg: 640x384 2 persons, 21.3ms\n",
      "Speed: 3.1ms preprocess, 21.3ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_30.jpg: 640x384 3 persons, 1 cell phone, 19.5ms\n",
      "Speed: 4.7ms preprocess, 19.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_300.jpg: 640x384 3 persons, 1 tv, 9.7ms\n",
      "Speed: 3.4ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_330.jpg: 640x384 2 persons, 9.0ms\n",
      "Speed: 3.3ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_360.jpg: 640x384 4 persons, 7.9ms\n",
      "Speed: 2.5ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_390.jpg: 640x384 3 persons, 11.1ms\n",
      "Speed: 3.9ms preprocess, 11.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_60.jpg: 640x384 4 persons, 10.8ms\n",
      "Speed: 3.5ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-902309670925392/frame_90.jpg: 640x384 6 persons, 10.3ms\n",
      "Speed: 3.6ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-9020567984620018\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-9020567984620018: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.5ms\n",
      "Speed: 3.2ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_120.jpg: 640x384 4 persons, 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_150.jpg: 640x384 4 persons, 11.4ms\n",
      "Speed: 3.3ms preprocess, 11.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_180.jpg: 640x384 2 persons, 11.9ms\n",
      "Speed: 3.0ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_210.jpg: 640x384 2 persons, 10.9ms\n",
      "Speed: 4.1ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_240.jpg: 640x384 3 persons, 11.9ms\n",
      "Speed: 4.0ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_270.jpg: 640x384 2 persons, 11.4ms\n",
      "Speed: 4.3ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.7ms\n",
      "Speed: 3.4ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_300.jpg: 640x384 3 persons, 1 tv, 13.2ms\n",
      "Speed: 3.9ms preprocess, 13.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_330.jpg: 640x384 2 persons, 33.7ms\n",
      "Speed: 4.7ms preprocess, 33.7ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_360.jpg: 640x384 4 persons, 11.8ms\n",
      "Speed: 3.8ms preprocess, 11.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_390.jpg: 640x384 3 persons, 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_60.jpg: 640x384 4 persons, 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-9020567984620018/frame_90.jpg: 640x384 6 persons, 18.8ms\n",
      "Speed: 3.7ms preprocess, 18.8ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-901695498551491\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-901695498551491: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_0.jpg: 640x640 1 person, 1 car, 7.0ms\n",
      "Speed: 7.3ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_120.jpg: 640x640 10 persons, 12.8ms\n",
      "Speed: 8.6ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_150.jpg: 640x640 9 persons, 12.7ms\n",
      "Speed: 7.6ms preprocess, 12.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_180.jpg: 640x640 8 persons, 1 cup, 21.2ms\n",
      "Speed: 7.0ms preprocess, 21.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_210.jpg: 640x640 1 person, 1 dining table, 21.8ms\n",
      "Speed: 6.9ms preprocess, 21.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_240.jpg: 640x640 3 persons, 2 cell phones, 10.1ms\n",
      "Speed: 6.6ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_270.jpg: 640x640 3 persons, 21.0ms\n",
      "Speed: 6.4ms preprocess, 21.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_30.jpg: 640x640 1 person, 2 cars, 8.5ms\n",
      "Speed: 4.7ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_300.jpg: 640x640 1 person, 8.1ms\n",
      "Speed: 4.2ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_330.jpg: 640x640 2 persons, 7.4ms\n",
      "Speed: 4.3ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_360.jpg: 640x640 2 persons, 7.4ms\n",
      "Speed: 4.2ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_390.jpg: 640x640 1 person, 1 cell phone, 9.9ms\n",
      "Speed: 5.4ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_420.jpg: 640x640 (no detections), 9.2ms\n",
      "Speed: 5.3ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_450.jpg: 640x640 (no detections), 9.8ms\n",
      "Speed: 5.8ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_480.jpg: 640x640 (no detections), 10.2ms\n",
      "Speed: 5.7ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_60.jpg: 640x640 1 truck, 11.3ms\n",
      "Speed: 5.8ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901695498551491/frame_90.jpg: 640x640 (no detections), 18.8ms\n",
      "Speed: 8.1ms preprocess, 18.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-901272811190482\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-901272811190482: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_0.jpg: 640x384 1 person, 1 potted plant, 9.0ms\n",
      "Speed: 3.1ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_120.jpg: 640x384 2 persons, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_150.jpg: 640x384 3 persons, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_180.jpg: 640x384 1 person, 1 potted plant, 1 book, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_210.jpg: 640x384 1 person, 2 potted plants, 1 book, 1 vase, 12.6ms\n",
      "Speed: 4.2ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_240.jpg: 640x384 2 potted plants, 1 book, 1 vase, 12.5ms\n",
      "Speed: 4.1ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_270.jpg: 640x384 1 book, 10.2ms\n",
      "Speed: 3.7ms preprocess, 10.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_30.jpg: 640x384 3 persons, 1 cup, 1 potted plant, 1 book, 11.3ms\n",
      "Speed: 3.9ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_300.jpg: 640x384 1 book, 9.4ms\n",
      "Speed: 2.8ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_330.jpg: 640x384 1 suitcase, 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_360.jpg: 640x384 1 bowl, 1 dining table, 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_390.jpg: 640x384 1 book, 12.6ms\n",
      "Speed: 4.5ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_420.jpg: 640x384 (no detections), 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_450.jpg: 640x384 (no detections), 13.6ms\n",
      "Speed: 3.8ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_480.jpg: 640x384 (no detections), 15.2ms\n",
      "Speed: 4.3ms preprocess, 15.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_60.jpg: 640x384 1 person, 1 potted plant, 18.7ms\n",
      "Speed: 4.8ms preprocess, 18.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-901272811190482/frame_90.jpg: 640x384 1 person, 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8995485367146316\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8995485367146316: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_0.jpg: 640x640 1 person, 1 chair, 1 clock, 7.3ms\n",
      "Speed: 5.4ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_120.jpg: 640x640 1 person, 1 clock, 8.0ms\n",
      "Speed: 5.6ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_150.jpg: 640x640 1 person, 2 clocks, 7.9ms\n",
      "Speed: 5.8ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_180.jpg: 640x640 1 person, 1 chair, 8.7ms\n",
      "Speed: 4.3ms preprocess, 8.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_210.jpg: 640x640 2 persons, 24.1ms\n",
      "Speed: 8.1ms preprocess, 24.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_240.jpg: 640x640 2 persons, 1 chair, 1 clock, 9.0ms\n",
      "Speed: 5.8ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_270.jpg: 640x640 2 persons, 1 chair, 8.4ms\n",
      "Speed: 5.2ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_30.jpg: 640x640 1 person, 1 chair, 1 clock, 7.7ms\n",
      "Speed: 5.0ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_300.jpg: 640x640 (no detections), 7.8ms\n",
      "Speed: 4.4ms preprocess, 7.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_330.jpg: 640x640 (no detections), 6.8ms\n",
      "Speed: 4.1ms preprocess, 6.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_60.jpg: 640x640 2 persons, 1 bowl, 15.7ms\n",
      "Speed: 4.8ms preprocess, 15.7ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8995485367146316/frame_90.jpg: 640x640 3 persons, 27.0ms\n",
      "Speed: 7.4ms preprocess, 27.0ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-898967424867870\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-898967424867870: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.5ms\n",
      "Speed: 2.5ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_120.jpg: 640x384 4 persons, 7.5ms\n",
      "Speed: 2.9ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_150.jpg: 640x384 4 persons, 7.8ms\n",
      "Speed: 2.3ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_180.jpg: 640x384 2 persons, 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_210.jpg: 640x384 2 persons, 7.9ms\n",
      "Speed: 2.5ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_240.jpg: 640x384 3 persons, 10.0ms\n",
      "Speed: 3.3ms preprocess, 10.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_270.jpg: 640x384 2 persons, 19.4ms\n",
      "Speed: 3.0ms preprocess, 19.4ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_30.jpg: 640x384 3 persons, 1 cell phone, 16.3ms\n",
      "Speed: 3.3ms preprocess, 16.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_300.jpg: 640x384 3 persons, 1 tv, 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_330.jpg: 640x384 2 persons, 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_360.jpg: 640x384 4 persons, 9.2ms\n",
      "Speed: 3.2ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_390.jpg: 640x384 3 persons, 8.5ms\n",
      "Speed: 3.1ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_60.jpg: 640x384 4 persons, 9.1ms\n",
      "Speed: 2.3ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898967424867870/frame_90.jpg: 640x384 6 persons, 8.6ms\n",
      "Speed: 2.7ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-898103501380741\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-898103501380741: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.6ms\n",
      "Speed: 3.0ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_120.jpg: 640x384 4 persons, 7.5ms\n",
      "Speed: 3.1ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_150.jpg: 640x384 4 persons, 9.4ms\n",
      "Speed: 3.1ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_180.jpg: 640x384 2 persons, 12.5ms\n",
      "Speed: 3.6ms preprocess, 12.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_210.jpg: 640x384 2 persons, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_240.jpg: 640x384 3 persons, 12.4ms\n",
      "Speed: 3.8ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_270.jpg: 640x384 2 persons, 16.8ms\n",
      "Speed: 5.0ms preprocess, 16.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_30.jpg: 640x384 3 persons, 1 cell phone, 33.3ms\n",
      "Speed: 3.9ms preprocess, 33.3ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_300.jpg: 640x384 3 persons, 1 tv, 17.4ms\n",
      "Speed: 3.7ms preprocess, 17.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_330.jpg: 640x384 2 persons, 11.4ms\n",
      "Speed: 3.9ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_360.jpg: 640x384 4 persons, 12.0ms\n",
      "Speed: 3.5ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_390.jpg: 640x384 3 persons, 11.7ms\n",
      "Speed: 3.9ms preprocess, 11.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_60.jpg: 640x384 4 persons, 16.4ms\n",
      "Speed: 4.5ms preprocess, 16.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-898103501380741/frame_90.jpg: 640x384 6 persons, 13.7ms\n",
      "Speed: 4.1ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-897088088160051\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-897088088160051: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_120.jpg: 640x384 4 persons, 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_150.jpg: 640x384 4 persons, 7.3ms\n",
      "Speed: 2.8ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_180.jpg: 640x384 2 persons, 8.7ms\n",
      "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_210.jpg: 640x384 2 persons, 8.5ms\n",
      "Speed: 3.8ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_240.jpg: 640x384 3 persons, 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_270.jpg: 640x384 2 persons, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_30.jpg: 640x384 3 persons, 1 cell phone, 19.6ms\n",
      "Speed: 3.5ms preprocess, 19.6ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_300.jpg: 640x384 3 persons, 1 tv, 10.7ms\n",
      "Speed: 3.7ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_330.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 3.2ms preprocess, 8.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_360.jpg: 640x384 4 persons, 23.7ms\n",
      "Speed: 4.2ms preprocess, 23.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_390.jpg: 640x384 3 persons, 8.6ms\n",
      "Speed: 2.3ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_60.jpg: 640x384 4 persons, 10.4ms\n",
      "Speed: 3.7ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-897088088160051/frame_90.jpg: 640x384 6 persons, 14.0ms\n",
      "Speed: 2.5ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-896589688256009\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-896589688256009: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.8ms\n",
      "Speed: 2.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_120.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 2.6ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_150.jpg: 640x384 4 persons, 9.4ms\n",
      "Speed: 3.1ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_180.jpg: 640x384 2 persons, 9.4ms\n",
      "Speed: 2.7ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_210.jpg: 640x384 2 persons, 12.5ms\n",
      "Speed: 3.6ms preprocess, 12.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_240.jpg: 640x384 3 persons, 13.9ms\n",
      "Speed: 4.0ms preprocess, 13.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_270.jpg: 640x384 2 persons, 12.2ms\n",
      "Speed: 4.6ms preprocess, 12.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_30.jpg: 640x384 3 persons, 1 cell phone, 14.6ms\n",
      "Speed: 4.8ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_300.jpg: 640x384 3 persons, 1 tv, 12.3ms\n",
      "Speed: 3.5ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_330.jpg: 640x384 2 persons, 13.4ms\n",
      "Speed: 4.2ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_360.jpg: 640x384 4 persons, 17.2ms\n",
      "Speed: 4.3ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_390.jpg: 640x384 3 persons, 26.1ms\n",
      "Speed: 4.1ms preprocess, 26.1ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_60.jpg: 640x384 4 persons, 16.8ms\n",
      "Speed: 3.7ms preprocess, 16.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-896589688256009/frame_90.jpg: 640x384 6 persons, 7.9ms\n",
      "Speed: 3.1ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-895042408159688\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-895042408159688: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_120.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 2.7ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_150.jpg: 640x384 4 persons, 7.7ms\n",
      "Speed: 2.7ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_180.jpg: 640x384 2 persons, 8.7ms\n",
      "Speed: 2.5ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_210.jpg: 640x384 2 persons, 12.6ms\n",
      "Speed: 4.2ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_240.jpg: 640x384 3 persons, 12.5ms\n",
      "Speed: 4.2ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_270.jpg: 640x384 2 persons, 32.7ms\n",
      "Speed: 4.5ms preprocess, 32.7ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_30.jpg: 640x384 3 persons, 1 cell phone, 12.4ms\n",
      "Speed: 3.9ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_300.jpg: 640x384 3 persons, 1 tv, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_330.jpg: 640x384 2 persons, 10.5ms\n",
      "Speed: 4.0ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_360.jpg: 640x384 4 persons, 7.8ms\n",
      "Speed: 2.9ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_390.jpg: 640x384 3 persons, 12.7ms\n",
      "Speed: 4.2ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_60.jpg: 640x384 4 persons, 9.0ms\n",
      "Speed: 2.7ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-895042408159688/frame_90.jpg: 640x384 6 persons, 28.9ms\n",
      "Speed: 4.9ms preprocess, 28.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-894559812351386\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-894559812351386: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_0.jpg: 640x640 (no detections), 11.0ms\n",
      "Speed: 8.0ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_120.jpg: 640x640 3 persons, 1 book, 8.5ms\n",
      "Speed: 5.8ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_150.jpg: 640x640 4 persons, 9.2ms\n",
      "Speed: 4.8ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_180.jpg: 640x640 1 person, 18.7ms\n",
      "Speed: 6.3ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_210.jpg: 640x640 2 persons, 7.1ms\n",
      "Speed: 4.3ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_240.jpg: 640x640 4 persons, 7.9ms\n",
      "Speed: 4.4ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_270.jpg: 640x640 1 person, 1 cell phone, 10.7ms\n",
      "Speed: 4.1ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_30.jpg: 640x640 2 persons, 1 vase, 8.3ms\n",
      "Speed: 5.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_300.jpg: 640x640 1 person, 1 cell phone, 13.4ms\n",
      "Speed: 6.9ms preprocess, 13.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_330.jpg: 640x640 4 persons, 1 cell phone, 16.1ms\n",
      "Speed: 10.2ms preprocess, 16.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_360.jpg: 640x640 1 person, 1 cell phone, 24.9ms\n",
      "Speed: 9.0ms preprocess, 24.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_390.jpg: 640x640 4 persons, 2 tvs, 14.2ms\n",
      "Speed: 6.9ms preprocess, 14.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_420.jpg: 640x640 3 persons, 12.4ms\n",
      "Speed: 8.8ms preprocess, 12.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_450.jpg: 640x640 5 persons, 13.0ms\n",
      "Speed: 7.9ms preprocess, 13.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_480.jpg: 640x640 3 persons, 1 cell phone, 10.7ms\n",
      "Speed: 6.6ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_510.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 6.0ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_540.jpg: 640x640 (no detections), 7.7ms\n",
      "Speed: 5.2ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_60.jpg: 640x640 3 persons, 12.0ms\n",
      "Speed: 7.9ms preprocess, 12.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894559812351386/frame_90.jpg: 640x640 (no detections), 10.9ms\n",
      "Speed: 5.5ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-894457734962164\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-894457734962164: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.0ms\n",
      "Speed: 2.6ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_120.jpg: 640x384 4 persons, 8.7ms\n",
      "Speed: 3.7ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_150.jpg: 640x384 4 persons, 8.8ms\n",
      "Speed: 2.6ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_180.jpg: 640x384 2 persons, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_210.jpg: 640x384 2 persons, 8.5ms\n",
      "Speed: 2.5ms preprocess, 8.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_240.jpg: 640x384 3 persons, 24.9ms\n",
      "Speed: 4.7ms preprocess, 24.9ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_270.jpg: 640x384 2 persons, 9.9ms\n",
      "Speed: 4.3ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_300.jpg: 640x384 3 persons, 1 tv, 23.2ms\n",
      "Speed: 4.1ms preprocess, 23.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_330.jpg: 640x384 2 persons, 16.3ms\n",
      "Speed: 4.2ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_360.jpg: 640x384 4 persons, 8.9ms\n",
      "Speed: 3.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_390.jpg: 640x384 3 persons, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_60.jpg: 640x384 4 persons, 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894457734962164/frame_90.jpg: 640x384 6 persons, 11.6ms\n",
      "Speed: 4.1ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-894066258497958\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-894066258497958: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_120.jpg: 640x384 4 persons, 7.6ms\n",
      "Speed: 2.3ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_150.jpg: 640x384 4 persons, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_180.jpg: 640x384 2 persons, 12.2ms\n",
      "Speed: 4.3ms preprocess, 12.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_210.jpg: 640x384 2 persons, 26.9ms\n",
      "Speed: 3.6ms preprocess, 26.9ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_240.jpg: 640x384 3 persons, 9.0ms\n",
      "Speed: 3.6ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_270.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 3.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.6ms\n",
      "Speed: 3.3ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_300.jpg: 640x384 3 persons, 1 tv, 11.9ms\n",
      "Speed: 3.8ms preprocess, 11.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_330.jpg: 640x384 2 persons, 12.5ms\n",
      "Speed: 4.3ms preprocess, 12.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_360.jpg: 640x384 4 persons, 17.9ms\n",
      "Speed: 4.0ms preprocess, 17.9ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_390.jpg: 640x384 3 persons, 12.3ms\n",
      "Speed: 3.8ms preprocess, 12.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_60.jpg: 640x384 4 persons, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-894066258497958/frame_90.jpg: 640x384 6 persons, 13.0ms\n",
      "Speed: 4.7ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-893539262677484\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-893539262677484: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_0.jpg: 640x384 1 person, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_120.jpg: 640x384 1 person, 10.6ms\n",
      "Speed: 3.9ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_150.jpg: 640x384 4 persons, 1 cell phone, 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_180.jpg: 640x384 2 persons, 14.3ms\n",
      "Speed: 2.6ms preprocess, 14.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_210.jpg: 640x384 3 persons, 1 remote, 11.9ms\n",
      "Speed: 3.4ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_240.jpg: 640x384 2 persons, 21.8ms\n",
      "Speed: 4.1ms preprocess, 21.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_270.jpg: 640x384 1 person, 1 remote, 30.0ms\n",
      "Speed: 3.5ms preprocess, 30.0ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_30.jpg: 640x384 1 person, 24.7ms\n",
      "Speed: 4.8ms preprocess, 24.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_300.jpg: 640x384 1 person, 1 cell phone, 12.9ms\n",
      "Speed: 3.6ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_330.jpg: 640x384 1 person, 9.8ms\n",
      "Speed: 3.6ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_360.jpg: 640x384 1 person, 2 cell phones, 11.2ms\n",
      "Speed: 3.5ms preprocess, 11.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_390.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.7ms\n",
      "Speed: 3.7ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_420.jpg: 640x384 1 person, 1 cell phone, 12.3ms\n",
      "Speed: 4.2ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_450.jpg: 640x384 2 persons, 1 laptop, 1 cell phone, 13.6ms\n",
      "Speed: 3.8ms preprocess, 13.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_480.jpg: 640x384 2 persons, 1 laptop, 1 cell phone, 1 book, 28.2ms\n",
      "Speed: 4.4ms preprocess, 28.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_510.jpg: 640x384 2 persons, 1 potted plant, 1 remote, 1 cell phone, 11.3ms\n",
      "Speed: 4.3ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_540.jpg: 640x384 1 person, 1 potted plant, 11.6ms\n",
      "Speed: 4.5ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_570.jpg: 640x384 1 potted plant, 14.4ms\n",
      "Speed: 3.8ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_60.jpg: 640x384 (no detections), 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_600.jpg: 640x384 (no detections), 8.0ms\n",
      "Speed: 3.1ms preprocess, 8.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_630.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_630.jpg: 640x384 (no detections), 22.7ms\n",
      "Speed: 3.0ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_660.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_660.jpg: 640x384 (no detections), 29.3ms\n",
      "Speed: 4.1ms preprocess, 29.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_690.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_690.jpg: 640x384 (no detections), 13.0ms\n",
      "Speed: 3.8ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893539262677484/frame_90.jpg: 640x384 1 person, 18.8ms\n",
      "Speed: 4.3ms preprocess, 18.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-893173505441981\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-893173505441981: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.4ms\n",
      "Speed: 2.6ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_120.jpg: 640x384 4 persons, 7.8ms\n",
      "Speed: 2.6ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_150.jpg: 640x384 4 persons, 8.0ms\n",
      "Speed: 2.6ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_180.jpg: 640x384 2 persons, 30.3ms\n",
      "Speed: 4.4ms preprocess, 30.3ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_210.jpg: 640x384 2 persons, 13.4ms\n",
      "Speed: 3.4ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_240.jpg: 640x384 3 persons, 8.4ms\n",
      "Speed: 3.2ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_270.jpg: 640x384 2 persons, 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_30.jpg: 640x384 3 persons, 1 cell phone, 8.7ms\n",
      "Speed: 2.7ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_300.jpg: 640x384 3 persons, 1 tv, 15.1ms\n",
      "Speed: 4.1ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_330.jpg: 640x384 2 persons, 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_360.jpg: 640x384 4 persons, 9.7ms\n",
      "Speed: 3.2ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_390.jpg: 640x384 3 persons, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_60.jpg: 640x384 4 persons, 14.9ms\n",
      "Speed: 4.5ms preprocess, 14.9ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-893173505441981/frame_90.jpg: 640x384 6 persons, 12.2ms\n",
      "Speed: 3.8ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-892383375224287\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-892383375224287: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.6ms\n",
      "Speed: 2.9ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_120.jpg: 640x384 4 persons, 9.0ms\n",
      "Speed: 2.8ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_150.jpg: 640x384 4 persons, 7.8ms\n",
      "Speed: 2.7ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_180.jpg: 640x384 2 persons, 8.0ms\n",
      "Speed: 2.6ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_210.jpg: 640x384 2 persons, 7.3ms\n",
      "Speed: 2.6ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_240.jpg: 640x384 3 persons, 8.3ms\n",
      "Speed: 2.7ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_270.jpg: 640x384 2 persons, 9.3ms\n",
      "Speed: 3.9ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_300.jpg: 640x384 3 persons, 1 tv, 8.7ms\n",
      "Speed: 3.3ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_330.jpg: 640x384 2 persons, 11.1ms\n",
      "Speed: 3.7ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_360.jpg: 640x384 4 persons, 9.2ms\n",
      "Speed: 2.8ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_390.jpg: 640x384 3 persons, 9.2ms\n",
      "Speed: 2.6ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_60.jpg: 640x384 4 persons, 19.5ms\n",
      "Speed: 4.1ms preprocess, 19.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-892383375224287/frame_90.jpg: 640x384 6 persons, 8.8ms\n",
      "Speed: 2.9ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-891661008828094\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-891661008828094: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.7ms\n",
      "Speed: 2.3ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_120.jpg: 640x384 4 persons, 8.0ms\n",
      "Speed: 2.7ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_150.jpg: 640x384 4 persons, 7.3ms\n",
      "Speed: 2.5ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_180.jpg: 640x384 2 persons, 14.6ms\n",
      "Speed: 3.8ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_210.jpg: 640x384 2 persons, 7.8ms\n",
      "Speed: 3.7ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_240.jpg: 640x384 3 persons, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_270.jpg: 640x384 2 persons, 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_30.jpg: 640x384 3 persons, 1 cell phone, 15.5ms\n",
      "Speed: 3.7ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_300.jpg: 640x384 3 persons, 1 tv, 32.6ms\n",
      "Speed: 4.6ms preprocess, 32.6ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_330.jpg: 640x384 2 persons, 13.8ms\n",
      "Speed: 4.0ms preprocess, 13.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_360.jpg: 640x384 4 persons, 12.7ms\n",
      "Speed: 3.8ms preprocess, 12.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_390.jpg: 640x384 3 persons, 13.4ms\n",
      "Speed: 3.3ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_60.jpg: 640x384 4 persons, 12.8ms\n",
      "Speed: 4.0ms preprocess, 12.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891661008828094/frame_90.jpg: 640x384 6 persons, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-891391212618023\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-891391212618023: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_0.jpg: 640x544 2 cups, 7.5ms\n",
      "Speed: 4.1ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_120.jpg: 640x544 2 persons, 1 wine glass, 1 dining table, 1 book, 7.1ms\n",
      "Speed: 4.3ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_150.jpg: 640x544 2 persons, 1 chair, 1 book, 11.3ms\n",
      "Speed: 5.9ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_180.jpg: 640x544 2 persons, 1 chair, 10.4ms\n",
      "Speed: 6.5ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_210.jpg: 640x544 3 persons, 11.7ms\n",
      "Speed: 6.5ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_240.jpg: 640x544 2 persons, 1 cup, 12.2ms\n",
      "Speed: 6.5ms preprocess, 12.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_270.jpg: 640x544 2 persons, 1 cup, 16.0ms\n",
      "Speed: 5.8ms preprocess, 16.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_30.jpg: 640x544 1 cup, 1 dining table, 14.5ms\n",
      "Speed: 6.7ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_300.jpg: 640x544 1 person, 2 cups, 11.2ms\n",
      "Speed: 5.3ms preprocess, 11.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_330.jpg: 640x544 2 cups, 1 chair, 1 dining table, 10.8ms\n",
      "Speed: 5.5ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_360.jpg: 640x544 1 chair, 1 couch, 1 dining table, 8.9ms\n",
      "Speed: 4.9ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_390.jpg: 640x544 1 cup, 1 chair, 1 couch, 8.4ms\n",
      "Speed: 5.8ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_420.jpg: 640x544 1 cup, 1 dining table, 11.4ms\n",
      "Speed: 6.1ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_60.jpg: 640x544 (no detections), 8.8ms\n",
      "Speed: 4.6ms preprocess, 8.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-891391212618023/frame_90.jpg: 640x544 1 person, 1 scissors, 1 teddy bear, 8.1ms\n",
      "Speed: 4.2ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-890166872024685\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-890166872024685: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.9ms\n",
      "Speed: 2.7ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_120.jpg: 640x384 4 persons, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_150.jpg: 640x384 4 persons, 8.8ms\n",
      "Speed: 3.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_180.jpg: 640x384 2 persons, 9.4ms\n",
      "Speed: 3.1ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_210.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 2.7ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_240.jpg: 640x384 3 persons, 11.0ms\n",
      "Speed: 3.7ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_270.jpg: 640x384 2 persons, 16.8ms\n",
      "Speed: 4.1ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_30.jpg: 640x384 3 persons, 1 cell phone, 11.3ms\n",
      "Speed: 4.1ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_300.jpg: 640x384 3 persons, 1 tv, 9.1ms\n",
      "Speed: 2.8ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_330.jpg: 640x384 2 persons, 8.6ms\n",
      "Speed: 2.8ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_360.jpg: 640x384 4 persons, 9.3ms\n",
      "Speed: 2.4ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_390.jpg: 640x384 3 persons, 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_60.jpg: 640x384 4 persons, 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-890166872024685/frame_90.jpg: 640x384 6 persons, 9.8ms\n",
      "Speed: 3.6ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-889728479746704\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-889728479746704: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_0.jpg: 640x384 1 person, 8.1ms\n",
      "Speed: 3.2ms preprocess, 8.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_120.jpg: 640x384 1 person, 7.8ms\n",
      "Speed: 2.7ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_150.jpg: 640x384 4 persons, 1 cell phone, 7.7ms\n",
      "Speed: 2.7ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_180.jpg: 640x384 2 persons, 9.0ms\n",
      "Speed: 3.4ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_210.jpg: 640x384 3 persons, 1 remote, 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_240.jpg: 640x384 2 persons, 10.9ms\n",
      "Speed: 3.4ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_270.jpg: 640x384 1 person, 1 remote, 24.2ms\n",
      "Speed: 4.4ms preprocess, 24.2ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_30.jpg: 640x384 1 person, 26.7ms\n",
      "Speed: 4.5ms preprocess, 26.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_300.jpg: 640x384 1 person, 1 cell phone, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_330.jpg: 640x384 1 person, 8.9ms\n",
      "Speed: 3.0ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_360.jpg: 640x384 1 person, 2 cell phones, 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_390.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.1ms\n",
      "Speed: 2.8ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_420.jpg: 640x384 1 person, 1 cell phone, 8.3ms\n",
      "Speed: 2.6ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_450.jpg: 640x384 2 persons, 1 laptop, 1 cell phone, 14.8ms\n",
      "Speed: 4.3ms preprocess, 14.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_480.jpg: 640x384 2 persons, 1 laptop, 1 cell phone, 1 book, 20.8ms\n",
      "Speed: 4.8ms preprocess, 20.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_510.jpg: 640x384 2 persons, 1 potted plant, 1 remote, 1 cell phone, 9.5ms\n",
      "Speed: 5.0ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_540.jpg: 640x384 1 person, 1 potted plant, 10.5ms\n",
      "Speed: 3.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_570.jpg: 640x384 1 potted plant, 9.1ms\n",
      "Speed: 3.2ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_60.jpg: 640x384 (no detections), 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_600.jpg: 640x384 (no detections), 8.4ms\n",
      "Speed: 2.6ms preprocess, 8.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_630.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_630.jpg: 640x384 (no detections), 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_660.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_660.jpg: 640x384 (no detections), 18.8ms\n",
      "Speed: 3.3ms preprocess, 18.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_690.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_690.jpg: 640x384 (no detections), 34.7ms\n",
      "Speed: 5.3ms preprocess, 34.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-889728479746704/frame_90.jpg: 640x384 1 person, 16.7ms\n",
      "Speed: 4.6ms preprocess, 16.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-888593019388197\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-888593019388197: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_0.jpg: 640x640 1 banana, 9.7ms\n",
      "Speed: 4.3ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_120.jpg: 640x640 3 persons, 8.1ms\n",
      "Speed: 7.1ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_150.jpg: 640x640 2 persons, 22.0ms\n",
      "Speed: 7.2ms preprocess, 22.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_180.jpg: 640x640 2 persons, 24.3ms\n",
      "Speed: 8.4ms preprocess, 24.3ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_210.jpg: 640x640 1 person, 1 cell phone, 23.9ms\n",
      "Speed: 7.3ms preprocess, 23.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_240.jpg: 640x640 3 persons, 2 cell phones, 8.6ms\n",
      "Speed: 6.1ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_270.jpg: 640x640 1 person, 1 cell phone, 12.5ms\n",
      "Speed: 7.6ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_30.jpg: 640x640 1 person, 1 book, 21.4ms\n",
      "Speed: 5.8ms preprocess, 21.4ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_300.jpg: 640x640 1 person, 1 cell phone, 19.4ms\n",
      "Speed: 7.6ms preprocess, 19.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_330.jpg: 640x640 3 persons, 1 cell phone, 17.5ms\n",
      "Speed: 7.5ms preprocess, 17.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_360.jpg: 640x640 3 persons, 3 cell phones, 10.6ms\n",
      "Speed: 7.4ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_390.jpg: 640x640 2 persons, 1 cell phone, 12.0ms\n",
      "Speed: 5.7ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_420.jpg: 640x640 3 persons, 1 toilet, 14.2ms\n",
      "Speed: 6.9ms preprocess, 14.2ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_450.jpg: 640x640 2 persons, 9.7ms\n",
      "Speed: 5.5ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_480.jpg: 640x640 (no detections), 7.7ms\n",
      "Speed: 4.5ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_510.jpg: 640x640 (no detections), 8.7ms\n",
      "Speed: 4.3ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_60.jpg: 640x640 1 person, 1 book, 9.8ms\n",
      "Speed: 5.5ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-888593019388197/frame_90.jpg: 640x640 2 bananas, 11.4ms\n",
      "Speed: 6.9ms preprocess, 11.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-885689066019680\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-885689066019680: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.5ms\n",
      "Speed: 2.7ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_120.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 2.4ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_150.jpg: 640x384 4 persons, 8.8ms\n",
      "Speed: 2.8ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_180.jpg: 640x384 2 persons, 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_210.jpg: 640x384 2 persons, 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_240.jpg: 640x384 3 persons, 9.3ms\n",
      "Speed: 3.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_270.jpg: 640x384 2 persons, 12.3ms\n",
      "Speed: 2.7ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_30.jpg: 640x384 3 persons, 1 cell phone, 25.4ms\n",
      "Speed: 4.0ms preprocess, 25.4ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_300.jpg: 640x384 3 persons, 1 tv, 9.4ms\n",
      "Speed: 3.1ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_330.jpg: 640x384 2 persons, 14.5ms\n",
      "Speed: 3.5ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_360.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 3.1ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_390.jpg: 640x384 3 persons, 12.8ms\n",
      "Speed: 3.3ms preprocess, 12.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_60.jpg: 640x384 4 persons, 8.7ms\n",
      "Speed: 3.5ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885689066019680/frame_90.jpg: 640x384 6 persons, 9.4ms\n",
      "Speed: 3.6ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-885670366433640\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-885670366433640: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_0.jpg: 640x640 (no detections), 6.8ms\n",
      "Speed: 4.1ms preprocess, 6.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_120.jpg: 640x640 1 person, 1 hot dog, 1 dining table, 7.8ms\n",
      "Speed: 4.1ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_150.jpg: 640x640 (no detections), 7.9ms\n",
      "Speed: 4.9ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_180.jpg: 640x640 1 person, 9.0ms\n",
      "Speed: 4.3ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_210.jpg: 640x640 1 person, 1 fork, 18.5ms\n",
      "Speed: 6.4ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_240.jpg: 640x640 1 remote, 7.9ms\n",
      "Speed: 4.6ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_270.jpg: 640x640 1 person, 9.3ms\n",
      "Speed: 5.1ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_30.jpg: 640x640 1 person, 10.4ms\n",
      "Speed: 7.2ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_300.jpg: 640x640 1 person, 1 bottle, 10.5ms\n",
      "Speed: 5.2ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_330.jpg: 640x640 3 persons, 10.2ms\n",
      "Speed: 5.4ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_360.jpg: 640x640 1 person, 1 remote, 9.8ms\n",
      "Speed: 5.1ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_390.jpg: 640x640 1 person, 1 cell phone, 10.6ms\n",
      "Speed: 7.2ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_420.jpg: 640x640 1 person, 10.3ms\n",
      "Speed: 6.3ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_450.jpg: 640x640 (no detections), 10.0ms\n",
      "Speed: 5.5ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_480.jpg: 640x640 (no detections), 15.0ms\n",
      "Speed: 6.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_510.jpg: 640x640 (no detections), 17.4ms\n",
      "Speed: 6.3ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_540.jpg: 640x640 (no detections), 11.5ms\n",
      "Speed: 5.7ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_570.jpg: 640x640 (no detections), 9.1ms\n",
      "Speed: 5.5ms preprocess, 9.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_60.jpg: 640x640 (no detections), 7.4ms\n",
      "Speed: 4.3ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885670366433640/frame_90.jpg: 640x640 (no detections), 9.6ms\n",
      "Speed: 5.3ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-885209946993560\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-885209946993560: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_0.jpg: 640x640 (no detections), 8.2ms\n",
      "Speed: 6.2ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_120.jpg: 640x640 3 persons, 12.0ms\n",
      "Speed: 6.1ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_150.jpg: 640x640 3 persons, 9.5ms\n",
      "Speed: 6.0ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_180.jpg: 640x640 1 person, 8.5ms\n",
      "Speed: 4.7ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_210.jpg: 640x640 2 persons, 11.1ms\n",
      "Speed: 5.9ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_240.jpg: 640x640 5 persons, 8.7ms\n",
      "Speed: 5.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_270.jpg: 640x640 1 person, 2 cell phones, 12.3ms\n",
      "Speed: 6.5ms preprocess, 12.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_30.jpg: 640x640 1 person, 10.2ms\n",
      "Speed: 5.6ms preprocess, 10.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_300.jpg: 640x640 1 person, 1 cell phone, 24.1ms\n",
      "Speed: 10.0ms preprocess, 24.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_330.jpg: 640x640 10 persons, 1 cell phone, 31.4ms\n",
      "Speed: 8.9ms preprocess, 31.4ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_360.jpg: 640x640 1 person, 1 cell phone, 10.6ms\n",
      "Speed: 7.3ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_390.jpg: 640x640 3 persons, 1 tv, 12.9ms\n",
      "Speed: 7.2ms preprocess, 12.9ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_420.jpg: 640x640 3 persons, 20.4ms\n",
      "Speed: 8.4ms preprocess, 20.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_450.jpg: 640x640 5 persons, 12.5ms\n",
      "Speed: 7.4ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_480.jpg: 640x640 2 persons, 1 cell phone, 12.7ms\n",
      "Speed: 5.6ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_510.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 5.7ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_540.jpg: 640x640 (no detections), 8.2ms\n",
      "Speed: 6.9ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_60.jpg: 640x640 4 persons, 15.9ms\n",
      "Speed: 8.0ms preprocess, 15.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-885209946993560/frame_90.jpg: 640x640 (no detections), 22.7ms\n",
      "Speed: 7.8ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-882993126248062\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-882993126248062: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.5ms\n",
      "Speed: 3.0ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_120.jpg: 640x384 4 persons, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_150.jpg: 640x384 4 persons, 15.7ms\n",
      "Speed: 4.4ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_180.jpg: 640x384 2 persons, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_210.jpg: 640x384 2 persons, 15.8ms\n",
      "Speed: 4.1ms preprocess, 15.8ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_240.jpg: 640x384 3 persons, 20.3ms\n",
      "Speed: 3.8ms preprocess, 20.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_270.jpg: 640x384 2 persons, 14.6ms\n",
      "Speed: 3.5ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_30.jpg: 640x384 3 persons, 1 cell phone, 7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_300.jpg: 640x384 3 persons, 1 tv, 7.6ms\n",
      "Speed: 2.6ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_330.jpg: 640x384 2 persons, 9.0ms\n",
      "Speed: 2.6ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_360.jpg: 640x384 4 persons, 15.9ms\n",
      "Speed: 2.6ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_390.jpg: 640x384 3 persons, 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_60.jpg: 640x384 4 persons, 9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882993126248062/frame_90.jpg: 640x384 6 persons, 14.5ms\n",
      "Speed: 3.4ms preprocess, 14.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-882867522830120\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-882867522830120: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.7ms\n",
      "Speed: 2.4ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_120.jpg: 640x384 4 persons, 8.3ms\n",
      "Speed: 2.7ms preprocess, 8.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_150.jpg: 640x384 4 persons, 9.8ms\n",
      "Speed: 3.5ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_180.jpg: 640x384 2 persons, 8.5ms\n",
      "Speed: 2.8ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_210.jpg: 640x384 2 persons, 16.2ms\n",
      "Speed: 3.6ms preprocess, 16.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_240.jpg: 640x384 3 persons, 13.5ms\n",
      "Speed: 3.3ms preprocess, 13.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_270.jpg: 640x384 2 persons, 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.4ms\n",
      "Speed: 3.0ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_300.jpg: 640x384 3 persons, 1 tv, 13.3ms\n",
      "Speed: 4.1ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_330.jpg: 640x384 2 persons, 8.5ms\n",
      "Speed: 2.9ms preprocess, 8.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_360.jpg: 640x384 4 persons, 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_390.jpg: 640x384 3 persons, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_60.jpg: 640x384 4 persons, 10.3ms\n",
      "Speed: 3.7ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882867522830120/frame_90.jpg: 640x384 6 persons, 22.9ms\n",
      "Speed: 4.0ms preprocess, 22.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-882019143545185\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-882019143545185: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_0.jpg: 640x384 3 persons, 1 sports ball, 1 clock, 8.6ms\n",
      "Speed: 2.8ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_120.jpg: 640x384 1 book, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_150.jpg: 640x384 1 person, 1 book, 1 clock, 11.5ms\n",
      "Speed: 4.3ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_180.jpg: 640x384 3 persons, 1 book, 12.7ms\n",
      "Speed: 3.8ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_210.jpg: 640x384 4 persons, 1 tv, 9.4ms\n",
      "Speed: 2.6ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_240.jpg: 640x384 4 persons, 32.8ms\n",
      "Speed: 5.1ms preprocess, 32.8ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_270.jpg: 640x384 3 persons, 1 train, 1 tv, 29.9ms\n",
      "Speed: 3.8ms preprocess, 29.9ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_30.jpg: 640x384 2 persons, 12.4ms\n",
      "Speed: 4.3ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_300.jpg: 640x384 1 person, 2 potted plants, 1 tv, 1 cell phone, 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_330.jpg: 640x384 2 persons, 13.3ms\n",
      "Speed: 4.4ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_360.jpg: 640x384 2 persons, 1 potted plant, 1 cell phone, 13.6ms\n",
      "Speed: 5.1ms preprocess, 13.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_390.jpg: 640x384 1 person, 1 potted plant, 1 cell phone, 15.3ms\n",
      "Speed: 4.2ms preprocess, 15.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_420.jpg: 640x384 4 persons, 1 train, 1 tv, 19.8ms\n",
      "Speed: 5.1ms preprocess, 19.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_450.jpg: 640x384 (no detections), 13.2ms\n",
      "Speed: 4.2ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_480.jpg: 640x384 (no detections), 22.5ms\n",
      "Speed: 4.1ms preprocess, 22.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_60.jpg: 640x384 1 person, 1 book, 9.5ms\n",
      "Speed: 3.2ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-882019143545185/frame_90.jpg: 640x384 1 person, 2 books, 21.8ms\n",
      "Speed: 5.0ms preprocess, 21.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-881925359723909\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-881925359723909: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_0.jpg: 640x384 2 tennis rackets, 8.8ms\n",
      "Speed: 2.6ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_120.jpg: 640x384 1 tennis racket, 9.3ms\n",
      "Speed: 2.7ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_150.jpg: 640x384 1 chair, 8.4ms\n",
      "Speed: 2.8ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_180.jpg: 640x384 1 chair, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_210.jpg: 640x384 1 tennis racket, 8.5ms\n",
      "Speed: 2.7ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_240.jpg: 640x384 1 tennis racket, 26.3ms\n",
      "Speed: 4.2ms preprocess, 26.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_270.jpg: 640x384 1 tennis racket, 10.9ms\n",
      "Speed: 3.5ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_30.jpg: 640x384 2 tennis rackets, 8.0ms\n",
      "Speed: 3.1ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_300.jpg: 640x384 (no detections), 10.0ms\n",
      "Speed: 3.3ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_330.jpg: 640x384 1 person, 1 tennis racket, 1 cup, 9.3ms\n",
      "Speed: 3.1ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_360.jpg: 640x384 1 person, 1 tennis racket, 1 cup, 13.7ms\n",
      "Speed: 3.0ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_390.jpg: 640x384 (no detections), 7.9ms\n",
      "Speed: 2.9ms preprocess, 7.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_420.jpg: 640x384 (no detections), 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_450.jpg: 640x384 (no detections), 9.7ms\n",
      "Speed: 4.2ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_60.jpg: 640x384 1 tennis racket, 27.3ms\n",
      "Speed: 3.9ms preprocess, 27.3ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881925359723909/frame_90.jpg: 640x384 1 tennis racket, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-881342303358042\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-881342303358042: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_0.jpg: 640x640 9 persons, 1 bench, 1 sports ball, 7.8ms\n",
      "Speed: 4.2ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_120.jpg: 640x640 9 persons, 1 bench, 1 sports ball, 7.7ms\n",
      "Speed: 4.6ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_150.jpg: 640x640 (no detections), 8.3ms\n",
      "Speed: 5.1ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_180.jpg: 640x640 (no detections), 27.7ms\n",
      "Speed: 6.5ms preprocess, 27.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_210.jpg: 640x640 (no detections), 25.0ms\n",
      "Speed: 7.1ms preprocess, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_240.jpg: 640x640 1 traffic light, 11.4ms\n",
      "Speed: 5.7ms preprocess, 11.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_270.jpg: 640x640 (no detections), 15.6ms\n",
      "Speed: 5.9ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_30.jpg: 640x640 9 persons, 1 bench, 1 sports ball, 8.5ms\n",
      "Speed: 4.9ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_300.jpg: 640x640 (no detections), 10.6ms\n",
      "Speed: 5.1ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_330.jpg: 640x640 (no detections), 9.0ms\n",
      "Speed: 5.0ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_360.jpg: 640x640 (no detections), 9.7ms\n",
      "Speed: 5.5ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_390.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 7.5ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_420.jpg: 640x640 1 banana, 1 bed, 1 clock, 15.0ms\n",
      "Speed: 7.8ms preprocess, 15.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_450.jpg: 640x640 1 banana, 1 bed, 1 keyboard, 1 clock, 27.2ms\n",
      "Speed: 7.3ms preprocess, 27.2ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_480.jpg: 640x640 2 chairs, 8.9ms\n",
      "Speed: 6.1ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_510.jpg: 640x640 1 couch, 9.4ms\n",
      "Speed: 5.1ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_540.jpg: 640x640 1 couch, 8.1ms\n",
      "Speed: 4.7ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_570.jpg: 640x640 1 clock, 22.5ms\n",
      "Speed: 5.7ms preprocess, 22.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_60.jpg: 640x640 8 persons, 1 bench, 1 sports ball, 8.1ms\n",
      "Speed: 4.5ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_600.jpg: 640x640 1 bed, 8.0ms\n",
      "Speed: 5.0ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_630.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_630.jpg: 640x640 1 bed, 8.3ms\n",
      "Speed: 4.3ms preprocess, 8.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-881342303358042/frame_90.jpg: 640x640 9 persons, 1 bench, 1 sports ball, 10.1ms\n",
      "Speed: 6.1ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8806609246079208\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8806609246079208: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_120.jpg: 640x384 4 persons, 7.4ms\n",
      "Speed: 2.6ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_150.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 2.5ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_180.jpg: 640x384 2 persons, 8.4ms\n",
      "Speed: 3.0ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_210.jpg: 640x384 2 persons, 7.8ms\n",
      "Speed: 2.5ms preprocess, 7.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_240.jpg: 640x384 3 persons, 12.8ms\n",
      "Speed: 4.0ms preprocess, 12.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_270.jpg: 640x384 2 persons, 13.1ms\n",
      "Speed: 3.6ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_30.jpg: 640x384 3 persons, 1 cell phone, 17.7ms\n",
      "Speed: 3.9ms preprocess, 17.7ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_300.jpg: 640x384 3 persons, 1 tv, 13.9ms\n",
      "Speed: 4.6ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_330.jpg: 640x384 2 persons, 9.0ms\n",
      "Speed: 3.2ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_360.jpg: 640x384 4 persons, 9.4ms\n",
      "Speed: 3.4ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_390.jpg: 640x384 3 persons, 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_60.jpg: 640x384 4 persons, 15.3ms\n",
      "Speed: 4.2ms preprocess, 15.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8806609246079208/frame_90.jpg: 640x384 6 persons, 16.9ms\n",
      "Speed: 5.3ms preprocess, 16.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-880568190186256\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-880568190186256: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_0.jpg: 640x640 (no detections), 8.9ms\n",
      "Speed: 5.4ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_116.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_116.jpg: 640x640 1 dog, 11.3ms\n",
      "Speed: 5.4ms preprocess, 11.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_145.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_145.jpg: 640x640 4 persons, 7.6ms\n",
      "Speed: 4.5ms preprocess, 7.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_174.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_174.jpg: 640x640 3 persons, 23.3ms\n",
      "Speed: 9.1ms preprocess, 23.3ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_203.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_203.jpg: 640x640 4 persons, 8.1ms\n",
      "Speed: 6.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_232.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_232.jpg: 640x640 1 person, 1 bus, 1 cell phone, 1 book, 8.0ms\n",
      "Speed: 5.0ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_261.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_261.jpg: 640x640 1 person, 1 cell phone, 1 clock, 8.1ms\n",
      "Speed: 4.5ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_29.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_29.jpg: 640x640 1 tv, 1 microwave, 23.1ms\n",
      "Speed: 5.7ms preprocess, 23.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_290.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_290.jpg: 640x640 1 tv, 1 cell phone, 29.2ms\n",
      "Speed: 7.6ms preprocess, 29.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_319.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_319.jpg: 640x640 2 persons, 1 tv, 2 cell phones, 1 clock, 21.3ms\n",
      "Speed: 7.5ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_348.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_348.jpg: 640x640 2 persons, 1 cell phone, 1 clock, 10.0ms\n",
      "Speed: 5.8ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_377.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_377.jpg: 640x640 3 persons, 11.1ms\n",
      "Speed: 6.0ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_406.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_406.jpg: 640x640 1 person, 8.8ms\n",
      "Speed: 4.8ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_435.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_435.jpg: 640x640 1 person, 16.2ms\n",
      "Speed: 5.2ms preprocess, 16.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_464.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_464.jpg: 640x640 1 person, 11.1ms\n",
      "Speed: 5.3ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_493.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_493.jpg: 640x640 1 person, 24.9ms\n",
      "Speed: 7.3ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_522.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_522.jpg: 640x640 (no detections), 16.9ms\n",
      "Speed: 7.7ms preprocess, 16.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_551.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_551.jpg: 640x640 (no detections), 8.8ms\n",
      "Speed: 6.2ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_58.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_58.jpg: 640x640 1 person, 1 tv, 8.4ms\n",
      "Speed: 5.1ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_87.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880568190186256/frame_87.jpg: 640x640 (no detections), 20.5ms\n",
      "Speed: 6.2ms preprocess, 20.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-880340126836307\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-880340126836307: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_0.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_120.jpg: 640x384 3 persons, 1 book, 8.1ms\n",
      "Speed: 2.6ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_150.jpg: 640x384 2 persons, 2 books, 8.6ms\n",
      "Speed: 2.9ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_180.jpg: 640x384 4 persons, 13.0ms\n",
      "Speed: 3.2ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_210.jpg: 640x384 1 person, 8.4ms\n",
      "Speed: 3.7ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_240.jpg: 640x384 1 person, 8.8ms\n",
      "Speed: 2.9ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_270.jpg: 640x384 3 persons, 26.9ms\n",
      "Speed: 4.0ms preprocess, 26.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_30.jpg: 640x384 2 persons, 2 cell phones, 8.9ms\n",
      "Speed: 4.1ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_300.jpg: 640x384 3 persons, 10.9ms\n",
      "Speed: 3.6ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_330.jpg: 640x384 1 person, 1 book, 12.0ms\n",
      "Speed: 3.8ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_360.jpg: 640x384 1 person, 1 book, 8.2ms\n",
      "Speed: 2.6ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_390.jpg: 640x384 3 persons, 1 book, 9.5ms\n",
      "Speed: 2.9ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_420.jpg: 640x384 2 persons, 1 book, 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_450.jpg: 640x384 2 persons, 8.8ms\n",
      "Speed: 2.7ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_480.jpg: 640x384 1 person, 9.4ms\n",
      "Speed: 2.7ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_510.jpg: 640x384 (no detections), 20.5ms\n",
      "Speed: 3.8ms preprocess, 20.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_540.jpg: 640x384 1 kite, 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_60.jpg: 640x384 1 person, 1 book, 9.3ms\n",
      "Speed: 3.0ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-880340126836307/frame_90.jpg: 640x384 6 persons, 18.0ms\n",
      "Speed: 4.3ms preprocess, 18.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8796411607036992\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8796411607036992: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_0.jpg: 640x384 1 dog, 1 chair, 7.2ms\n",
      "Speed: 2.4ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_120.jpg: 640x384 1 person, 1 chair, 2 clocks, 7.4ms\n",
      "Speed: 2.2ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_150.jpg: 640x384 1 person, 1 chair, 1 clock, 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_180.jpg: 640x384 1 person, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_210.jpg: 640x384 3 persons, 1 chair, 10.0ms\n",
      "Speed: 3.3ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_240.jpg: 640x384 1 person, 1 chair, 1 clock, 1 teddy bear, 29.1ms\n",
      "Speed: 4.9ms preprocess, 29.1ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_270.jpg: 640x384 1 person, 1 dog, 1 teddy bear, 21.7ms\n",
      "Speed: 4.2ms preprocess, 21.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_30.jpg: 640x384 1 dog, 1 chair, 11.5ms\n",
      "Speed: 4.1ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_300.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 2.8ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_330.jpg: 640x384 (no detections), 9.3ms\n",
      "Speed: 2.7ms preprocess, 9.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_60.jpg: 640x384 2 persons, 1 chair, 7.6ms\n",
      "Speed: 3.0ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8796411607036992/frame_90.jpg: 640x384 3 persons, 1 bench, 2 clocks, 8.9ms\n",
      "Speed: 2.6ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-879631723735807\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-879631723735807: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_0.jpg: 640x384 1 person, 1 clock, 7.8ms\n",
      "Speed: 2.3ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_120.jpg: 640x384 2 persons, 8.6ms\n",
      "Speed: 2.7ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_150.jpg: 640x384 2 persons, 16.7ms\n",
      "Speed: 3.0ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_180.jpg: 640x384 1 person, 1 cell phone, 7.4ms\n",
      "Speed: 2.8ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_210.jpg: 640x384 1 person, 1 cell phone, 8.2ms\n",
      "Speed: 2.7ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_240.jpg: 640x384 1 person, 1 cell phone, 23.5ms\n",
      "Speed: 3.6ms preprocess, 23.5ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_270.jpg: 640x384 4 persons, 1 cell phone, 27.3ms\n",
      "Speed: 4.2ms preprocess, 27.3ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_30.jpg: 640x384 1 person, 25.7ms\n",
      "Speed: 4.7ms preprocess, 25.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_300.jpg: 640x384 1 person, 1 cell phone, 10.6ms\n",
      "Speed: 4.1ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_330.jpg: 640x384 1 person, 1 toilet, 22.3ms\n",
      "Speed: 4.1ms preprocess, 22.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_360.jpg: 640x384 1 person, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_390.jpg: 640x384 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_420.jpg: 640x384 (no detections), 7.8ms\n",
      "Speed: 2.5ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_450.jpg: 640x384 (no detections), 22.1ms\n",
      "Speed: 2.9ms preprocess, 22.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_480.jpg: 640x384 (no detections), 28.5ms\n",
      "Speed: 4.6ms preprocess, 28.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_60.jpg: 640x384 1 person, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879631723735807/frame_90.jpg: 640x384 1 toilet, 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-879049300656635\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-879049300656635: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_0.jpg: 640x544 2 cups, 10.9ms\n",
      "Speed: 6.7ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_120.jpg: 640x544 2 persons, 1 wine glass, 1 dining table, 1 book, 6.8ms\n",
      "Speed: 3.7ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_150.jpg: 640x544 2 persons, 1 chair, 1 book, 7.4ms\n",
      "Speed: 3.9ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_180.jpg: 640x544 2 persons, 1 chair, 17.0ms\n",
      "Speed: 5.5ms preprocess, 17.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_210.jpg: 640x544 3 persons, 8.8ms\n",
      "Speed: 4.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_240.jpg: 640x544 2 persons, 1 cup, 8.4ms\n",
      "Speed: 5.2ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_270.jpg: 640x544 2 persons, 1 cup, 8.9ms\n",
      "Speed: 5.0ms preprocess, 8.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_30.jpg: 640x544 1 cup, 1 dining table, 15.1ms\n",
      "Speed: 7.4ms preprocess, 15.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_300.jpg: 640x544 1 person, 2 cups, 25.5ms\n",
      "Speed: 5.7ms preprocess, 25.5ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_330.jpg: 640x544 2 cups, 1 chair, 1 dining table, 14.4ms\n",
      "Speed: 6.3ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_360.jpg: 640x544 1 chair, 1 couch, 1 dining table, 8.0ms\n",
      "Speed: 4.3ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_390.jpg: 640x544 1 cup, 1 chair, 1 couch, 9.9ms\n",
      "Speed: 4.5ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_420.jpg: 640x544 1 cup, 1 dining table, 7.6ms\n",
      "Speed: 4.0ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_60.jpg: 640x544 (no detections), 8.5ms\n",
      "Speed: 4.0ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-879049300656635/frame_90.jpg: 640x544 1 person, 1 scissors, 1 teddy bear, 7.8ms\n",
      "Speed: 4.6ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877975993416760\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877975993416760: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_120.jpg: 640x384 4 persons, 12.4ms\n",
      "Speed: 4.1ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_150.jpg: 640x384 4 persons, 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_180.jpg: 640x384 2 persons, 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_210.jpg: 640x384 2 persons, 7.9ms\n",
      "Speed: 2.7ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_240.jpg: 640x384 3 persons, 23.3ms\n",
      "Speed: 3.7ms preprocess, 23.3ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_270.jpg: 640x384 2 persons, 30.4ms\n",
      "Speed: 4.8ms preprocess, 30.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_30.jpg: 640x384 3 persons, 1 cell phone, 23.0ms\n",
      "Speed: 3.9ms preprocess, 23.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_300.jpg: 640x384 3 persons, 1 tv, 20.8ms\n",
      "Speed: 4.1ms preprocess, 20.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_330.jpg: 640x384 2 persons, 9.1ms\n",
      "Speed: 2.6ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_360.jpg: 640x384 4 persons, 8.1ms\n",
      "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_390.jpg: 640x384 3 persons, 8.5ms\n",
      "Speed: 3.0ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_60.jpg: 640x384 4 persons, 19.5ms\n",
      "Speed: 2.6ms preprocess, 19.5ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877975993416760/frame_90.jpg: 640x384 6 persons, 15.4ms\n",
      "Speed: 4.4ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877662697022279\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877662697022279: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.7ms\n",
      "Speed: 2.7ms preprocess, 8.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_120.jpg: 640x384 4 persons, 8.2ms\n",
      "Speed: 2.9ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_150.jpg: 640x384 4 persons, 12.4ms\n",
      "Speed: 3.9ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_180.jpg: 640x384 2 persons, 9.2ms\n",
      "Speed: 2.8ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_210.jpg: 640x384 2 persons, 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_240.jpg: 640x384 3 persons, 27.9ms\n",
      "Speed: 5.2ms preprocess, 27.9ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_270.jpg: 640x384 2 persons, 15.9ms\n",
      "Speed: 4.0ms preprocess, 15.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_30.jpg: 640x384 3 persons, 1 cell phone, 13.1ms\n",
      "Speed: 4.3ms preprocess, 13.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_300.jpg: 640x384 3 persons, 1 tv, 12.4ms\n",
      "Speed: 4.1ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_330.jpg: 640x384 2 persons, 10.3ms\n",
      "Speed: 3.4ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_360.jpg: 640x384 4 persons, 26.5ms\n",
      "Speed: 4.8ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_390.jpg: 640x384 3 persons, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_60.jpg: 640x384 4 persons, 31.4ms\n",
      "Speed: 4.0ms preprocess, 31.4ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877662697022279/frame_90.jpg: 640x384 6 persons, 11.9ms\n",
      "Speed: 3.7ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877511836784655\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877511836784655: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.7ms\n",
      "Speed: 2.7ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_120.jpg: 640x384 4 persons, 7.6ms\n",
      "Speed: 2.6ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_150.jpg: 640x384 4 persons, 9.0ms\n",
      "Speed: 3.2ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_180.jpg: 640x384 2 persons, 9.6ms\n",
      "Speed: 3.3ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_210.jpg: 640x384 2 persons, 10.2ms\n",
      "Speed: 3.4ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_240.jpg: 640x384 3 persons, 11.2ms\n",
      "Speed: 3.5ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_270.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 3.0ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_30.jpg: 640x384 3 persons, 1 cell phone, 12.9ms\n",
      "Speed: 2.9ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_300.jpg: 640x384 3 persons, 1 tv, 7.6ms\n",
      "Speed: 3.0ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_330.jpg: 640x384 2 persons, 9.5ms\n",
      "Speed: 3.4ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_360.jpg: 640x384 4 persons, 25.6ms\n",
      "Speed: 3.1ms preprocess, 25.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_390.jpg: 640x384 3 persons, 18.2ms\n",
      "Speed: 2.9ms preprocess, 18.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_60.jpg: 640x384 4 persons, 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877511836784655/frame_90.jpg: 640x384 6 persons, 29.0ms\n",
      "Speed: 5.0ms preprocess, 29.0ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877210454387561\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877210454387561: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_0.jpg: 640x384 (no detections), 7.6ms\n",
      "Speed: 2.1ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_120.jpg: 640x384 3 persons, 8.5ms\n",
      "Speed: 3.1ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_150.jpg: 640x384 4 persons, 1 book, 12.0ms\n",
      "Speed: 3.8ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_180.jpg: 640x384 4 persons, 17.6ms\n",
      "Speed: 3.0ms preprocess, 17.6ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_210.jpg: 640x384 3 persons, 24.8ms\n",
      "Speed: 3.9ms preprocess, 24.8ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_240.jpg: 640x384 2 persons, 13.0ms\n",
      "Speed: 3.3ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_270.jpg: 640x384 4 persons, 12.6ms\n",
      "Speed: 4.3ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_30.jpg: 640x384 (no detections), 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_300.jpg: 640x384 4 persons, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_330.jpg: 640x384 3 persons, 13.5ms\n",
      "Speed: 4.0ms preprocess, 13.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_360.jpg: 640x384 1 person, 30.1ms\n",
      "Speed: 4.4ms preprocess, 30.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_390.jpg: 640x384 3 persons, 21.7ms\n",
      "Speed: 3.9ms preprocess, 21.7ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_420.jpg: 640x384 2 persons, 8.6ms\n",
      "Speed: 2.9ms preprocess, 8.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_450.jpg: 640x384 3 persons, 8.6ms\n",
      "Speed: 3.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_480.jpg: 640x384 3 persons, 1 cell phone, 12.2ms\n",
      "Speed: 3.8ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_510.jpg: 640x384 (no detections), 8.6ms\n",
      "Speed: 3.5ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_540.jpg: 640x384 1 kite, 7.8ms\n",
      "Speed: 3.3ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_60.jpg: 640x384 (no detections), 19.4ms\n",
      "Speed: 5.2ms preprocess, 19.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877210454387561/frame_90.jpg: 640x384 (no detections), 17.2ms\n",
      "Speed: 3.8ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877129693575192\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-877129693575192: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_120.jpg: 640x384 4 persons, 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_150.jpg: 640x384 4 persons, 12.2ms\n",
      "Speed: 3.4ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_180.jpg: 640x384 2 persons, 13.8ms\n",
      "Speed: 2.8ms preprocess, 13.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_210.jpg: 640x384 2 persons, 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_240.jpg: 640x384 3 persons, 14.5ms\n",
      "Speed: 3.6ms preprocess, 14.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_270.jpg: 640x384 2 persons, 29.5ms\n",
      "Speed: 4.9ms preprocess, 29.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.5ms\n",
      "Speed: 4.0ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_300.jpg: 640x384 3 persons, 1 tv, 17.1ms\n",
      "Speed: 4.4ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_330.jpg: 640x384 2 persons, 11.2ms\n",
      "Speed: 3.6ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_360.jpg: 640x384 4 persons, 11.8ms\n",
      "Speed: 3.9ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_390.jpg: 640x384 3 persons, 13.7ms\n",
      "Speed: 4.3ms preprocess, 13.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_60.jpg: 640x384 4 persons, 13.7ms\n",
      "Speed: 4.4ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-877129693575192/frame_90.jpg: 640x384 6 persons, 13.8ms\n",
      "Speed: 4.1ms preprocess, 13.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-875485623676104\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-875485623676104: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_120.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 3.0ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_150.jpg: 640x384 4 persons, 12.2ms\n",
      "Speed: 3.3ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_180.jpg: 640x384 2 persons, 9.0ms\n",
      "Speed: 2.8ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_210.jpg: 640x384 2 persons, 8.9ms\n",
      "Speed: 2.5ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_240.jpg: 640x384 3 persons, 7.6ms\n",
      "Speed: 2.4ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_270.jpg: 640x384 2 persons, 10.0ms\n",
      "Speed: 3.7ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_30.jpg: 640x384 3 persons, 1 cell phone, 29.6ms\n",
      "Speed: 4.3ms preprocess, 29.6ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_300.jpg: 640x384 3 persons, 1 tv, 14.2ms\n",
      "Speed: 3.9ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_330.jpg: 640x384 2 persons, 11.3ms\n",
      "Speed: 3.2ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_360.jpg: 640x384 4 persons, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_390.jpg: 640x384 3 persons, 14.9ms\n",
      "Speed: 4.3ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_60.jpg: 640x384 4 persons, 27.7ms\n",
      "Speed: 4.3ms preprocess, 27.7ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-875485623676104/frame_90.jpg: 640x384 6 persons, 16.8ms\n",
      "Speed: 2.7ms preprocess, 16.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874747697073121\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874747697073121: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.7ms\n",
      "Speed: 3.1ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_120.jpg: 640x384 4 persons, 10.9ms\n",
      "Speed: 3.5ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_150.jpg: 640x384 4 persons, 11.1ms\n",
      "Speed: 3.7ms preprocess, 11.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_180.jpg: 640x384 2 persons, 9.3ms\n",
      "Speed: 3.4ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_210.jpg: 640x384 2 persons, 12.3ms\n",
      "Speed: 3.3ms preprocess, 12.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_240.jpg: 640x384 3 persons, 29.2ms\n",
      "Speed: 4.0ms preprocess, 29.2ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_270.jpg: 640x384 2 persons, 11.9ms\n",
      "Speed: 3.9ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_30.jpg: 640x384 3 persons, 1 cell phone, 18.1ms\n",
      "Speed: 2.9ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_300.jpg: 640x384 3 persons, 1 tv, 8.8ms\n",
      "Speed: 2.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_330.jpg: 640x384 2 persons, 9.4ms\n",
      "Speed: 2.8ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_360.jpg: 640x384 4 persons, 7.9ms\n",
      "Speed: 2.8ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_390.jpg: 640x384 3 persons, 10.0ms\n",
      "Speed: 3.4ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_60.jpg: 640x384 4 persons, 21.5ms\n",
      "Speed: 2.9ms preprocess, 21.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874747697073121/frame_90.jpg: 640x384 6 persons, 27.0ms\n",
      "Speed: 4.9ms preprocess, 27.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874543520932484\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874543520932484: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_0.jpg: 640x640 9 persons, 1 bench, 1 sports ball, 6.9ms\n",
      "Speed: 5.3ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_120.jpg: 640x640 9 persons, 1 bench, 1 sports ball, 7.3ms\n",
      "Speed: 5.7ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_150.jpg: 640x640 (no detections), 8.9ms\n",
      "Speed: 4.4ms preprocess, 8.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_180.jpg: 640x640 (no detections), 8.1ms\n",
      "Speed: 4.8ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_210.jpg: 640x640 (no detections), 8.6ms\n",
      "Speed: 4.8ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_240.jpg: 640x640 1 traffic light, 19.3ms\n",
      "Speed: 6.3ms preprocess, 19.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_270.jpg: 640x640 (no detections), 31.1ms\n",
      "Speed: 7.5ms preprocess, 31.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_30.jpg: 640x640 9 persons, 1 bench, 1 sports ball, 28.2ms\n",
      "Speed: 7.9ms preprocess, 28.2ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_300.jpg: 640x640 (no detections), 23.9ms\n",
      "Speed: 8.7ms preprocess, 23.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_330.jpg: 640x640 (no detections), 13.3ms\n",
      "Speed: 7.3ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_360.jpg: 640x640 (no detections), 13.1ms\n",
      "Speed: 7.6ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_390.jpg: 640x640 (no detections), 13.3ms\n",
      "Speed: 7.0ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_420.jpg: 640x640 1 banana, 1 bed, 1 clock, 11.2ms\n",
      "Speed: 5.1ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_450.jpg: 640x640 1 banana, 1 bed, 1 keyboard, 1 clock, 10.6ms\n",
      "Speed: 6.2ms preprocess, 10.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_480.jpg: 640x640 2 chairs, 30.5ms\n",
      "Speed: 8.2ms preprocess, 30.5ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_510.jpg: 640x640 1 couch, 29.2ms\n",
      "Speed: 8.5ms preprocess, 29.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_540.jpg: 640x640 1 couch, 15.9ms\n",
      "Speed: 6.9ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_570.jpg: 640x640 1 clock, 10.6ms\n",
      "Speed: 5.3ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_60.jpg: 640x640 8 persons, 1 bench, 1 sports ball, 8.2ms\n",
      "Speed: 4.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_600.jpg: 640x640 1 bed, 11.0ms\n",
      "Speed: 5.3ms preprocess, 11.0ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_630.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_630.jpg: 640x640 1 bed, 13.1ms\n",
      "Speed: 4.8ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874543520932484/frame_90.jpg: 640x640 9 persons, 1 bench, 1 sports ball, 14.6ms\n",
      "Speed: 6.7ms preprocess, 14.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874190910572544\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874190910572544: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_0.jpg: 640x384 1 person, 1 potted plant, 7.6ms\n",
      "Speed: 2.9ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_120.jpg: 640x384 2 persons, 7.3ms\n",
      "Speed: 2.6ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_150.jpg: 640x384 3 persons, 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_180.jpg: 640x384 1 person, 1 potted plant, 1 book, 7.7ms\n",
      "Speed: 2.9ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_210.jpg: 640x384 1 person, 2 potted plants, 1 book, 1 vase, 29.0ms\n",
      "Speed: 4.0ms preprocess, 29.0ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_240.jpg: 640x384 2 potted plants, 1 book, 1 vase, 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_270.jpg: 640x384 1 book, 22.5ms\n",
      "Speed: 4.0ms preprocess, 22.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_30.jpg: 640x384 3 persons, 1 cup, 1 potted plant, 1 book, 9.0ms\n",
      "Speed: 3.3ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_300.jpg: 640x384 1 book, 8.6ms\n",
      "Speed: 3.6ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_330.jpg: 640x384 1 suitcase, 13.5ms\n",
      "Speed: 2.8ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_360.jpg: 640x384 1 bowl, 1 dining table, 18.9ms\n",
      "Speed: 3.2ms preprocess, 18.9ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_390.jpg: 640x384 1 book, 12.4ms\n",
      "Speed: 4.2ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_420.jpg: 640x384 (no detections), 9.3ms\n",
      "Speed: 3.0ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_450.jpg: 640x384 (no detections), 8.9ms\n",
      "Speed: 3.1ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_480.jpg: 640x384 (no detections), 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_60.jpg: 640x384 1 person, 1 potted plant, 12.3ms\n",
      "Speed: 3.9ms preprocess, 12.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874190910572544/frame_90.jpg: 640x384 1 person, 10.5ms\n",
      "Speed: 3.9ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874084244131796\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-874084244131796: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_0.jpg: 640x384 2 persons, 9.2ms\n",
      "Speed: 3.1ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_120.jpg: 640x384 3 persons, 1 book, 7.3ms\n",
      "Speed: 2.1ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_150.jpg: 640x384 2 persons, 2 books, 13.9ms\n",
      "Speed: 3.2ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_180.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 3.0ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_210.jpg: 640x384 1 person, 8.7ms\n",
      "Speed: 3.0ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_240.jpg: 640x384 1 person, 21.2ms\n",
      "Speed: 3.5ms preprocess, 21.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_270.jpg: 640x384 3 persons, 8.5ms\n",
      "Speed: 3.2ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_30.jpg: 640x384 2 persons, 2 cell phones, 27.5ms\n",
      "Speed: 3.6ms preprocess, 27.5ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_300.jpg: 640x384 3 persons, 15.4ms\n",
      "Speed: 3.7ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_330.jpg: 640x384 1 person, 1 book, 22.9ms\n",
      "Speed: 4.0ms preprocess, 22.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_360.jpg: 640x384 1 person, 1 book, 8.8ms\n",
      "Speed: 2.9ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_390.jpg: 640x384 3 persons, 1 book, 11.7ms\n",
      "Speed: 3.0ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_420.jpg: 640x384 2 persons, 1 book, 11.0ms\n",
      "Speed: 3.9ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_450.jpg: 640x384 2 persons, 26.8ms\n",
      "Speed: 3.6ms preprocess, 26.8ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_480.jpg: 640x384 1 person, 10.8ms\n",
      "Speed: 3.5ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_510.jpg: 640x384 (no detections), 12.0ms\n",
      "Speed: 4.2ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_540.jpg: 640x384 1 kite, 21.4ms\n",
      "Speed: 3.5ms preprocess, 21.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_60.jpg: 640x384 1 person, 1 book, 7.6ms\n",
      "Speed: 2.6ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-874084244131796/frame_90.jpg: 640x384 6 persons, 8.5ms\n",
      "Speed: 3.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-873560550525047\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-873560550525047: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 12.4ms\n",
      "Speed: 2.7ms preprocess, 12.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_120.jpg: 640x384 4 persons, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_150.jpg: 640x384 4 persons, 10.0ms\n",
      "Speed: 3.4ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_180.jpg: 640x384 2 persons, 8.1ms\n",
      "Speed: 3.0ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_210.jpg: 640x384 2 persons, 9.3ms\n",
      "Speed: 2.8ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_240.jpg: 640x384 3 persons, 8.8ms\n",
      "Speed: 2.7ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_270.jpg: 640x384 2 persons, 11.2ms\n",
      "Speed: 3.3ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_30.jpg: 640x384 3 persons, 1 cell phone, 13.2ms\n",
      "Speed: 3.9ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_300.jpg: 640x384 3 persons, 1 tv, 13.5ms\n",
      "Speed: 3.9ms preprocess, 13.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_330.jpg: 640x384 2 persons, 12.5ms\n",
      "Speed: 3.2ms preprocess, 12.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_360.jpg: 640x384 4 persons, 12.8ms\n",
      "Speed: 3.4ms preprocess, 12.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_390.jpg: 640x384 3 persons, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_60.jpg: 640x384 4 persons, 12.5ms\n",
      "Speed: 4.1ms preprocess, 12.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873560550525047/frame_90.jpg: 640x384 6 persons, 9.4ms\n",
      "Speed: 2.5ms preprocess, 9.4ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-873043573965895\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-873043573965895: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 18.7ms\n",
      "Speed: 2.7ms preprocess, 18.7ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_120.jpg: 640x384 4 persons, 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_150.jpg: 640x384 4 persons, 12.6ms\n",
      "Speed: 5.1ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_180.jpg: 640x384 2 persons, 13.8ms\n",
      "Speed: 4.2ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_210.jpg: 640x384 2 persons, 9.2ms\n",
      "Speed: 2.9ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_240.jpg: 640x384 3 persons, 9.1ms\n",
      "Speed: 3.3ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_270.jpg: 640x384 2 persons, 9.1ms\n",
      "Speed: 3.0ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_30.jpg: 640x384 3 persons, 1 cell phone, 28.8ms\n",
      "Speed: 4.1ms preprocess, 28.8ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_300.jpg: 640x384 3 persons, 1 tv, 8.9ms\n",
      "Speed: 3.3ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_330.jpg: 640x384 2 persons, 9.1ms\n",
      "Speed: 3.1ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_360.jpg: 640x384 4 persons, 21.7ms\n",
      "Speed: 4.2ms preprocess, 21.7ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_390.jpg: 640x384 3 persons, 24.8ms\n",
      "Speed: 5.0ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_60.jpg: 640x384 4 persons, 14.9ms\n",
      "Speed: 3.9ms preprocess, 14.9ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-873043573965895/frame_90.jpg: 640x384 6 persons, 13.0ms\n",
      "Speed: 3.9ms preprocess, 13.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-872760463806517\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-872760463806517: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 24.8ms\n",
      "Speed: 4.4ms preprocess, 24.8ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_120.jpg: 640x384 4 persons, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_150.jpg: 640x384 4 persons, 13.7ms\n",
      "Speed: 4.3ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_180.jpg: 640x384 2 persons, 12.3ms\n",
      "Speed: 3.9ms preprocess, 12.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_210.jpg: 640x384 2 persons, 33.0ms\n",
      "Speed: 3.6ms preprocess, 33.0ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_240.jpg: 640x384 3 persons, 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_270.jpg: 640x384 2 persons, 21.4ms\n",
      "Speed: 4.1ms preprocess, 21.4ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_30.jpg: 640x384 3 persons, 1 cell phone, 9.6ms\n",
      "Speed: 3.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_300.jpg: 640x384 3 persons, 1 tv, 10.2ms\n",
      "Speed: 3.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_330.jpg: 640x384 2 persons, 9.4ms\n",
      "Speed: 3.3ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_360.jpg: 640x384 4 persons, 8.2ms\n",
      "Speed: 2.6ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_390.jpg: 640x384 3 persons, 14.5ms\n",
      "Speed: 4.0ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_60.jpg: 640x384 4 persons, 33.1ms\n",
      "Speed: 4.8ms preprocess, 33.1ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872760463806517/frame_90.jpg: 640x384 6 persons, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-872400620956045\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-872400620956045: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_120.jpg: 640x384 4 persons, 8.7ms\n",
      "Speed: 3.1ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_150.jpg: 640x384 4 persons, 8.1ms\n",
      "Speed: 2.5ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_180.jpg: 640x384 2 persons, 8.0ms\n",
      "Speed: 3.3ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_210.jpg: 640x384 2 persons, 28.6ms\n",
      "Speed: 4.4ms preprocess, 28.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_240.jpg: 640x384 3 persons, 12.4ms\n",
      "Speed: 3.7ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_270.jpg: 640x384 2 persons, 18.7ms\n",
      "Speed: 3.7ms preprocess, 18.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_300.jpg: 640x384 3 persons, 1 tv, 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_330.jpg: 640x384 2 persons, 8.6ms\n",
      "Speed: 3.1ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_360.jpg: 640x384 4 persons, 11.1ms\n",
      "Speed: 3.4ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_390.jpg: 640x384 3 persons, 28.7ms\n",
      "Speed: 3.5ms preprocess, 28.7ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_60.jpg: 640x384 4 persons, 12.7ms\n",
      "Speed: 4.6ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872400620956045/frame_90.jpg: 640x384 6 persons, 10.1ms\n",
      "Speed: 3.6ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-872222594086011\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-872222594086011: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 11.8ms\n",
      "Speed: 3.3ms preprocess, 11.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_120.jpg: 640x384 4 persons, 8.7ms\n",
      "Speed: 3.1ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_150.jpg: 640x384 4 persons, 8.7ms\n",
      "Speed: 3.2ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_180.jpg: 640x384 2 persons, 16.8ms\n",
      "Speed: 3.0ms preprocess, 16.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_210.jpg: 640x384 2 persons, 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_240.jpg: 640x384 3 persons, 19.0ms\n",
      "Speed: 3.8ms preprocess, 19.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_270.jpg: 640x384 2 persons, 22.8ms\n",
      "Speed: 4.2ms preprocess, 22.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_30.jpg: 640x384 3 persons, 1 cell phone, 12.4ms\n",
      "Speed: 4.6ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_300.jpg: 640x384 3 persons, 1 tv, 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_330.jpg: 640x384 2 persons, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_360.jpg: 640x384 4 persons, 17.9ms\n",
      "Speed: 4.3ms preprocess, 17.9ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_390.jpg: 640x384 3 persons, 30.1ms\n",
      "Speed: 4.6ms preprocess, 30.1ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_60.jpg: 640x384 4 persons, 9.9ms\n",
      "Speed: 3.9ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-872222594086011/frame_90.jpg: 640x384 6 persons, 9.7ms\n",
      "Speed: 3.4ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8715627171842855\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8715627171842855: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_120.jpg: 640x384 4 persons, 8.8ms\n",
      "Speed: 3.1ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_150.jpg: 640x384 4 persons, 15.9ms\n",
      "Speed: 4.2ms preprocess, 15.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_180.jpg: 640x384 2 persons, 11.2ms\n",
      "Speed: 3.2ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_210.jpg: 640x384 2 persons, 11.7ms\n",
      "Speed: 3.9ms preprocess, 11.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_240.jpg: 640x384 3 persons, 22.0ms\n",
      "Speed: 3.8ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_270.jpg: 640x384 2 persons, 12.3ms\n",
      "Speed: 3.1ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_30.jpg: 640x384 3 persons, 1 cell phone, 8.3ms\n",
      "Speed: 2.9ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_300.jpg: 640x384 3 persons, 1 tv, 8.1ms\n",
      "Speed: 2.7ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_330.jpg: 640x384 2 persons, 20.8ms\n",
      "Speed: 2.6ms preprocess, 20.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_360.jpg: 640x384 4 persons, 11.0ms\n",
      "Speed: 4.3ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_390.jpg: 640x384 3 persons, 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_60.jpg: 640x384 4 persons, 13.5ms\n",
      "Speed: 3.9ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8715627171842855/frame_90.jpg: 640x384 6 persons, 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-871286287458461\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-871286287458461: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.6ms\n",
      "Speed: 3.0ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_120.jpg: 640x384 4 persons, 11.5ms\n",
      "Speed: 3.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_150.jpg: 640x384 4 persons, 8.5ms\n",
      "Speed: 2.6ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_180.jpg: 640x384 2 persons, 10.2ms\n",
      "Speed: 3.2ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_210.jpg: 640x384 2 persons, 25.0ms\n",
      "Speed: 3.5ms preprocess, 25.0ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_240.jpg: 640x384 3 persons, 10.0ms\n",
      "Speed: 3.7ms preprocess, 10.0ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_270.jpg: 640x384 2 persons, 29.0ms\n",
      "Speed: 4.7ms preprocess, 29.0ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_30.jpg: 640x384 3 persons, 1 cell phone, 21.0ms\n",
      "Speed: 3.9ms preprocess, 21.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_300.jpg: 640x384 3 persons, 1 tv, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_330.jpg: 640x384 2 persons, 9.3ms\n",
      "Speed: 3.6ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_360.jpg: 640x384 4 persons, 8.8ms\n",
      "Speed: 3.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_390.jpg: 640x384 3 persons, 31.2ms\n",
      "Speed: 3.6ms preprocess, 31.2ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_60.jpg: 640x384 4 persons, 13.0ms\n",
      "Speed: 4.1ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871286287458461/frame_90.jpg: 640x384 6 persons, 17.4ms\n",
      "Speed: 3.9ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-871185627435460\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-871185627435460: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.8ms\n",
      "Speed: 3.1ms preprocess, 7.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_120.jpg: 640x384 4 persons, 27.4ms\n",
      "Speed: 4.6ms preprocess, 27.4ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_150.jpg: 640x384 4 persons, 14.7ms\n",
      "Speed: 3.9ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_180.jpg: 640x384 2 persons, 14.1ms\n",
      "Speed: 4.2ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_210.jpg: 640x384 2 persons, 9.6ms\n",
      "Speed: 3.7ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_240.jpg: 640x384 3 persons, 9.3ms\n",
      "Speed: 3.2ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_270.jpg: 640x384 2 persons, 8.4ms\n",
      "Speed: 2.6ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_30.jpg: 640x384 3 persons, 1 cell phone, 13.8ms\n",
      "Speed: 5.3ms preprocess, 13.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_300.jpg: 640x384 3 persons, 1 tv, 11.7ms\n",
      "Speed: 3.9ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_330.jpg: 640x384 2 persons, 11.1ms\n",
      "Speed: 3.7ms preprocess, 11.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_360.jpg: 640x384 4 persons, 12.2ms\n",
      "Speed: 3.1ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_390.jpg: 640x384 3 persons, 9.3ms\n",
      "Speed: 2.9ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_60.jpg: 640x384 4 persons, 9.2ms\n",
      "Speed: 2.9ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-871185627435460/frame_90.jpg: 640x384 6 persons, 8.1ms\n",
      "Speed: 2.5ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-818776323774715\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-818776323774715: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_0.jpg: 640x640 (no detections), 10.8ms\n",
      "Speed: 4.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_120.jpg: 640x640 3 persons, 12.6ms\n",
      "Speed: 7.3ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_150.jpg: 640x640 3 persons, 12.5ms\n",
      "Speed: 7.2ms preprocess, 12.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_180.jpg: 640x640 1 person, 8.8ms\n",
      "Speed: 5.6ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_210.jpg: 640x640 2 persons, 8.8ms\n",
      "Speed: 4.6ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_240.jpg: 640x640 5 persons, 8.3ms\n",
      "Speed: 4.6ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_270.jpg: 640x640 1 person, 2 cell phones, 14.0ms\n",
      "Speed: 4.9ms preprocess, 14.0ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_30.jpg: 640x640 1 person, 14.2ms\n",
      "Speed: 7.6ms preprocess, 14.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_300.jpg: 640x640 1 person, 1 cell phone, 10.2ms\n",
      "Speed: 6.4ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_330.jpg: 640x640 10 persons, 1 cell phone, 10.1ms\n",
      "Speed: 5.8ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_360.jpg: 640x640 1 person, 1 cell phone, 19.8ms\n",
      "Speed: 6.0ms preprocess, 19.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_390.jpg: 640x640 3 persons, 1 tv, 9.7ms\n",
      "Speed: 5.4ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_420.jpg: 640x640 3 persons, 12.6ms\n",
      "Speed: 5.5ms preprocess, 12.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_450.jpg: 640x640 5 persons, 9.7ms\n",
      "Speed: 5.0ms preprocess, 9.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_480.jpg: 640x640 2 persons, 1 cell phone, 16.3ms\n",
      "Speed: 6.8ms preprocess, 16.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_510.jpg: 640x640 (no detections), 10.1ms\n",
      "Speed: 5.9ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_540.jpg: 640x640 (no detections), 10.0ms\n",
      "Speed: 5.8ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_60.jpg: 640x640 4 persons, 9.0ms\n",
      "Speed: 4.6ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818776323774715/frame_90.jpg: 640x640 (no detections), 13.8ms\n",
      "Speed: 7.2ms preprocess, 13.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-818462803696191\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-818462803696191: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_0.jpg: 640x640 (no detections), 6.3ms\n",
      "Speed: 4.1ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_120.jpg: 640x640 3 persons, 7.0ms\n",
      "Speed: 3.9ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_150.jpg: 640x640 3 persons, 12.2ms\n",
      "Speed: 4.1ms preprocess, 12.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_180.jpg: 640x640 1 person, 15.7ms\n",
      "Speed: 8.2ms preprocess, 15.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_210.jpg: 640x640 2 persons, 13.4ms\n",
      "Speed: 5.9ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_240.jpg: 640x640 5 persons, 12.5ms\n",
      "Speed: 6.3ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_270.jpg: 640x640 1 person, 2 cell phones, 12.7ms\n",
      "Speed: 7.4ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_30.jpg: 640x640 1 person, 9.9ms\n",
      "Speed: 6.6ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_300.jpg: 640x640 1 person, 1 cell phone, 9.4ms\n",
      "Speed: 4.7ms preprocess, 9.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_330.jpg: 640x640 10 persons, 1 cell phone, 11.1ms\n",
      "Speed: 5.3ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_360.jpg: 640x640 1 person, 1 cell phone, 17.9ms\n",
      "Speed: 6.4ms preprocess, 17.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_390.jpg: 640x640 3 persons, 1 tv, 27.1ms\n",
      "Speed: 7.6ms preprocess, 27.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_420.jpg: 640x640 3 persons, 9.6ms\n",
      "Speed: 6.1ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_450.jpg: 640x640 5 persons, 8.3ms\n",
      "Speed: 6.0ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_480.jpg: 640x640 2 persons, 1 cell phone, 7.8ms\n",
      "Speed: 4.6ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_510.jpg: 640x640 (no detections), 21.7ms\n",
      "Speed: 5.1ms preprocess, 21.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_540.jpg: 640x640 (no detections), 16.5ms\n",
      "Speed: 8.5ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_60.jpg: 640x640 4 persons, 10.9ms\n",
      "Speed: 5.9ms preprocess, 10.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-818462803696191/frame_90.jpg: 640x640 (no detections), 8.8ms\n",
      "Speed: 5.8ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-817763467176157\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-817763467176157: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_0.jpg: 640x640 1 person, 6.6ms\n",
      "Speed: 4.9ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_120.jpg: 640x640 1 person, 1 tv, 7.8ms\n",
      "Speed: 5.2ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_150.jpg: 640x640 3 persons, 9.1ms\n",
      "Speed: 4.4ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_180.jpg: 640x640 5 persons, 8.9ms\n",
      "Speed: 5.2ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_210.jpg: 640x640 2 persons, 1 cell phone, 13.1ms\n",
      "Speed: 6.4ms preprocess, 13.1ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_240.jpg: 640x640 3 persons, 1 cell phone, 8.5ms\n",
      "Speed: 6.2ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_270.jpg: 640x640 1 person, 1 cell phone, 11.8ms\n",
      "Speed: 6.0ms preprocess, 11.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_30.jpg: 640x640 1 person, 1 cell phone, 30.0ms\n",
      "Speed: 9.7ms preprocess, 30.0ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_300.jpg: 640x640 3 persons, 1 cell phone, 13.0ms\n",
      "Speed: 8.0ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_330.jpg: 640x640 5 persons, 1 cell phone, 12.1ms\n",
      "Speed: 6.6ms preprocess, 12.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_360.jpg: 640x640 7 persons, 1 cell phone, 24.2ms\n",
      "Speed: 6.6ms preprocess, 24.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_390.jpg: 640x640 4 persons, 1 cell phone, 1 book, 23.6ms\n",
      "Speed: 6.7ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_420.jpg: 640x640 3 persons, 1 cell phone, 1 book, 20.9ms\n",
      "Speed: 7.4ms preprocess, 20.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_450.jpg: 640x640 (no detections), 20.0ms\n",
      "Speed: 7.2ms preprocess, 20.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_480.jpg: 640x640 1 person, 14.2ms\n",
      "Speed: 8.2ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_510.jpg: 640x640 1 bicycle, 1 motorcycle, 12.9ms\n",
      "Speed: 6.8ms preprocess, 12.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_540.jpg: 640x640 1 person, 1 donut, 13.6ms\n",
      "Speed: 5.8ms preprocess, 13.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_570.jpg: 640x640 1 person, 9.7ms\n",
      "Speed: 5.0ms preprocess, 9.7ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_60.jpg: 640x640 1 person, 1 cell phone, 9.9ms\n",
      "Speed: 5.7ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_600.jpg: 640x640 2 persons, 10.6ms\n",
      "Speed: 5.0ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_630.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_630.jpg: 640x640 1 person, 24.0ms\n",
      "Speed: 6.5ms preprocess, 24.0ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817763467176157/frame_90.jpg: 640x640 (no detections), 13.1ms\n",
      "Speed: 7.9ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-817475239730695\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-817475239730695: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 10.7ms\n",
      "Speed: 3.4ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_120.jpg: 640x384 4 persons, 7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_150.jpg: 640x384 4 persons, 7.9ms\n",
      "Speed: 2.7ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_180.jpg: 640x384 2 persons, 28.5ms\n",
      "Speed: 3.7ms preprocess, 28.5ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_210.jpg: 640x384 2 persons, 11.3ms\n",
      "Speed: 4.0ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_240.jpg: 640x384 3 persons, 13.5ms\n",
      "Speed: 3.3ms preprocess, 13.5ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_270.jpg: 640x384 2 persons, 11.1ms\n",
      "Speed: 3.2ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_30.jpg: 640x384 3 persons, 1 cell phone, 21.5ms\n",
      "Speed: 3.7ms preprocess, 21.5ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_300.jpg: 640x384 3 persons, 1 tv, 8.7ms\n",
      "Speed: 2.9ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_330.jpg: 640x384 2 persons, 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_360.jpg: 640x384 4 persons, 13.3ms\n",
      "Speed: 2.7ms preprocess, 13.3ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_390.jpg: 640x384 3 persons, 28.6ms\n",
      "Speed: 3.9ms preprocess, 28.6ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_60.jpg: 640x384 4 persons, 9.2ms\n",
      "Speed: 3.3ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817475239730695/frame_90.jpg: 640x384 6 persons, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-817135236672734\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-817135236672734: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_0.jpg: 640x384 (no detections), 7.6ms\n",
      "Speed: 2.1ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_116.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_116.jpg: 640x384 (no detections), 8.8ms\n",
      "Speed: 3.0ms preprocess, 8.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_145.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_145.jpg: 640x384 2 persons, 2 books, 17.0ms\n",
      "Speed: 3.1ms preprocess, 17.0ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_174.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_174.jpg: 640x384 1 person, 9.2ms\n",
      "Speed: 3.3ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_203.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_203.jpg: 640x384 1 person, 9.5ms\n",
      "Speed: 2.9ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_232.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_232.jpg: 640x384 2 persons, 1 bed, 9.3ms\n",
      "Speed: 2.6ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_261.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_261.jpg: 640x384 1 person, 1 bus, 1 cell phone, 23.7ms\n",
      "Speed: 3.8ms preprocess, 23.7ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_29.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_29.jpg: 640x384 1 tv, 1 mouse, 26.5ms\n",
      "Speed: 4.4ms preprocess, 26.5ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_290.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_290.jpg: 640x384 1 person, 1 laptop, 1 book, 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_319.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_319.jpg: 640x384 1 cell phone, 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_348.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_348.jpg: 640x384 2 persons, 3 cell phones, 1 clock, 9.3ms\n",
      "Speed: 3.6ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_377.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_377.jpg: 640x384 2 persons, 2 cell phones, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_406.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_406.jpg: 640x384 2 persons, 8.9ms\n",
      "Speed: 2.9ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_435.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_435.jpg: 640x384 1 person, 8.3ms\n",
      "Speed: 2.5ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_464.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_464.jpg: 640x384 1 person, 27.2ms\n",
      "Speed: 3.8ms preprocess, 27.2ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_493.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_493.jpg: 640x384 1 person, 19.9ms\n",
      "Speed: 3.7ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_522.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_522.jpg: 640x384 1 person, 8.9ms\n",
      "Speed: 2.9ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_551.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_551.jpg: 640x384 (no detections), 14.1ms\n",
      "Speed: 3.6ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_58.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_58.jpg: 640x384 1 person, 1 bus, 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_580.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_580.jpg: 640x384 (no detections), 8.3ms\n",
      "Speed: 3.2ms preprocess, 8.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_87.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-817135236672734/frame_87.jpg: 640x384 (no detections), 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-816335920524988\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-816335920524988: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_0.jpg: 640x384 (no detections), 10.6ms\n",
      "Speed: 4.0ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_120.jpg: 640x384 3 persons, 1 book, 8.4ms\n",
      "Speed: 3.7ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_150.jpg: 640x384 2 persons, 19.3ms\n",
      "Speed: 4.9ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_180.jpg: 640x384 1 person, 8.7ms\n",
      "Speed: 3.0ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_210.jpg: 640x384 1 person, 8.9ms\n",
      "Speed: 2.6ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_240.jpg: 640x384 3 persons, 1 cell phone, 32.6ms\n",
      "Speed: 4.9ms preprocess, 32.6ms inference, 7.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_270.jpg: 640x384 1 person, 1 cell phone, 11.8ms\n",
      "Speed: 4.1ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_30.jpg: 640x384 1 person, 12.6ms\n",
      "Speed: 4.0ms preprocess, 12.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_300.jpg: 640x384 1 person, 1 cell phone, 19.1ms\n",
      "Speed: 4.1ms preprocess, 19.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_330.jpg: 640x384 5 persons, 11.3ms\n",
      "Speed: 4.0ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_360.jpg: 640x384 1 person, 1 cell phone, 13.1ms\n",
      "Speed: 3.4ms preprocess, 13.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_390.jpg: 640x384 2 persons, 18.8ms\n",
      "Speed: 4.7ms preprocess, 18.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_420.jpg: 640x384 4 persons, 22.2ms\n",
      "Speed: 3.4ms preprocess, 22.2ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_450.jpg: 640x384 2 persons, 23.4ms\n",
      "Speed: 4.3ms preprocess, 23.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_480.jpg: 640x384 3 persons, 2 cars, 1 cell phone, 9.4ms\n",
      "Speed: 3.2ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_510.jpg: 640x384 (no detections), 7.5ms\n",
      "Speed: 2.4ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_540.jpg: 640x384 (no detections), 8.2ms\n",
      "Speed: 2.8ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_60.jpg: 640x384 1 person, 24.3ms\n",
      "Speed: 4.8ms preprocess, 24.3ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-816335920524988/frame_90.jpg: 640x384 1 person, 15.9ms\n",
      "Speed: 3.9ms preprocess, 15.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-814072014151046\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-814072014151046: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_0.jpg: 640x384 1 person, 9.3ms\n",
      "Speed: 2.8ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_120.jpg: 640x384 4 persons, 1 cell phone, 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_150.jpg: 640x384 5 persons, 9.3ms\n",
      "Speed: 2.7ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_180.jpg: 640x384 (no detections), 27.8ms\n",
      "Speed: 4.6ms preprocess, 27.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_210.jpg: 640x384 1 person, 14.1ms\n",
      "Speed: 4.0ms preprocess, 14.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_240.jpg: 640x384 2 persons, 13.2ms\n",
      "Speed: 4.1ms preprocess, 13.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_270.jpg: 640x384 (no detections), 15.1ms\n",
      "Speed: 4.1ms preprocess, 15.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_30.jpg: 640x384 (no detections), 12.6ms\n",
      "Speed: 4.0ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_300.jpg: 640x384 2 persons, 12.0ms\n",
      "Speed: 3.8ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_330.jpg: 640x384 (no detections), 14.6ms\n",
      "Speed: 4.8ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_360.jpg: 640x384 (no detections), 12.3ms\n",
      "Speed: 4.3ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_390.jpg: 640x384 (no detections), 14.2ms\n",
      "Speed: 4.5ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_60.jpg: 640x384 (no detections), 12.4ms\n",
      "Speed: 4.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-814072014151046/frame_90.jpg: 640x384 2 persons, 1 cell phone, 13.2ms\n",
      "Speed: 4.8ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-811606650922029\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-811606650922029: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_0.jpg: 640x640 1 person, 27.1ms\n",
      "Speed: 6.8ms preprocess, 27.1ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_120.jpg: 640x640 1 person, 1 tv, 8.3ms\n",
      "Speed: 4.7ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_150.jpg: 640x640 3 persons, 8.1ms\n",
      "Speed: 5.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_180.jpg: 640x640 5 persons, 7.9ms\n",
      "Speed: 4.5ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_210.jpg: 640x640 2 persons, 1 cell phone, 16.2ms\n",
      "Speed: 4.7ms preprocess, 16.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_240.jpg: 640x640 3 persons, 1 cell phone, 30.7ms\n",
      "Speed: 8.9ms preprocess, 30.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_270.jpg: 640x640 1 person, 1 cell phone, 12.2ms\n",
      "Speed: 5.6ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_30.jpg: 640x640 1 person, 1 cell phone, 15.7ms\n",
      "Speed: 6.5ms preprocess, 15.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_300.jpg: 640x640 3 persons, 1 cell phone, 12.6ms\n",
      "Speed: 7.7ms preprocess, 12.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_330.jpg: 640x640 5 persons, 1 cell phone, 7.8ms\n",
      "Speed: 4.8ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_360.jpg: 640x640 7 persons, 1 cell phone, 9.5ms\n",
      "Speed: 4.7ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_390.jpg: 640x640 4 persons, 1 cell phone, 1 book, 8.2ms\n",
      "Speed: 5.4ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_420.jpg: 640x640 3 persons, 1 cell phone, 1 book, 10.5ms\n",
      "Speed: 5.0ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_450.jpg: 640x640 (no detections), 9.7ms\n",
      "Speed: 5.6ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_480.jpg: 640x640 1 person, 13.3ms\n",
      "Speed: 6.4ms preprocess, 13.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_510.jpg: 640x640 1 bicycle, 1 motorcycle, 15.5ms\n",
      "Speed: 8.0ms preprocess, 15.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_540.jpg: 640x640 1 person, 1 donut, 24.5ms\n",
      "Speed: 7.8ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_570.jpg: 640x640 1 person, 9.6ms\n",
      "Speed: 5.9ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_60.jpg: 640x640 1 person, 1 cell phone, 8.0ms\n",
      "Speed: 4.5ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_600.jpg: 640x640 2 persons, 9.5ms\n",
      "Speed: 5.1ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_630.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_630.jpg: 640x640 1 person, 8.5ms\n",
      "Speed: 5.1ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-811606650922029/frame_90.jpg: 640x640 (no detections), 9.0ms\n",
      "Speed: 5.4ms preprocess, 9.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8111507755613955\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8111507755613955: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_0.jpg: 640x384 (no detections), 8.0ms\n",
      "Speed: 2.8ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_120.jpg: 640x384 1 cup, 6.7ms\n",
      "Speed: 2.9ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_150.jpg: 640x384 3 persons, 1 bowl, 1 broccoli, 1 cell phone, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_180.jpg: 640x384 2 persons, 1 cell phone, 12.8ms\n",
      "Speed: 4.1ms preprocess, 12.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_210.jpg: 640x384 1 person, 1 umbrella, 1 cell phone, 10.7ms\n",
      "Speed: 4.0ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_240.jpg: 640x384 1 person, 1 umbrella, 25.5ms\n",
      "Speed: 4.6ms preprocess, 25.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_270.jpg: 640x384 1 tv, 8.8ms\n",
      "Speed: 4.1ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_30.jpg: 640x384 (no detections), 11.3ms\n",
      "Speed: 3.4ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_300.jpg: 640x384 3 persons, 12.7ms\n",
      "Speed: 3.7ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_330.jpg: 640x384 2 persons, 31.7ms\n",
      "Speed: 3.0ms preprocess, 31.7ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_360.jpg: 640x384 (no detections), 17.4ms\n",
      "Speed: 4.8ms preprocess, 17.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_390.jpg: 640x384 1 keyboard, 1 cell phone, 12.7ms\n",
      "Speed: 3.2ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_420.jpg: 640x384 (no detections), 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_450.jpg: 640x384 1 cell phone, 8.2ms\n",
      "Speed: 3.0ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_480.jpg: 640x384 (no detections), 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_510.jpg: 640x384 (no detections), 10.1ms\n",
      "Speed: 3.6ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_60.jpg: 640x384 (no detections), 9.1ms\n",
      "Speed: 3.8ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8111507755613955/frame_90.jpg: 640x384 1 bicycle, 11.6ms\n",
      "Speed: 4.1ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8100667816697710\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8100667816697710: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_0.jpg: 640x384 4 persons, 1 cell phone, 1 book, 8.0ms\n",
      "Speed: 3.6ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_120.jpg: 640x384 2 persons, 1 bottle, 8.0ms\n",
      "Speed: 4.1ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_150.jpg: 640x384 1 person, 10.5ms\n",
      "Speed: 3.9ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_180.jpg: 640x384 4 persons, 9.7ms\n",
      "Speed: 2.9ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_210.jpg: 640x384 2 persons, 10.8ms\n",
      "Speed: 3.2ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_240.jpg: 640x384 1 person, 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_270.jpg: 640x384 1 person, 13.4ms\n",
      "Speed: 3.8ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_30.jpg: 640x384 (no detections), 12.7ms\n",
      "Speed: 3.5ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_300.jpg: 640x384 1 person, 12.4ms\n",
      "Speed: 4.8ms preprocess, 12.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_330.jpg: 640x384 (no detections), 19.7ms\n",
      "Speed: 4.3ms preprocess, 19.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_360.jpg: 640x384 (no detections), 9.2ms\n",
      "Speed: 3.3ms preprocess, 9.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_60.jpg: 640x384 2 persons, 25.2ms\n",
      "Speed: 4.0ms preprocess, 25.2ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8100667816697710/frame_90.jpg: 640x384 1 person, 8.6ms\n",
      "Speed: 2.9ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-809480737932683\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-809480737932683: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_0.jpg: 640x640 (no detections), 6.5ms\n",
      "Speed: 5.2ms preprocess, 6.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_116.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_116.jpg: 640x640 (no detections), 22.3ms\n",
      "Speed: 7.8ms preprocess, 22.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_145.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_145.jpg: 640x640 1 zebra, 21.8ms\n",
      "Speed: 6.7ms preprocess, 21.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_174.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_174.jpg: 640x640 1 zebra, 8.1ms\n",
      "Speed: 5.4ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_203.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_203.jpg: 640x640 1 clock, 7.5ms\n",
      "Speed: 4.4ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_232.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_232.jpg: 640x640 (no detections), 20.7ms\n",
      "Speed: 6.5ms preprocess, 20.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_261.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_261.jpg: 640x640 1 clock, 15.2ms\n",
      "Speed: 6.1ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_29.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_29.jpg: 640x640 1 person, 1 sports ball, 23.0ms\n",
      "Speed: 5.9ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_290.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_290.jpg: 640x640 (no detections), 8.6ms\n",
      "Speed: 4.5ms preprocess, 8.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_58.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_58.jpg: 640x640 1 clock, 7.7ms\n",
      "Speed: 4.1ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_87.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-809480737932683/frame_87.jpg: 640x640 (no detections), 8.0ms\n",
      "Speed: 4.1ms preprocess, 8.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-808321904744283\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-808321904744283: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_0.jpg: 640x640 (no detections), 8.0ms\n",
      "Speed: 4.2ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_120.jpg: 640x640 3 persons, 11.0ms\n",
      "Speed: 5.7ms preprocess, 11.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_150.jpg: 640x640 3 persons, 7.9ms\n",
      "Speed: 7.0ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_180.jpg: 640x640 1 person, 10.8ms\n",
      "Speed: 7.3ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_210.jpg: 640x640 2 persons, 18.3ms\n",
      "Speed: 8.5ms preprocess, 18.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_240.jpg: 640x640 5 persons, 12.3ms\n",
      "Speed: 6.8ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_270.jpg: 640x640 1 person, 2 cell phones, 15.1ms\n",
      "Speed: 6.0ms preprocess, 15.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_30.jpg: 640x640 1 person, 10.1ms\n",
      "Speed: 5.2ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_300.jpg: 640x640 1 person, 1 cell phone, 9.8ms\n",
      "Speed: 4.8ms preprocess, 9.8ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_330.jpg: 640x640 10 persons, 1 cell phone, 12.5ms\n",
      "Speed: 6.8ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_360.jpg: 640x640 1 person, 1 cell phone, 12.1ms\n",
      "Speed: 7.4ms preprocess, 12.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_390.jpg: 640x640 3 persons, 1 tv, 30.7ms\n",
      "Speed: 6.3ms preprocess, 30.7ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_420.jpg: 640x640 3 persons, 27.7ms\n",
      "Speed: 8.7ms preprocess, 27.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_450.jpg: 640x640 5 persons, 16.4ms\n",
      "Speed: 10.0ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_480.jpg: 640x640 2 persons, 1 cell phone, 12.7ms\n",
      "Speed: 6.5ms preprocess, 12.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_510.jpg: 640x640 (no detections), 8.2ms\n",
      "Speed: 6.3ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_540.jpg: 640x640 (no detections), 7.5ms\n",
      "Speed: 4.5ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_60.jpg: 640x640 4 persons, 8.8ms\n",
      "Speed: 4.8ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-808321904744283/frame_90.jpg: 640x640 (no detections), 10.7ms\n",
      "Speed: 5.6ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-807800198130528\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-807800198130528: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_0.jpg: 640x384 (no detections), 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_120.jpg: 640x384 3 persons, 9.0ms\n",
      "Speed: 3.4ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_150.jpg: 640x384 2 persons, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_180.jpg: 640x384 1 person, 25.0ms\n",
      "Speed: 4.5ms preprocess, 25.0ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_210.jpg: 640x384 1 person, 10.8ms\n",
      "Speed: 3.6ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_240.jpg: 640x384 3 persons, 8.8ms\n",
      "Speed: 3.1ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_270.jpg: 640x384 1 person, 2 cell phones, 9.0ms\n",
      "Speed: 3.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_30.jpg: 640x384 1 person, 22.2ms\n",
      "Speed: 3.4ms preprocess, 22.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_300.jpg: 640x384 1 person, 1 cell phone, 24.2ms\n",
      "Speed: 4.5ms preprocess, 24.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_330.jpg: 640x384 7 persons, 10.9ms\n",
      "Speed: 3.7ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_360.jpg: 640x384 1 person, 1 cell phone, 8.7ms\n",
      "Speed: 3.0ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_390.jpg: 640x384 1 person, 1 train, 1 keyboard, 8.0ms\n",
      "Speed: 2.4ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_420.jpg: 640x384 3 persons, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_450.jpg: 640x384 2 persons, 29.8ms\n",
      "Speed: 4.1ms preprocess, 29.8ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_480.jpg: 640x384 2 persons, 3 cars, 23.0ms\n",
      "Speed: 3.6ms preprocess, 23.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_510.jpg: 640x384 (no detections), 8.6ms\n",
      "Speed: 2.8ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_540.jpg: 640x384 (no detections), 10.3ms\n",
      "Speed: 3.5ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_60.jpg: 640x384 2 persons, 9.3ms\n",
      "Speed: 3.7ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-807800198130528/frame_90.jpg: 640x384 1 person, 1 remote, 27.7ms\n",
      "Speed: 3.7ms preprocess, 27.7ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8057957437624799\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-8057957437624799: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_0.jpg: 640x640 1 person, 6.7ms\n",
      "Speed: 4.0ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_120.jpg: 640x640 1 person, 1 tv, 7.6ms\n",
      "Speed: 4.1ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_150.jpg: 640x640 3 persons, 22.7ms\n",
      "Speed: 4.4ms preprocess, 22.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_180.jpg: 640x640 5 persons, 9.0ms\n",
      "Speed: 5.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_210.jpg: 640x640 2 persons, 1 cell phone, 7.5ms\n",
      "Speed: 4.7ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_240.jpg: 640x640 3 persons, 1 cell phone, 8.9ms\n",
      "Speed: 4.1ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_270.jpg: 640x640 1 person, 1 cell phone, 9.8ms\n",
      "Speed: 4.9ms preprocess, 9.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_30.jpg: 640x640 1 person, 1 cell phone, 32.2ms\n",
      "Speed: 7.3ms preprocess, 32.2ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_300.jpg: 640x640 3 persons, 1 cell phone, 16.2ms\n",
      "Speed: 7.6ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_330.jpg: 640x640 5 persons, 1 cell phone, 8.6ms\n",
      "Speed: 5.1ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_360.jpg: 640x640 7 persons, 1 cell phone, 8.4ms\n",
      "Speed: 4.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_390.jpg: 640x640 4 persons, 1 cell phone, 1 book, 8.4ms\n",
      "Speed: 4.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_420.jpg: 640x640 3 persons, 1 cell phone, 1 book, 8.1ms\n",
      "Speed: 5.1ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_450.jpg: 640x640 (no detections), 9.0ms\n",
      "Speed: 5.6ms preprocess, 9.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_480.jpg: 640x640 1 person, 10.4ms\n",
      "Speed: 5.1ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_510.jpg: 640x640 1 bicycle, 1 motorcycle, 26.8ms\n",
      "Speed: 5.6ms preprocess, 26.8ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_540.jpg: 640x640 1 person, 1 donut, 9.2ms\n",
      "Speed: 5.7ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_570.jpg: 640x640 1 person, 7.7ms\n",
      "Speed: 4.8ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_60.jpg: 640x640 1 person, 1 cell phone, 7.2ms\n",
      "Speed: 4.3ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_600.jpg: 640x640 2 persons, 10.1ms\n",
      "Speed: 5.3ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_630.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_630.jpg: 640x640 1 person, 27.0ms\n",
      "Speed: 7.1ms preprocess, 27.0ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-8057957437624799/frame_90.jpg: 640x640 (no detections), 11.5ms\n",
      "Speed: 6.4ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-803897110603133\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-803897110603133: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_0.jpg: 640x640 (no detections), 11.4ms\n",
      "Speed: 5.8ms preprocess, 11.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_120.jpg: 640x640 (no detections), 12.5ms\n",
      "Speed: 5.1ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_150.jpg: 640x640 1 car, 10.7ms\n",
      "Speed: 5.9ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_180.jpg: 640x640 1 bus, 7.3ms\n",
      "Speed: 3.9ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_210.jpg: 640x640 1 train, 15.4ms\n",
      "Speed: 4.8ms preprocess, 15.4ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_240.jpg: 640x640 (no detections), 23.5ms\n",
      "Speed: 6.2ms preprocess, 23.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_270.jpg: 640x640 (no detections), 8.7ms\n",
      "Speed: 5.0ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_30.jpg: 640x640 (no detections), 16.8ms\n",
      "Speed: 7.3ms preprocess, 16.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_300.jpg: 640x640 (no detections), 13.9ms\n",
      "Speed: 6.7ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_330.jpg: 640x640 2 clocks, 22.1ms\n",
      "Speed: 6.2ms preprocess, 22.1ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_360.jpg: 640x640 (no detections), 14.1ms\n",
      "Speed: 5.8ms preprocess, 14.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_390.jpg: 640x640 (no detections), 28.9ms\n",
      "Speed: 7.8ms preprocess, 28.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_420.jpg: 640x640 1 train, 15.8ms\n",
      "Speed: 4.6ms preprocess, 15.8ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_450.jpg: 640x640 1 train, 15.0ms\n",
      "Speed: 7.2ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_480.jpg: 640x640 1 clock, 10.1ms\n",
      "Speed: 6.9ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_510.jpg: 640x640 2 persons, 1 car, 1 clock, 8.8ms\n",
      "Speed: 5.7ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_540.jpg: 640x640 1 clock, 13.5ms\n",
      "Speed: 6.4ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_60.jpg: 640x640 (no detections), 9.1ms\n",
      "Speed: 4.9ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-803897110603133/frame_90.jpg: 640x640 (no detections), 12.6ms\n",
      "Speed: 5.9ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-802443478544141\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-802443478544141: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_0.jpg: 640x640 1 person, 6.6ms\n",
      "Speed: 4.4ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_120.jpg: 640x640 1 person, 1 tv, 8.2ms\n",
      "Speed: 4.6ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_150.jpg: 640x640 3 persons, 7.5ms\n",
      "Speed: 4.3ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_180.jpg: 640x640 5 persons, 9.3ms\n",
      "Speed: 4.7ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_210.jpg: 640x640 2 persons, 1 cell phone, 9.7ms\n",
      "Speed: 5.8ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_240.jpg: 640x640 3 persons, 1 cell phone, 28.0ms\n",
      "Speed: 7.7ms preprocess, 28.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_270.jpg: 640x640 1 person, 1 cell phone, 16.9ms\n",
      "Speed: 7.2ms preprocess, 16.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_30.jpg: 640x640 1 person, 1 cell phone, 26.9ms\n",
      "Speed: 8.7ms preprocess, 26.9ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_300.jpg: 640x640 3 persons, 1 cell phone, 27.6ms\n",
      "Speed: 7.9ms preprocess, 27.6ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_330.jpg: 640x640 5 persons, 1 cell phone, 10.6ms\n",
      "Speed: 7.0ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_360.jpg: 640x640 7 persons, 1 cell phone, 8.9ms\n",
      "Speed: 4.3ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_390.jpg: 640x640 4 persons, 1 cell phone, 1 book, 14.5ms\n",
      "Speed: 5.8ms preprocess, 14.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_420.jpg: 640x640 3 persons, 1 cell phone, 1 book, 22.1ms\n",
      "Speed: 8.0ms preprocess, 22.1ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_450.jpg: 640x640 (no detections), 19.3ms\n",
      "Speed: 7.2ms preprocess, 19.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_480.jpg: 640x640 1 person, 10.6ms\n",
      "Speed: 6.1ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_510.jpg: 640x640 1 bicycle, 1 motorcycle, 24.8ms\n",
      "Speed: 5.4ms preprocess, 24.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_540.jpg: 640x640 1 person, 1 donut, 30.5ms\n",
      "Speed: 8.0ms preprocess, 30.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_570.jpg: 640x640 1 person, 10.8ms\n",
      "Speed: 6.8ms preprocess, 10.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_60.jpg: 640x640 1 person, 1 cell phone, 9.1ms\n",
      "Speed: 7.2ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_600.jpg: 640x640 2 persons, 14.9ms\n",
      "Speed: 8.8ms preprocess, 14.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_630.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_630.jpg: 640x640 1 person, 13.3ms\n",
      "Speed: 7.3ms preprocess, 13.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-802443478544141/frame_90.jpg: 640x640 (no detections), 17.2ms\n",
      "Speed: 7.2ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-7995631707140182\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-7995631707140182: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_0.jpg: 640x640 3 persons, 1 bed, 10.0ms\n",
      "Speed: 6.7ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_120.jpg: 640x640 (no detections), 10.3ms\n",
      "Speed: 6.5ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_150.jpg: 640x640 2 persons, 9.6ms\n",
      "Speed: 4.6ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_180.jpg: 640x640 2 persons, 1 tv, 8.7ms\n",
      "Speed: 5.8ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_210.jpg: 640x640 3 persons, 2 trains, 27.7ms\n",
      "Speed: 6.6ms preprocess, 27.7ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_240.jpg: 640x640 1 clock, 29.7ms\n",
      "Speed: 7.6ms preprocess, 29.7ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_270.jpg: 640x640 1 clock, 14.4ms\n",
      "Speed: 8.5ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_30.jpg: 640x640 5 persons, 8.2ms\n",
      "Speed: 4.3ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_60.jpg: 640x640 6 persons, 11.4ms\n",
      "Speed: 5.8ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-7995631707140182/frame_90.jpg: 640x640 1 bed, 1 book, 7.9ms\n",
      "Speed: 4.6ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-797179088937277\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-797179088937277: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_0.jpg: 640x640 3 persons, 1 bed, 9.7ms\n",
      "Speed: 4.2ms preprocess, 9.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_120.jpg: 640x640 1 person, 11.1ms\n",
      "Speed: 6.4ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_150.jpg: 640x640 2 persons, 1 cake, 12.9ms\n",
      "Speed: 6.4ms preprocess, 12.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_180.jpg: 640x640 2 persons, 1 tv, 11.4ms\n",
      "Speed: 5.0ms preprocess, 11.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_210.jpg: 640x640 3 persons, 2 trains, 28.3ms\n",
      "Speed: 6.1ms preprocess, 28.3ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_240.jpg: 640x640 1 clock, 12.1ms\n",
      "Speed: 6.8ms preprocess, 12.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_270.jpg: 640x640 1 clock, 20.8ms\n",
      "Speed: 6.3ms preprocess, 20.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_30.jpg: 640x640 4 persons, 14.3ms\n",
      "Speed: 7.6ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_60.jpg: 640x640 8 persons, 13.0ms\n",
      "Speed: 7.2ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-797179088937277/frame_90.jpg: 640x640 1 bed, 1 book, 9.9ms\n",
      "Speed: 5.3ms preprocess, 9.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-789793989900194\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-789793989900194: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_0.jpg: 640x640 (no detections), 10.3ms\n",
      "Speed: 4.8ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_116.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_116.jpg: 640x640 1 dog, 10.7ms\n",
      "Speed: 6.4ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_145.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_145.jpg: 640x640 4 persons, 23.9ms\n",
      "Speed: 9.1ms preprocess, 23.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_174.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_174.jpg: 640x640 3 persons, 11.8ms\n",
      "Speed: 6.0ms preprocess, 11.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_203.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_203.jpg: 640x640 4 persons, 33.2ms\n",
      "Speed: 9.2ms preprocess, 33.2ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_232.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_232.jpg: 640x640 1 person, 1 bus, 1 cell phone, 1 book, 13.7ms\n",
      "Speed: 7.6ms preprocess, 13.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_261.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_261.jpg: 640x640 1 person, 1 cell phone, 1 clock, 9.7ms\n",
      "Speed: 7.3ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_29.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_29.jpg: 640x640 1 tv, 1 microwave, 10.2ms\n",
      "Speed: 6.1ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_290.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_290.jpg: 640x640 1 tv, 1 cell phone, 9.9ms\n",
      "Speed: 4.4ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_319.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_319.jpg: 640x640 2 persons, 1 tv, 2 cell phones, 1 clock, 21.0ms\n",
      "Speed: 5.7ms preprocess, 21.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_348.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_348.jpg: 640x640 2 persons, 1 cell phone, 1 clock, 10.0ms\n",
      "Speed: 6.3ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_377.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_377.jpg: 640x640 3 persons, 13.1ms\n",
      "Speed: 6.9ms preprocess, 13.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_406.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_406.jpg: 640x640 1 person, 26.9ms\n",
      "Speed: 6.0ms preprocess, 26.9ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_435.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_435.jpg: 640x640 1 person, 9.1ms\n",
      "Speed: 5.2ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_464.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_464.jpg: 640x640 1 person, 7.7ms\n",
      "Speed: 4.4ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_493.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_493.jpg: 640x640 1 person, 15.1ms\n",
      "Speed: 7.0ms preprocess, 15.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_522.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_522.jpg: 640x640 (no detections), 9.1ms\n",
      "Speed: 5.0ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_551.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_551.jpg: 640x640 (no detections), 14.2ms\n",
      "Speed: 5.8ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_58.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_58.jpg: 640x640 1 person, 1 tv, 9.3ms\n",
      "Speed: 5.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_87.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-789793989900194/frame_87.jpg: 640x640 (no detections), 27.1ms\n",
      "Speed: 7.5ms preprocess, 27.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-786610583313461\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-786610583313461: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.1ms\n",
      "Speed: 2.5ms preprocess, 8.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_120.jpg: 640x384 4 persons, 9.1ms\n",
      "Speed: 4.1ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_150.jpg: 640x384 4 persons, 12.2ms\n",
      "Speed: 3.7ms preprocess, 12.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_180.jpg: 640x384 2 persons, 30.5ms\n",
      "Speed: 3.4ms preprocess, 30.5ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_210.jpg: 640x384 2 persons, 11.0ms\n",
      "Speed: 3.6ms preprocess, 11.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_240.jpg: 640x384 3 persons, 17.0ms\n",
      "Speed: 4.6ms preprocess, 17.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_270.jpg: 640x384 2 persons, 12.5ms\n",
      "Speed: 4.9ms preprocess, 12.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_30.jpg: 640x384 3 persons, 1 cell phone, 17.1ms\n",
      "Speed: 3.9ms preprocess, 17.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_300.jpg: 640x384 3 persons, 1 tv, 12.8ms\n",
      "Speed: 4.0ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_330.jpg: 640x384 2 persons, 16.2ms\n",
      "Speed: 4.1ms preprocess, 16.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_360.jpg: 640x384 4 persons, 14.0ms\n",
      "Speed: 4.1ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_390.jpg: 640x384 3 persons, 11.4ms\n",
      "Speed: 3.7ms preprocess, 11.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_60.jpg: 640x384 4 persons, 15.5ms\n",
      "Speed: 4.6ms preprocess, 15.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-786610583313461/frame_90.jpg: 640x384 6 persons, 11.4ms\n",
      "Speed: 3.0ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-694675672308301\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-694675672308301: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 13.3ms\n",
      "Speed: 4.0ms preprocess, 13.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_120.jpg: 640x384 4 persons, 8.9ms\n",
      "Speed: 3.1ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_150.jpg: 640x384 4 persons, 9.6ms\n",
      "Speed: 3.5ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_180.jpg: 640x384 2 persons, 17.6ms\n",
      "Speed: 3.8ms preprocess, 17.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_210.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 2.5ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_240.jpg: 640x384 3 persons, 7.7ms\n",
      "Speed: 2.5ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_270.jpg: 640x384 2 persons, 24.8ms\n",
      "Speed: 2.5ms preprocess, 24.8ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_30.jpg: 640x384 3 persons, 1 cell phone, 33.5ms\n",
      "Speed: 4.9ms preprocess, 33.5ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_300.jpg: 640x384 3 persons, 1 tv, 24.2ms\n",
      "Speed: 4.8ms preprocess, 24.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_330.jpg: 640x384 2 persons, 11.1ms\n",
      "Speed: 4.1ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_360.jpg: 640x384 4 persons, 11.4ms\n",
      "Speed: 3.8ms preprocess, 11.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_390.jpg: 640x384 3 persons, 9.0ms\n",
      "Speed: 3.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_60.jpg: 640x384 4 persons, 32.6ms\n",
      "Speed: 4.5ms preprocess, 32.6ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-694675672308301/frame_90.jpg: 640x384 6 persons, 14.2ms\n",
      "Speed: 4.3ms preprocess, 14.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-691581235967071\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-691581235967071: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 26.6ms\n",
      "Speed: 3.7ms preprocess, 26.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_120.jpg: 640x384 4 persons, 8.3ms\n",
      "Speed: 3.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_150.jpg: 640x384 4 persons, 7.9ms\n",
      "Speed: 2.7ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_180.jpg: 640x384 2 persons, 7.5ms\n",
      "Speed: 2.7ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_210.jpg: 640x384 2 persons, 21.3ms\n",
      "Speed: 3.7ms preprocess, 21.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_240.jpg: 640x384 3 persons, 11.5ms\n",
      "Speed: 3.6ms preprocess, 11.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_270.jpg: 640x384 2 persons, 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_30.jpg: 640x384 3 persons, 1 cell phone, 15.4ms\n",
      "Speed: 3.8ms preprocess, 15.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_300.jpg: 640x384 3 persons, 1 tv, 14.5ms\n",
      "Speed: 4.9ms preprocess, 14.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_330.jpg: 640x384 2 persons, 14.2ms\n",
      "Speed: 3.2ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_360.jpg: 640x384 4 persons, 21.4ms\n",
      "Speed: 4.1ms preprocess, 21.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_390.jpg: 640x384 3 persons, 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_60.jpg: 640x384 4 persons, 8.2ms\n",
      "Speed: 3.1ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-691581235967071/frame_90.jpg: 640x384 6 persons, 30.2ms\n",
      "Speed: 4.3ms preprocess, 30.2ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-690541956158254\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-690541956158254: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_120.jpg: 640x384 4 persons, 7.4ms\n",
      "Speed: 2.6ms preprocess, 7.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_150.jpg: 640x384 4 persons, 7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_180.jpg: 640x384 2 persons, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_210.jpg: 640x384 2 persons, 26.5ms\n",
      "Speed: 3.5ms preprocess, 26.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_240.jpg: 640x384 3 persons, 28.8ms\n",
      "Speed: 4.2ms preprocess, 28.8ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_270.jpg: 640x384 2 persons, 10.0ms\n",
      "Speed: 3.3ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_30.jpg: 640x384 3 persons, 1 cell phone, 12.7ms\n",
      "Speed: 3.4ms preprocess, 12.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_300.jpg: 640x384 3 persons, 1 tv, 9.4ms\n",
      "Speed: 3.3ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_330.jpg: 640x384 2 persons, 7.4ms\n",
      "Speed: 2.6ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_360.jpg: 640x384 4 persons, 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_390.jpg: 640x384 3 persons, 8.3ms\n",
      "Speed: 3.0ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_60.jpg: 640x384 4 persons, 30.5ms\n",
      "Speed: 3.6ms preprocess, 30.5ms inference, 8.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-690541956158254/frame_90.jpg: 640x384 6 persons, 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-689599909618915\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-689599909618915: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.8ms\n",
      "Speed: 2.5ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_120.jpg: 640x384 4 persons, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_150.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 2.6ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_180.jpg: 640x384 2 persons, 13.1ms\n",
      "Speed: 4.0ms preprocess, 13.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_210.jpg: 640x384 2 persons, 27.5ms\n",
      "Speed: 3.9ms preprocess, 27.5ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_240.jpg: 640x384 3 persons, 24.3ms\n",
      "Speed: 4.0ms preprocess, 24.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_270.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 3.6ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_30.jpg: 640x384 3 persons, 1 cell phone, 16.0ms\n",
      "Speed: 2.9ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_300.jpg: 640x384 3 persons, 1 tv, 9.5ms\n",
      "Speed: 2.9ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_330.jpg: 640x384 2 persons, 8.4ms\n",
      "Speed: 2.6ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_360.jpg: 640x384 4 persons, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_390.jpg: 640x384 3 persons, 9.2ms\n",
      "Speed: 2.9ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_60.jpg: 640x384 4 persons, 31.5ms\n",
      "Speed: 3.8ms preprocess, 31.5ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689599909618915/frame_90.jpg: 640x384 6 persons, 17.6ms\n",
      "Speed: 3.6ms preprocess, 17.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-689363059404444\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-689363059404444: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.4ms\n",
      "Speed: 2.7ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_120.jpg: 640x384 4 persons, 14.4ms\n",
      "Speed: 3.4ms preprocess, 14.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_150.jpg: 640x384 4 persons, 25.6ms\n",
      "Speed: 4.0ms preprocess, 25.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_180.jpg: 640x384 2 persons, 26.1ms\n",
      "Speed: 4.7ms preprocess, 26.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_210.jpg: 640x384 2 persons, 25.6ms\n",
      "Speed: 4.1ms preprocess, 25.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_240.jpg: 640x384 3 persons, 9.6ms\n",
      "Speed: 3.7ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_270.jpg: 640x384 2 persons, 13.7ms\n",
      "Speed: 2.8ms preprocess, 13.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_300.jpg: 640x384 3 persons, 1 tv, 8.2ms\n",
      "Speed: 3.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_330.jpg: 640x384 2 persons, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_360.jpg: 640x384 4 persons, 8.1ms\n",
      "Speed: 4.1ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_390.jpg: 640x384 3 persons, 30.2ms\n",
      "Speed: 3.5ms preprocess, 30.2ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_60.jpg: 640x384 4 persons, 13.7ms\n",
      "Speed: 3.9ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-689363059404444/frame_90.jpg: 640x384 6 persons, 10.2ms\n",
      "Speed: 3.4ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-687665956347322\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-687665956347322: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 10.9ms\n",
      "Speed: 3.8ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_120.jpg: 640x384 4 persons, 8.7ms\n",
      "Speed: 3.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_150.jpg: 640x384 4 persons, 8.4ms\n",
      "Speed: 2.9ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_180.jpg: 640x384 2 persons, 10.8ms\n",
      "Speed: 3.6ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_210.jpg: 640x384 2 persons, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_240.jpg: 640x384 3 persons, 22.9ms\n",
      "Speed: 3.4ms preprocess, 22.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_270.jpg: 640x384 2 persons, 33.3ms\n",
      "Speed: 4.2ms preprocess, 33.3ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_30.jpg: 640x384 3 persons, 1 cell phone, 11.1ms\n",
      "Speed: 4.3ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_300.jpg: 640x384 3 persons, 1 tv, 10.5ms\n",
      "Speed: 3.3ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_330.jpg: 640x384 2 persons, 8.4ms\n",
      "Speed: 2.7ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_360.jpg: 640x384 4 persons, 8.1ms\n",
      "Speed: 2.7ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_390.jpg: 640x384 3 persons, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_60.jpg: 640x384 4 persons, 9.7ms\n",
      "Speed: 3.8ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687665956347322/frame_90.jpg: 640x384 6 persons, 26.0ms\n",
      "Speed: 3.9ms preprocess, 26.0ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-687024156350870\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-687024156350870: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.9ms\n",
      "Speed: 2.5ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_120.jpg: 640x384 4 persons, 7.5ms\n",
      "Speed: 2.8ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_150.jpg: 640x384 4 persons, 11.7ms\n",
      "Speed: 3.5ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_180.jpg: 640x384 2 persons, 13.6ms\n",
      "Speed: 4.1ms preprocess, 13.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_210.jpg: 640x384 2 persons, 10.9ms\n",
      "Speed: 4.1ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_240.jpg: 640x384 3 persons, 14.5ms\n",
      "Speed: 4.2ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_270.jpg: 640x384 2 persons, 10.3ms\n",
      "Speed: 3.6ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_30.jpg: 640x384 3 persons, 1 cell phone, 11.3ms\n",
      "Speed: 3.5ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_300.jpg: 640x384 3 persons, 1 tv, 15.7ms\n",
      "Speed: 3.5ms preprocess, 15.7ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_330.jpg: 640x384 2 persons, 10.9ms\n",
      "Speed: 3.3ms preprocess, 10.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_360.jpg: 640x384 4 persons, 10.2ms\n",
      "Speed: 3.6ms preprocess, 10.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_390.jpg: 640x384 3 persons, 15.0ms\n",
      "Speed: 4.9ms preprocess, 15.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_60.jpg: 640x384 4 persons, 17.7ms\n",
      "Speed: 3.4ms preprocess, 17.7ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-687024156350870/frame_90.jpg: 640x384 6 persons, 13.5ms\n",
      "Speed: 4.4ms preprocess, 13.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-684364333171304\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-684364333171304: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 9.0ms\n",
      "Speed: 3.2ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_120.jpg: 640x384 4 persons, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_150.jpg: 640x384 4 persons, 9.1ms\n",
      "Speed: 2.9ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_180.jpg: 640x384 2 persons, 10.6ms\n",
      "Speed: 3.7ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_210.jpg: 640x384 2 persons, 8.7ms\n",
      "Speed: 3.1ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_240.jpg: 640x384 3 persons, 7.5ms\n",
      "Speed: 2.8ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_270.jpg: 640x384 2 persons, 15.3ms\n",
      "Speed: 4.0ms preprocess, 15.3ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_30.jpg: 640x384 3 persons, 1 cell phone, 31.8ms\n",
      "Speed: 4.9ms preprocess, 31.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_300.jpg: 640x384 3 persons, 1 tv, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_330.jpg: 640x384 2 persons, 12.7ms\n",
      "Speed: 3.9ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_360.jpg: 640x384 4 persons, 12.7ms\n",
      "Speed: 5.0ms preprocess, 12.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_390.jpg: 640x384 3 persons, 13.2ms\n",
      "Speed: 3.4ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_60.jpg: 640x384 4 persons, 12.8ms\n",
      "Speed: 3.5ms preprocess, 12.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-684364333171304/frame_90.jpg: 640x384 6 persons, 15.2ms\n",
      "Speed: 5.6ms preprocess, 15.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-6837957766319053\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-6837957766319053: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 14.7ms\n",
      "Speed: 3.5ms preprocess, 14.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_120.jpg: 640x384 4 persons, 9.0ms\n",
      "Speed: 3.5ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_150.jpg: 640x384 4 persons, 9.6ms\n",
      "Speed: 3.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_180.jpg: 640x384 2 persons, 8.9ms\n",
      "Speed: 3.0ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_210.jpg: 640x384 2 persons, 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_240.jpg: 640x384 3 persons, 13.2ms\n",
      "Speed: 3.2ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_270.jpg: 640x384 2 persons, 28.0ms\n",
      "Speed: 3.9ms preprocess, 28.0ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_30.jpg: 640x384 3 persons, 1 cell phone, 15.9ms\n",
      "Speed: 4.2ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_300.jpg: 640x384 3 persons, 1 tv, 8.2ms\n",
      "Speed: 2.8ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_330.jpg: 640x384 2 persons, 8.9ms\n",
      "Speed: 2.9ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_360.jpg: 640x384 4 persons, 8.6ms\n",
      "Speed: 2.6ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_390.jpg: 640x384 3 persons, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_60.jpg: 640x384 4 persons, 11.6ms\n",
      "Speed: 3.3ms preprocess, 11.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-6837957766319053/frame_90.jpg: 640x384 6 persons, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-682791943270614\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-682791943270614: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.0ms\n",
      "Speed: 2.7ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_120.jpg: 640x384 4 persons, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_150.jpg: 640x384 4 persons, 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_180.jpg: 640x384 2 persons, 18.7ms\n",
      "Speed: 3.4ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_210.jpg: 640x384 2 persons, 8.5ms\n",
      "Speed: 2.6ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_240.jpg: 640x384 3 persons, 9.0ms\n",
      "Speed: 3.2ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_270.jpg: 640x384 2 persons, 24.5ms\n",
      "Speed: 3.3ms preprocess, 24.5ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_300.jpg: 640x384 3 persons, 1 tv, 18.8ms\n",
      "Speed: 4.5ms preprocess, 18.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_330.jpg: 640x384 2 persons, 9.0ms\n",
      "Speed: 3.2ms preprocess, 9.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_360.jpg: 640x384 4 persons, 17.6ms\n",
      "Speed: 3.3ms preprocess, 17.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_390.jpg: 640x384 3 persons, 8.8ms\n",
      "Speed: 3.7ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_60.jpg: 640x384 4 persons, 8.5ms\n",
      "Speed: 2.4ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-682791943270614/frame_90.jpg: 640x384 6 persons, 25.1ms\n",
      "Speed: 3.1ms preprocess, 25.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-680540137074841\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-680540137074841: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.3ms\n",
      "Speed: 3.0ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_120.jpg: 640x384 4 persons, 8.2ms\n",
      "Speed: 3.0ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_150.jpg: 640x384 4 persons, 8.1ms\n",
      "Speed: 2.9ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_180.jpg: 640x384 2 persons, 7.9ms\n",
      "Speed: 2.6ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_210.jpg: 640x384 2 persons, 22.8ms\n",
      "Speed: 4.3ms preprocess, 22.8ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_240.jpg: 640x384 3 persons, 29.0ms\n",
      "Speed: 4.6ms preprocess, 29.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_270.jpg: 640x384 2 persons, 10.1ms\n",
      "Speed: 4.0ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_30.jpg: 640x384 3 persons, 1 cell phone, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_300.jpg: 640x384 3 persons, 1 tv, 8.7ms\n",
      "Speed: 2.8ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_330.jpg: 640x384 2 persons, 8.2ms\n",
      "Speed: 2.7ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_360.jpg: 640x384 4 persons, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_390.jpg: 640x384 3 persons, 10.6ms\n",
      "Speed: 4.6ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_60.jpg: 640x384 4 persons, 10.7ms\n",
      "Speed: 4.0ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680540137074841/frame_90.jpg: 640x384 6 persons, 27.4ms\n",
      "Speed: 3.5ms preprocess, 27.4ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-680162593779089\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-680162593779089: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 12.8ms\n",
      "Speed: 3.7ms preprocess, 12.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_120.jpg: 640x384 4 persons, 11.3ms\n",
      "Speed: 4.0ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_150.jpg: 640x384 4 persons, 23.9ms\n",
      "Speed: 4.2ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_180.jpg: 640x384 2 persons, 12.4ms\n",
      "Speed: 4.4ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_210.jpg: 640x384 2 persons, 17.6ms\n",
      "Speed: 4.4ms preprocess, 17.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_240.jpg: 640x384 3 persons, 29.2ms\n",
      "Speed: 4.8ms preprocess, 29.2ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_270.jpg: 640x384 2 persons, 10.6ms\n",
      "Speed: 3.6ms preprocess, 10.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_30.jpg: 640x384 3 persons, 1 cell phone, 11.8ms\n",
      "Speed: 4.0ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_300.jpg: 640x384 3 persons, 1 tv, 12.8ms\n",
      "Speed: 3.9ms preprocess, 12.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_330.jpg: 640x384 2 persons, 8.4ms\n",
      "Speed: 3.8ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_360.jpg: 640x384 4 persons, 24.7ms\n",
      "Speed: 3.7ms preprocess, 24.7ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_390.jpg: 640x384 3 persons, 9.9ms\n",
      "Speed: 4.4ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_60.jpg: 640x384 4 persons, 11.0ms\n",
      "Speed: 3.3ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-680162593779089/frame_90.jpg: 640x384 6 persons, 12.3ms\n",
      "Speed: 4.6ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-678133704039459\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-678133704039459: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_120.jpg: 640x384 4 persons, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_150.jpg: 640x384 4 persons, 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_180.jpg: 640x384 2 persons, 21.9ms\n",
      "Speed: 3.7ms preprocess, 21.9ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_210.jpg: 640x384 2 persons, 11.2ms\n",
      "Speed: 3.7ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_240.jpg: 640x384 3 persons, 17.9ms\n",
      "Speed: 3.6ms preprocess, 17.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_270.jpg: 640x384 2 persons, 12.8ms\n",
      "Speed: 4.7ms preprocess, 12.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_30.jpg: 640x384 3 persons, 1 cell phone, 25.1ms\n",
      "Speed: 4.9ms preprocess, 25.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_300.jpg: 640x384 3 persons, 1 tv, 9.3ms\n",
      "Speed: 4.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_330.jpg: 640x384 2 persons, 12.1ms\n",
      "Speed: 3.8ms preprocess, 12.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_360.jpg: 640x384 4 persons, 22.9ms\n",
      "Speed: 3.0ms preprocess, 22.9ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_390.jpg: 640x384 3 persons, 22.9ms\n",
      "Speed: 4.2ms preprocess, 22.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_60.jpg: 640x384 4 persons, 13.2ms\n",
      "Speed: 4.1ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-678133704039459/frame_90.jpg: 640x384 6 persons, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-676770877464110\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-676770877464110: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 7.8ms\n",
      "Speed: 3.1ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_120.jpg: 640x384 4 persons, 14.3ms\n",
      "Speed: 4.0ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_150.jpg: 640x384 4 persons, 12.9ms\n",
      "Speed: 3.3ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_180.jpg: 640x384 2 persons, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_210.jpg: 640x384 2 persons, 17.0ms\n",
      "Speed: 3.8ms preprocess, 17.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_240.jpg: 640x384 3 persons, 34.3ms\n",
      "Speed: 4.7ms preprocess, 34.3ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_270.jpg: 640x384 2 persons, 12.7ms\n",
      "Speed: 3.9ms preprocess, 12.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_30.jpg: 640x384 3 persons, 1 cell phone, 11.2ms\n",
      "Speed: 3.6ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_300.jpg: 640x384 3 persons, 1 tv, 32.2ms\n",
      "Speed: 4.7ms preprocess, 32.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_330.jpg: 640x384 2 persons, 8.6ms\n",
      "Speed: 2.9ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_360.jpg: 640x384 4 persons, 8.0ms\n",
      "Speed: 2.6ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_390.jpg: 640x384 3 persons, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_60.jpg: 640x384 4 persons, 9.4ms\n",
      "Speed: 3.3ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-676770877464110/frame_90.jpg: 640x384 6 persons, 21.8ms\n",
      "Speed: 3.9ms preprocess, 21.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-673961584214053\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-673961584214053: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_0.jpg: 640x384 2 persons, 1 remote, 1 cell phone, 10.9ms\n",
      "Speed: 3.4ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_120.jpg: 640x384 4 persons, 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_150.jpg: 640x384 4 persons, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_180.jpg: 640x384 2 persons, 11.8ms\n",
      "Speed: 4.0ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_210.jpg: 640x384 2 persons, 31.7ms\n",
      "Speed: 3.5ms preprocess, 31.7ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_240.jpg: 640x384 3 persons, 14.3ms\n",
      "Speed: 4.3ms preprocess, 14.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_270.jpg: 640x384 2 persons, 9.7ms\n",
      "Speed: 3.3ms preprocess, 9.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_30.jpg: 640x384 3 persons, 1 cell phone, 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_300.jpg: 640x384 3 persons, 1 tv, 8.5ms\n",
      "Speed: 2.7ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_330.jpg: 640x384 2 persons, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_360.jpg: 640x384 4 persons, 12.7ms\n",
      "Speed: 3.0ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_390.jpg: 640x384 3 persons, 11.9ms\n",
      "Speed: 4.6ms preprocess, 11.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_60.jpg: 640x384 4 persons, 14.7ms\n",
      "Speed: 4.5ms preprocess, 14.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-673961584214053/frame_90.jpg: 640x384 6 persons, 13.6ms\n",
      "Speed: 3.9ms preprocess, 13.6ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-671839840899900\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-671839840899900: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_0.jpg: 640x640 (no detections), 6.8ms\n",
      "Speed: 5.2ms preprocess, 6.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_120.jpg: 640x640 1 dining table, 9.4ms\n",
      "Speed: 5.9ms preprocess, 9.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_150.jpg: 640x640 1 person, 11.2ms\n",
      "Speed: 7.7ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_180.jpg: 640x640 1 dining table, 12.8ms\n",
      "Speed: 5.3ms preprocess, 12.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_210.jpg: 640x640 1 dining table, 10.2ms\n",
      "Speed: 8.1ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_240.jpg: 640x640 1 person, 3 tvs, 28.1ms\n",
      "Speed: 8.8ms preprocess, 28.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_270.jpg: 640x640 2 persons, 1 tv, 24.0ms\n",
      "Speed: 5.9ms preprocess, 24.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_30.jpg: 640x640 (no detections), 10.0ms\n",
      "Speed: 6.0ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_300.jpg: 640x640 1 tv, 1 book, 10.1ms\n",
      "Speed: 4.9ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_330.jpg: 640x640 1 tv, 1 book, 32.0ms\n",
      "Speed: 8.3ms preprocess, 32.0ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_360.jpg: 640x640 (no detections), 13.6ms\n",
      "Speed: 5.5ms preprocess, 13.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_390.jpg: 640x640 (no detections), 26.7ms\n",
      "Speed: 8.2ms preprocess, 26.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_420.jpg: 640x640 (no detections), 14.6ms\n",
      "Speed: 7.7ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_60.jpg: 640x640 (no detections), 9.8ms\n",
      "Speed: 5.4ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-671839840899900/frame_90.jpg: 640x640 (no detections), 10.3ms\n",
      "Speed: 5.6ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-425151876539382\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-425151876539382: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_0.jpg: 640x384 1 person, 9.1ms\n",
      "Speed: 2.7ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_120.jpg: 640x384 (no detections), 12.4ms\n",
      "Speed: 3.8ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_150.jpg: 640x384 (no detections), 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_180.jpg: 640x384 1 banana, 1 toilet, 20.4ms\n",
      "Speed: 4.6ms preprocess, 20.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_210.jpg: 640x384 (no detections), 10.1ms\n",
      "Speed: 3.5ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_240.jpg: 640x384 (no detections), 13.7ms\n",
      "Speed: 3.0ms preprocess, 13.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_270.jpg: 640x384 (no detections), 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_30.jpg: 640x384 (no detections), 10.7ms\n",
      "Speed: 4.4ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_300.jpg: 640x384 3 persons, 18.6ms\n",
      "Speed: 3.3ms preprocess, 18.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_330.jpg: 640x384 2 persons, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_360.jpg: 640x384 1 person, 1 cell phone, 14.3ms\n",
      "Speed: 3.3ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_390.jpg: 640x384 1 cell phone, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_420.jpg: 640x384 1 person, 1 cell phone, 8.2ms\n",
      "Speed: 2.7ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_450.jpg: 640x384 3 persons, 1 cell phone, 9.6ms\n",
      "Speed: 3.0ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_480.jpg: 640x384 1 person, 1 cell phone, 28.2ms\n",
      "Speed: 3.7ms preprocess, 28.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_510.jpg: 640x384 3 persons, 9.3ms\n",
      "Speed: 3.1ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_540.jpg: 640x384 2 persons, 1 toilet, 10.6ms\n",
      "Speed: 3.2ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_570.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_570.jpg: 640x384 2 persons, 1 tv, 14.9ms\n",
      "Speed: 3.5ms preprocess, 14.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_60.jpg: 640x384 1 person, 11.8ms\n",
      "Speed: 3.8ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_600.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_600.jpg: 640x384 2 persons, 11.6ms\n",
      "Speed: 3.9ms preprocess, 11.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_630.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_630.jpg: 640x384 (no detections), 9.4ms\n",
      "Speed: 3.1ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_660.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_660.jpg: 640x384 (no detections), 11.6ms\n",
      "Speed: 3.2ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-425151876539382/frame_90.jpg: 640x384 (no detections), 14.1ms\n",
      "Speed: 3.8ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-424394867097391\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-424394867097391: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_0.jpg: 640x640 1 person, 1 chair, 1 clock, 8.2ms\n",
      "Speed: 4.8ms preprocess, 8.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_120.jpg: 640x640 1 person, 1 clock, 9.8ms\n",
      "Speed: 8.5ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_150.jpg: 640x640 1 person, 2 clocks, 8.3ms\n",
      "Speed: 4.5ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_180.jpg: 640x640 1 person, 1 chair, 7.3ms\n",
      "Speed: 4.4ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_210.jpg: 640x640 2 persons, 10.3ms\n",
      "Speed: 5.4ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_240.jpg: 640x640 2 persons, 1 chair, 1 clock, 10.1ms\n",
      "Speed: 5.2ms preprocess, 10.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_270.jpg: 640x640 2 persons, 1 chair, 31.3ms\n",
      "Speed: 8.8ms preprocess, 31.3ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_30.jpg: 640x640 1 person, 1 chair, 1 clock, 11.5ms\n",
      "Speed: 8.0ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_300.jpg: 640x640 (no detections), 10.0ms\n",
      "Speed: 6.7ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_330.jpg: 640x640 (no detections), 12.0ms\n",
      "Speed: 7.2ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_60.jpg: 640x640 2 persons, 1 bowl, 18.0ms\n",
      "Speed: 8.1ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-424394867097391/frame_90.jpg: 640x640 3 persons, 12.0ms\n",
      "Speed: 6.5ms preprocess, 12.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-1693566687752051\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-1693566687752051: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_0.jpg: 640x640 (no detections), 6.6ms\n",
      "Speed: 5.2ms preprocess, 6.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_120.jpg: 640x640 (no detections), 8.1ms\n",
      "Speed: 5.2ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_150.jpg: 640x640 2 persons, 7.7ms\n",
      "Speed: 4.4ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_180.jpg: 640x640 2 persons, 8.8ms\n",
      "Speed: 4.4ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_210.jpg: 640x640 2 persons, 1 motorcycle, 7.6ms\n",
      "Speed: 5.0ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_240.jpg: 640x640 2 persons, 1 giraffe, 8.9ms\n",
      "Speed: 5.7ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_270.jpg: 640x640 1 person, 29.6ms\n",
      "Speed: 6.6ms preprocess, 29.6ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_30.jpg: 640x640 (no detections), 24.9ms\n",
      "Speed: 8.8ms preprocess, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_300.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 6.2ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_330.jpg: 640x640 1 person, 1 bowl, 9.5ms\n",
      "Speed: 4.6ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_360.jpg: 640x640 2 persons, 9.1ms\n",
      "Speed: 5.0ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_390.jpg: 640x640 (no detections), 9.6ms\n",
      "Speed: 5.0ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_60.jpg: 640x640 (no detections), 8.4ms\n",
      "Speed: 4.6ms preprocess, 8.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1693566687752051/frame_90.jpg: 640x640 (no detections), 20.5ms\n",
      "Speed: 4.4ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-1689212771862832\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-1689212771862832: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_0.jpg: 640x384 2 persons, 8.1ms\n",
      "Speed: 2.5ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_120.jpg: 640x384 3 persons, 1 book, 8.2ms\n",
      "Speed: 3.0ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_150.jpg: 640x384 2 persons, 2 books, 7.8ms\n",
      "Speed: 2.4ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_180.jpg: 640x384 4 persons, 8.7ms\n",
      "Speed: 2.5ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_210.jpg: 640x384 1 person, 17.3ms\n",
      "Speed: 3.6ms preprocess, 17.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_240.jpg: 640x384 1 person, 14.9ms\n",
      "Speed: 4.2ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_270.jpg: 640x384 3 persons, 18.8ms\n",
      "Speed: 4.3ms preprocess, 18.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_30.jpg: 640x384 2 persons, 2 cell phones, 23.5ms\n",
      "Speed: 4.3ms preprocess, 23.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_300.jpg: 640x384 3 persons, 13.0ms\n",
      "Speed: 3.9ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_330.jpg: 640x384 1 person, 1 book, 9.5ms\n",
      "Speed: 3.5ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_360.jpg: 640x384 1 person, 1 book, 15.5ms\n",
      "Speed: 3.5ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_390.jpg: 640x384 3 persons, 1 book, 33.2ms\n",
      "Speed: 5.1ms preprocess, 33.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_420.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_420.jpg: 640x384 2 persons, 1 book, 10.9ms\n",
      "Speed: 3.5ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_450.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_450.jpg: 640x384 2 persons, 12.7ms\n",
      "Speed: 4.6ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_480.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_480.jpg: 640x384 1 person, 12.9ms\n",
      "Speed: 4.4ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_510.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_510.jpg: 640x384 (no detections), 12.3ms\n",
      "Speed: 3.9ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_540.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_540.jpg: 640x384 1 kite, 11.0ms\n",
      "Speed: 3.6ms preprocess, 11.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_60.jpg: 640x384 1 person, 1 book, 16.5ms\n",
      "Speed: 3.3ms preprocess, 16.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1689212771862832/frame_90.jpg: 640x384 6 persons, 19.1ms\n",
      "Speed: 5.9ms preprocess, 19.1ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-1685108828975354\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-1685108828975354: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_0.jpg: 640x384 1 person, 13.8ms\n",
      "Speed: 4.6ms preprocess, 13.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_120.jpg: 640x384 4 persons, 1 cell phone, 22.9ms\n",
      "Speed: 4.1ms preprocess, 22.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_150.jpg: 640x384 5 persons, 13.5ms\n",
      "Speed: 4.0ms preprocess, 13.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_180.jpg: 640x384 (no detections), 30.5ms\n",
      "Speed: 5.0ms preprocess, 30.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_210.jpg: 640x384 1 person, 19.8ms\n",
      "Speed: 4.8ms preprocess, 19.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_240.jpg: 640x384 2 persons, 15.4ms\n",
      "Speed: 4.2ms preprocess, 15.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_270.jpg: 640x384 (no detections), 29.0ms\n",
      "Speed: 3.8ms preprocess, 29.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_30.jpg: 640x384 (no detections), 14.3ms\n",
      "Speed: 4.6ms preprocess, 14.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_300.jpg: 640x384 2 persons, 27.7ms\n",
      "Speed: 4.2ms preprocess, 27.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_330.jpg: 640x384 (no detections), 12.4ms\n",
      "Speed: 4.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_360.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_360.jpg: 640x384 (no detections), 31.5ms\n",
      "Speed: 5.1ms preprocess, 31.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_390.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_390.jpg: 640x384 (no detections), 33.0ms\n",
      "Speed: 5.0ms preprocess, 33.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_60.jpg: 640x384 (no detections), 15.3ms\n",
      "Speed: 3.8ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1685108828975354/frame_90.jpg: 640x384 2 persons, 1 cell phone, 17.1ms\n",
      "Speed: 4.1ms preprocess, 17.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Processing video: /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-1118763132933218\n",
      "Error extracting audio from /home/harshit/Desktop/hi/influencer_analysis/notebooks/videos/hd-1118763132933218: [Errno 2] No such file or directory: 'ffmpeg'\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_0.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_0.jpg: 640x640 1 person, 1 chair, 1 clock, 11.2ms\n",
      "Speed: 5.5ms preprocess, 11.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_120.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_120.jpg: 640x640 1 person, 1 clock, 12.3ms\n",
      "Speed: 7.5ms preprocess, 12.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_150.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_150.jpg: 640x640 1 person, 2 clocks, 22.7ms\n",
      "Speed: 7.9ms preprocess, 22.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_180.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_180.jpg: 640x640 1 person, 1 chair, 16.4ms\n",
      "Speed: 7.8ms preprocess, 16.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_210.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_210.jpg: 640x640 2 persons, 19.8ms\n",
      "Speed: 8.8ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_240.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_240.jpg: 640x640 2 persons, 1 chair, 1 clock, 29.1ms\n",
      "Speed: 9.5ms preprocess, 29.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_270.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_270.jpg: 640x640 2 persons, 1 chair, 19.5ms\n",
      "Speed: 9.5ms preprocess, 19.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_30.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_30.jpg: 640x640 1 person, 1 chair, 1 clock, 17.3ms\n",
      "Speed: 8.0ms preprocess, 17.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_300.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_300.jpg: 640x640 (no detections), 14.5ms\n",
      "Speed: 7.4ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_330.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_330.jpg: 640x640 (no detections), 12.5ms\n",
      "Speed: 7.3ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_60.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_60.jpg: 640x640 2 persons, 1 bowl, 12.6ms\n",
      "Speed: 7.2ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Analyzing frame: /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_90.jpg\n",
      "\n",
      "image 1/1 /home/harshit/Desktop/hi/influencer_analysis/notebooks/frames/hd-1118763132933218/frame_90.jpg: 640x640 3 persons, 12.4ms\n",
      "Speed: 7.4ms preprocess, 12.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12540/2324502460.py:5: UserWarning: Pandas requires version '1.4.3' or newer of 'xlsxwriter' (version '1.3.7' currently installed).\n",
      "  updated_faceless_df.to_excel(\"faceless_videos_analysis.xlsx\", index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Results saved to faceless_videos_analysis.xlsx\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
